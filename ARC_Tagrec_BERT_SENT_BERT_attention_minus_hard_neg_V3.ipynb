{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ARC_Tagrec_BERT_SENT_BERT_attention_minus_hard_neg_V3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2cdce221827740e0a28d7045dbacb507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75b4c348c3f849f191cbc54ac14c42cb",
              "IPY_MODEL_cd1309a16f4348b190be12a356be55aa",
              "IPY_MODEL_e573954edea84fd591f8df7c49bf4184"
            ],
            "layout": "IPY_MODEL_d70e0ce2b913494ba4e9dcabe46c54b1"
          }
        },
        "75b4c348c3f849f191cbc54ac14c42cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b333ad77558a4a4d8cef4999dfe4d612",
            "placeholder": "​",
            "style": "IPY_MODEL_7740b11415904e708e473bb4873944e3",
            "value": "Downloading: 100%"
          }
        },
        "cd1309a16f4348b190be12a356be55aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74f8f8602b343838363e1d4926fde24",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7475b0061bf420a8594da45df1174c2",
            "value": 231508
          }
        },
        "e573954edea84fd591f8df7c49bf4184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffcf18e7ea0c4228bda1d697e7268c28",
            "placeholder": "​",
            "style": "IPY_MODEL_80a54fbfa0b24562a98f8891a29267aa",
            "value": " 232k/232k [00:00&lt;00:00, 1.00MB/s]"
          }
        },
        "d70e0ce2b913494ba4e9dcabe46c54b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b333ad77558a4a4d8cef4999dfe4d612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7740b11415904e708e473bb4873944e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f74f8f8602b343838363e1d4926fde24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7475b0061bf420a8594da45df1174c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffcf18e7ea0c4228bda1d697e7268c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a54fbfa0b24562a98f8891a29267aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fdca86a07c34ab4b18b56ae2d30ceea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29faee0296504936ae99dc0259c31637",
              "IPY_MODEL_35abecc0c0064463a31d3c544563856e",
              "IPY_MODEL_193b8ecf25984135adc70b2b8202b41d"
            ],
            "layout": "IPY_MODEL_d324e5d8e7cb40a48ba0a278c55dfaf3"
          }
        },
        "29faee0296504936ae99dc0259c31637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5afebaf86047ebba37058574e2e00e",
            "placeholder": "​",
            "style": "IPY_MODEL_e87f32991f954e7c8aec7e3ed3f05444",
            "value": "Downloading: 100%"
          }
        },
        "35abecc0c0064463a31d3c544563856e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8842a6ae612346d1865d537ccfa6565f",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_988964ecd37d471f893d7523bb040915",
            "value": 433
          }
        },
        "193b8ecf25984135adc70b2b8202b41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd6ce4cfe5bd451b9c6126cdbc18d6d1",
            "placeholder": "​",
            "style": "IPY_MODEL_1afe70289cb04d4f9263e5de1c3d882a",
            "value": " 433/433 [00:00&lt;00:00, 9.16kB/s]"
          }
        },
        "d324e5d8e7cb40a48ba0a278c55dfaf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5afebaf86047ebba37058574e2e00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e87f32991f954e7c8aec7e3ed3f05444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8842a6ae612346d1865d537ccfa6565f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988964ecd37d471f893d7523bb040915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd6ce4cfe5bd451b9c6126cdbc18d6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1afe70289cb04d4f9263e5de1c3d882a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f995a5f98f5f4c2a983c2f83354daa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bff1c6dff7a747c6a58011942070ff34",
              "IPY_MODEL_8732dd7ad5c7498b883cc2d0876b4358",
              "IPY_MODEL_f20360be6f4e46399a6fe3d93230ff3f"
            ],
            "layout": "IPY_MODEL_8f2e223875cc4682b9cf50b1a2bea249"
          }
        },
        "bff1c6dff7a747c6a58011942070ff34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a85e569614d4a05949d779a1465c9f7",
            "placeholder": "​",
            "style": "IPY_MODEL_963cec7dc7364f21b4420c6b17d1d6a7",
            "value": "Downloading: 100%"
          }
        },
        "8732dd7ad5c7498b883cc2d0876b4358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8f39618be3b42d48df9d96a49c7c427",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbe48b722d80495aa01347b73cb6bb2f",
            "value": 440473133
          }
        },
        "f20360be6f4e46399a6fe3d93230ff3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3692f6266014db198f42be50f7ec10c",
            "placeholder": "​",
            "style": "IPY_MODEL_f2cb16a60e1a44dd87d62f3d1a59e4fb",
            "value": " 440M/440M [00:41&lt;00:00, 11.5MB/s]"
          }
        },
        "8f2e223875cc4682b9cf50b1a2bea249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a85e569614d4a05949d779a1465c9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963cec7dc7364f21b4420c6b17d1d6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8f39618be3b42d48df9d96a49c7c427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe48b722d80495aa01347b73cb6bb2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3692f6266014db198f42be50f7ec10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2cb16a60e1a44dd87d62f3d1a59e4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR9av2JU3kf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870a8ae4-1cd3-4014-8dce-58c19763f1f8"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beu-zA1vy43M"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da-zaZJUGMFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd256f5-7521-4429-ae37-ac718ca299ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbjjEyCh1lf2",
        "outputId": "04fc8069-9918-4215-8556-c9dd79f0282e"
      },
      "source": [
        "!pip install tensorflow==1.13.1\n",
        "! pip install tensorflow-hub==0.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.13.1\n",
            "  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.46.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.6)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 46.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.7)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-hub==0.7.0\n",
            "  Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (3.17.3)\n",
            "Installing collected packages: tensorflow-hub\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.12.0\n",
            "    Uninstalling tensorflow-hub-0.12.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.12.0\n",
            "Successfully installed tensorflow-hub-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slZnjEXG5_-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4255d0af-7551-41a5-b929-49daf20b94f8"
      },
      "source": [
        "!pip install sentence-transformers==0.2.6.1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers==0.2.6.1\n",
            "  Downloading sentence-transformers-0.2.6.1.tar.gz (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting transformers>=2.8.0\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (3.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->sentence-transformers==0.2.6.1) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers==0.2.6.1) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers==0.2.6.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers==0.2.6.1) (3.1.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.6.1-py3-none-any.whl size=74031 sha256=6b6a556e2517719ce23953fe35d1f32d215d0eb75981a79e8f07bc723d065515\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/eb/84/05830bceaeef549ceb0257c6797254173e197e971b3f911ee4\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 sentence-transformers-0.2.6.1 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlE6vskY9VmG"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_SENT_BERT_cos_QC_attention_V3/\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Xz7HNHZYeo"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_SENT_BERT_cos_1/\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzKeqoCs3kgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d38700d-42d0-4e03-9cea-f61c83796427"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==2.8.0\n",
            "  Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
            "\u001b[K     |████████████████████████████████| 563 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.7.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 18.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 38.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.0\n",
            "  Downloading botocore-1.27.0-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 34.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.0->boto3->transformers==2.8.0) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 35.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.0->boto3->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 27.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=589a0c4feb49f39ab1f0e0aba0133cd79df8fba30b86fa520272c201a6702fe1\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.12.1\n",
            "    Uninstalling tokenizers-0.12.1:\n",
            "      Successfully uninstalled tokenizers-0.12.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.19.2\n",
            "    Uninstalling transformers-4.19.2:\n",
            "      Successfully uninstalled transformers-4.19.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.24.0 botocore-1.27.0 jmespath-1.0.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.8.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf-OXnTs-ZhS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZFv4UU8sLTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9b5028-62e9-48c4-c984-538c33830674"
      },
      "source": [
        "!pip install git+https://github.com/geoopt/geoopt.git\n",
        "! pip install git+https://github.com/ferrine/hyrnn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/geoopt/geoopt.git\n",
            "  Cloning https://github.com/geoopt/geoopt.git to /tmp/pip-req-build-7n4j63yr\n",
            "  Running command git clone -q https://github.com/geoopt/geoopt.git /tmp/pip-req-build-7n4j63yr\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from geoopt==0.4.1) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geoopt==0.4.1) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9.0->geoopt==0.4.1) (4.2.0)\n",
            "Building wheels for collected packages: geoopt\n",
            "  Building wheel for geoopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geoopt: filename=geoopt-0.4.1-py3-none-any.whl size=86950 sha256=ad675420997630b909c5c5e8969b9b3d176c01436aa22c011b64b6285321b55c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x2p760_x/wheels/e9/b9/1f/4238e702b8889c5329cc24bb3c1d020ab33de17df8ee1e8da4\n",
            "Successfully built geoopt\n",
            "Installing collected packages: geoopt\n",
            "Successfully installed geoopt-0.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ferrine/hyrnn.git\n",
            "  Cloning https://github.com/ferrine/hyrnn.git to /tmp/pip-req-build-anjk1e_j\n",
            "  Running command git clone -q https://github.com/ferrine/hyrnn.git /tmp/pip-req-build-anjk1e_j\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->hyrnn==0.0.0) (4.2.0)\n",
            "Building wheels for collected packages: hyrnn\n",
            "  Building wheel for hyrnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hyrnn: filename=hyrnn-0.0.0-py3-none-any.whl size=13968 sha256=f6d2b736c4ee172e2fc4e202e4282528eb316850a1c7d78d153fa444b817a5ba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-md6y1iv1/wheels/9a/b5/0c/65c228cf8105d16c7ce153a243913604c5f2312980a719e1b2\n",
            "Successfully built hyrnn\n",
            "Installing collected packages: hyrnn\n",
            "Successfully installed hyrnn-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsADhaO93kgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "771d129e-9667-42dd-ea4f-3d84e13a3456"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"train_QC_data.csv\")\n",
        "val_data = pd.read_csv(\"val_QC_data.csv\")\n",
        "test_data = pd.read_csv(\"test_QC_data.csv\")\n",
        "\n",
        "train_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  questionID originalQuestionID  totalPossiblePoint AnswerKey  \\\n",
              "0            VASoL_2008_3_34                 34                   1         C   \n",
              "1              MCAS_2015_8_6                  6                   1         B   \n",
              "2          Mercury_SC_417677             417677                   1         B   \n",
              "3            Mercury_7230423            7230423                   1         A   \n",
              "4      NYSEDREGENTS_2007_8_6                  6                   1         2   \n",
              "...                      ...                ...                 ...       ...   \n",
              "5592          Mercury_402502             402502                   1         D   \n",
              "5593          MCAS_2006_9_20                 20                   1         B   \n",
              "5594  NYSEDREGENTS_2013_8_35                 35                   1         4   \n",
              "5595         Mercury_7082670            7082670                   1         C   \n",
              "5596         Mercury_7004970            7004970                   1         C   \n",
              "\n",
              "      isMultipleChoiceQuestion  includesDiagram  \\\n",
              "0                            1                0   \n",
              "1                            1                0   \n",
              "2                            1                0   \n",
              "3                            1                0   \n",
              "4                            1                0   \n",
              "...                        ...              ...   \n",
              "5592                         1                0   \n",
              "5593                         1                0   \n",
              "5594                         1                0   \n",
              "5595                         1                0   \n",
              "5596                         1                0   \n",
              "\n",
              "                                      examName  grade  year  \\\n",
              "0     Virginia Standards of Learning - Science      3  2008   \n",
              "1                                         MCAS      8  2015   \n",
              "2                                      Mercury      4  2015   \n",
              "3                                      Mercury      9  2015   \n",
              "4                                 NYSEDREGENTS      8  2007   \n",
              "...                                        ...    ...   ...   \n",
              "5592                                   Mercury      8  2015   \n",
              "5593                                      MCAS      9  2006   \n",
              "5594                              NYSEDREGENTS      8  2013   \n",
              "5595                                   Mercury      7  2015   \n",
              "5596                                   Mercury      8  2015   \n",
              "\n",
              "                                                QCLabel  \\\n",
              "0                     matter_properties of objects_TEXT   \n",
              "1                            celestial_FEATURES_STELLAR   \n",
              "2                                  energy_LIGHT_REFLECT   \n",
              "3                                LIFE_EXTINCTION_MASSEX   \n",
              "4     Life_functions_features and functions_CELLBIO_...   \n",
              "...                                                 ...   \n",
              "5592                    matter_chemistry_periodic table   \n",
              "5593                                       FOR_MOMENTUM   \n",
              "5594  Life_functions_features and functions_PLANT_PH...   \n",
              "5595              energy_LIGHT_electromagnetic spectrum   \n",
              "5596        Life_reproduction_DNA inheritance_DOMRECESS   \n",
              "\n",
              "                                               Question  subject category  \\\n",
              "0     A student is asked to bring something that fee...      NaN    Train   \n",
              "1     Which of the following statements best describ...      NaN     Test   \n",
              "2     A polished metal ball looks very shiny and bri...      NaN     Test   \n",
              "3     Which was a main force driving extensive speci...      NaN     Test   \n",
              "4     Compared to the amount of hereditary informati...      NaN    Train   \n",
              "...                                                 ...      ...      ...   \n",
              "5592  According to the periodic table, argon is foun...      NaN     Test   \n",
              "5593  Which of the following has the least momentum?...      NaN    Train   \n",
              "5594  The amount of which greenhouse gas in the air ...      NaN     Test   \n",
              "5595  The visible light spectrum can be subdivided a...      NaN     Test   \n",
              "5596  A scientist crosses a red-flowered plant with ...      NaN    Train   \n",
              "\n",
              "           fold  \n",
              "0          Easy  \n",
              "1          Easy  \n",
              "2     Challenge  \n",
              "3          Easy  \n",
              "4     Challenge  \n",
              "...         ...  \n",
              "5592  Challenge  \n",
              "5593  Challenge  \n",
              "5594       Easy  \n",
              "5595       Easy  \n",
              "5596       Easy  \n",
              "\n",
              "[5597 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0aa78df5-2c40-4a4d-81fd-9ebc2dec32fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VASoL_2008_3_34</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Virginia Standards of Learning - Science</td>\n",
              "      <td>3</td>\n",
              "      <td>2008</td>\n",
              "      <td>matter_properties of objects_TEXT</td>\n",
              "      <td>A student is asked to bring something that fee...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MCAS_2015_8_6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>celestial_FEATURES_STELLAR</td>\n",
              "      <td>Which of the following statements best describ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mercury_SC_417677</td>\n",
              "      <td>417677</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>4</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_REFLECT</td>\n",
              "      <td>A polished metal ball looks very shiny and bri...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_7230423</td>\n",
              "      <td>7230423</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>9</td>\n",
              "      <td>2015</td>\n",
              "      <td>LIFE_EXTINCTION_MASSEX</td>\n",
              "      <td>Which was a main force driving extensive speci...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NYSEDREGENTS_2007_8_6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>Life_functions_features and functions_CELLBIO_...</td>\n",
              "      <td>Compared to the amount of hereditary informati...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5592</th>\n",
              "      <td>Mercury_402502</td>\n",
              "      <td>402502</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_chemistry_periodic table</td>\n",
              "      <td>According to the periodic table, argon is foun...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5593</th>\n",
              "      <td>MCAS_2006_9_20</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>FOR_MOMENTUM</td>\n",
              "      <td>Which of the following has the least momentum?...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5594</th>\n",
              "      <td>NYSEDREGENTS_2013_8_35</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>8</td>\n",
              "      <td>2013</td>\n",
              "      <td>Life_functions_features and functions_PLANT_PH...</td>\n",
              "      <td>The amount of which greenhouse gas in the air ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5595</th>\n",
              "      <td>Mercury_7082670</td>\n",
              "      <td>7082670</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_electromagnetic spectrum</td>\n",
              "      <td>The visible light spectrum can be subdivided a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5596</th>\n",
              "      <td>Mercury_7004970</td>\n",
              "      <td>7004970</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_reproduction_DNA inheritance_DOMRECESS</td>\n",
              "      <td>A scientist crosses a red-flowered plant with ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5597 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0aa78df5-2c40-4a4d-81fd-9ebc2dec32fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0aa78df5-2c40-4a4d-81fd-9ebc2dec32fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0aa78df5-2c40-4a4d-81fd-9ebc2dec32fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhO6qqt6lge"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD4IAgG1XQGp"
      },
      "source": [
        "import re\n",
        "def clean_sentence(question):\n",
        "  # print(question)\n",
        "  question = re.sub('<[^>]*>', ' ',question)\n",
        "  question = re.sub(' +', ' ', question)\n",
        "  question = re.sub('\\xa0','',question)\n",
        "  question = question.rstrip()\n",
        "  question = re.sub('nan','',question)\n",
        "  question = re.sub(u'\\u2004','',question)\n",
        "  question = re.sub(u'\\u2009','',question)\n",
        "\n",
        "  # question = question.decode(\"utf-8\")\n",
        "  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n",
        "  question = re.sub('&nbsp','',question)\n",
        "  question = re.sub('&ndash','',question)\n",
        "  question = re.sub('\\r','',question)\n",
        "  question = re.sub('\\t','',question)\n",
        "  question = re.sub('\\n',' ',question)\n",
        "\n",
        "  question = re.sub('MathType@.*','',question)\n",
        "  question = re.sub('&thinsp','',question)\n",
        "  question = re.sub('&times','',question)\n",
        "  question = re.sub('\\u200b','',question)\n",
        "  question = re.sub('&rarr;;;','',question)\n",
        "\n",
        "  return question"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNrGNk8f3kgh"
      },
      "source": [
        "# final_data_1 = final_data.loc[0:71003,:]\n",
        "# final_data_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIrS5sxE3kgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "2cdce221827740e0a28d7045dbacb507",
            "75b4c348c3f849f191cbc54ac14c42cb",
            "cd1309a16f4348b190be12a356be55aa",
            "e573954edea84fd591f8df7c49bf4184",
            "d70e0ce2b913494ba4e9dcabe46c54b1",
            "b333ad77558a4a4d8cef4999dfe4d612",
            "7740b11415904e708e473bb4873944e3",
            "f74f8f8602b343838363e1d4926fde24",
            "a7475b0061bf420a8594da45df1174c2",
            "ffcf18e7ea0c4228bda1d697e7268c28",
            "80a54fbfa0b24562a98f8891a29267aa"
          ]
        },
        "outputId": "b830eca6-fcb4-4102-bfc1-a4d2eb452dd0"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cdce221827740e0a28d7045dbacb507"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mgc72PQYV1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b108794-92d3-4dda-d362-af7cb53ccf4f"
      },
      "source": [
        "train_data[\"QCLabel\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                             106\n",
              "matter_chemistry_periodic table               85\n",
              "matter_chemistry_atomic                       79\n",
              "matter_CHANGES_CHEMICAL                       72\n",
              "science_INFERENCE_observation                 69\n",
              "                                            ... \n",
              "EARTH_GEO_HISTORY                              1\n",
              "science_INFERENCE_INFERENCE                    1\n",
              "FOR_AIRRESISTANCE                              1\n",
              "matter_measurement_UNIT_PH                     1\n",
              "energy_ELEC_ELECTROMAGNETS_energy_devices      1\n",
              "Name: QCLabel, Length: 416, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3lYOb2K3kgy"
      },
      "source": [
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# LE = LabelEncoder()\n",
        "# final_data['label'] = LE.fit_transform(final_data['board_syllabus'])\n",
        "# final_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp64MkNB3kg1"
      },
      "source": [
        "# def get_labels(prediction):\n",
        "#     predicted_label =  LE.inverse_transform([prediction])\n",
        "#     return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgTmJPS3kg4"
      },
      "source": [
        "# get_labels(330)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrQ1BBx0vWUQ"
      },
      "source": [
        "# train_data = pd.concat([train_data,val_data])\n",
        "# train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuhr8z0tcd_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1fe670e-cf3a-47ab-91e1-9712c80d817e"
      },
      "source": [
        "val_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            questionID originalQuestionID  totalPossiblePoint AnswerKey  \\\n",
              "0    MCAS_2006_9_30-v1                 30                   1         D   \n",
              "1    Mercury_SC_401144             401144                   1         B   \n",
              "2     NCEOGA_2013_8_46                 46                   1         A   \n",
              "3       Mercury_417146             417146                   1         A   \n",
              "4      Mercury_7283833            7283833                   1         B   \n",
              "..                 ...                ...                 ...       ...   \n",
              "773    Mercury_7128853            7128853                   1         A   \n",
              "774    Mercury_7245858            7245858                   1         A   \n",
              "775     Mercury_417462             417462                   1         C   \n",
              "776    Mercury_7044065            7044065                   1         D   \n",
              "777    Mercury_7094238            7094238                   1         C   \n",
              "\n",
              "     isMultipleChoiceQuestion  includesDiagram  \\\n",
              "0                           1                0   \n",
              "1                           1                0   \n",
              "2                           1                0   \n",
              "3                           1                0   \n",
              "4                           1                0   \n",
              "..                        ...              ...   \n",
              "773                         1                0   \n",
              "774                         1                0   \n",
              "775                         1                0   \n",
              "776                         1                0   \n",
              "777                         1                0   \n",
              "\n",
              "                                         examName  grade  year  \\\n",
              "0                                            MCAS      9  2006   \n",
              "1                                         Mercury      5  2015   \n",
              "2    North Carolina READY End-of-Grade Assessment      8  2013   \n",
              "3                                         Mercury      8  2015   \n",
              "4                                         Mercury      8  2015   \n",
              "..                                            ...    ...   ...   \n",
              "773                                       Mercury      8  2015   \n",
              "774                                       Mercury      7  2015   \n",
              "775                                       Mercury      7  2015   \n",
              "776                                       Mercury      8  2015   \n",
              "777                                       Mercury      7  2015   \n",
              "\n",
              "                                               QCLabel  \\\n",
              "0                              matter_CHANGES_PHYSICAL   \n",
              "1                                 EARTH_WEATHER_CLOUDS   \n",
              "2                                 EARTH_GEO_FORMATIONS   \n",
              "3             Life_interdependence_ecological features   \n",
              "4                LIFE_HEALTH_DIESEASE_PANDEMICEPIDEMIC   \n",
              "..                                                 ...   \n",
              "773                             energy_SOUND_AMPLITUDE   \n",
              "774                            celestial_SPACEEX_HUMAN   \n",
              "775  Life_functions_features and functions_PLANT_RE...   \n",
              "776             EARTH_human impacts_WHAT_air pollution   \n",
              "777                                              OTHER   \n",
              "\n",
              "                                              Question  subject category  \\\n",
              "0    Which of the following changes occurs as a sol...      NaN    Train   \n",
              "1    When water vapor rises and cools, the liquid w...      NaN    Train   \n",
              "2    Which best describes the characteristics of a ...      NaN      Dev   \n",
              "3    Most of the oxygen in the atmosphere is made b...      NaN      Dev   \n",
              "4    Which aspect of modern Life_could most likely ...      NaN     Test   \n",
              "..                                                 ...      ...      ...   \n",
              "773  As the loudness of a sound wave increases, whi...      NaN     Test   \n",
              "774  In the initial stages of manned space explorat...      NaN    Train   \n",
              "775  During a walk in the woods, Mandy finds a plan...      NaN     Test   \n",
              "776  What is the MAJOR cause of acid rain? (A) smel...      NaN     Test   \n",
              "777  Which invention would a culture living above t...      NaN    Train   \n",
              "\n",
              "          fold  \n",
              "0    Challenge  \n",
              "1         Easy  \n",
              "2         Easy  \n",
              "3    Challenge  \n",
              "4    Challenge  \n",
              "..         ...  \n",
              "773       Easy  \n",
              "774       Easy  \n",
              "775       Easy  \n",
              "776       Easy  \n",
              "777  Challenge  \n",
              "\n",
              "[778 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c94b0e23-d73d-4b80-ae69-2313c289a7de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MCAS_2006_9_30-v1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>matter_CHANGES_PHYSICAL</td>\n",
              "      <td>Which of the following changes occurs as a sol...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mercury_SC_401144</td>\n",
              "      <td>401144</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>EARTH_WEATHER_CLOUDS</td>\n",
              "      <td>When water vapor rises and cools, the liquid w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NCEOGA_2013_8_46</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>North Carolina READY End-of-Grade Assessment</td>\n",
              "      <td>8</td>\n",
              "      <td>2013</td>\n",
              "      <td>EARTH_GEO_FORMATIONS</td>\n",
              "      <td>Which best describes the characteristics of a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_417146</td>\n",
              "      <td>417146</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_interdependence_ecological features</td>\n",
              "      <td>Most of the oxygen in the atmosphere is made b...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mercury_7283833</td>\n",
              "      <td>7283833</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>LIFE_HEALTH_DIESEASE_PANDEMICEPIDEMIC</td>\n",
              "      <td>Which aspect of modern Life_could most likely ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>Mercury_7128853</td>\n",
              "      <td>7128853</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_SOUND_AMPLITUDE</td>\n",
              "      <td>As the loudness of a sound wave increases, whi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>774</th>\n",
              "      <td>Mercury_7245858</td>\n",
              "      <td>7245858</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>celestial_SPACEEX_HUMAN</td>\n",
              "      <td>In the initial stages of manned space explorat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>Mercury_417462</td>\n",
              "      <td>417462</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_functions_features and functions_PLANT_RE...</td>\n",
              "      <td>During a walk in the woods, Mandy finds a plan...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>Mercury_7044065</td>\n",
              "      <td>7044065</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>EARTH_human impacts_WHAT_air pollution</td>\n",
              "      <td>What is the MAJOR cause of acid rain? (A) smel...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>Mercury_7094238</td>\n",
              "      <td>7094238</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>Which invention would a culture living above t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>778 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c94b0e23-d73d-4b80-ae69-2313c289a7de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c94b0e23-d73d-4b80-ae69-2313c289a7de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c94b0e23-d73d-4b80-ae69-2313c289a7de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijn1nIpByb3e"
      },
      "source": [
        "train_features = train_data[\"Question\"]\n",
        "test_features = test_data[\"Question\"]\n",
        "train_labels = train_data[\"QCLabel\"]\n",
        "test_labels = test_data[\"QCLabel\"]\n",
        "val_features = val_data[\"Question\"]\n",
        "val_labels = val_data[\"QCLabel\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prM_km_83khD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0521b5-cccf-4f39-b63d-f4b44acb4605"
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                             106\n",
              "matter_chemistry_periodic table               85\n",
              "matter_chemistry_atomic                       79\n",
              "matter_CHANGES_CHEMICAL                       72\n",
              "science_INFERENCE_observation                 69\n",
              "                                            ... \n",
              "EARTH_GEO_HISTORY                              1\n",
              "science_INFERENCE_INFERENCE                    1\n",
              "FOR_AIRRESISTANCE                              1\n",
              "matter_measurement_UNIT_PH                     1\n",
              "energy_ELEC_ELECTROMAGNETS_energy_devices      1\n",
              "Name: QCLabel, Length: 416, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfhPstXJ03oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55a3c2c-07af-4fe6-e433-aadf3b30af7d"
      },
      "source": [
        "test_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                                          26\n",
              "Life_reproduction_DNA inheritance_inheritance             26\n",
              "Life_functions_features and functions_PLANT_PHOTOSYNTH    22\n",
              "matter_chemistry_atomic                                   21\n",
              "science_INFERENCE_experiment design                       19\n",
              "                                                          ..\n",
              "energy_LIGHT_REFLECT                                       1\n",
              "Life_cycle_animal cycle_BIRD                               1\n",
              "LIFE_HEALTH_DIESEASE_PREVENTION                            1\n",
              "matter_measurement_UNIT_MASS                               1\n",
              "matter_STATES_SOLID                                        1\n",
              "Name: QCLabel, Length: 352, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkyM7gqv3khI"
      },
      "source": [
        "\n",
        "question_answer = train_features.values\n",
        "categories = train_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkS_H_83khL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36982f02-cc09-484d-be84-753603eb6fb2"
      },
      "source": [
        "question_answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card',\n",
              "       'Which of the following statements best describes the role of gravity in the formation of stars? (A) Gravity converts solid matter into gases and light energy. (B) Gravity causes gases and dust particles to condense into spheres. (C) Gravity cools gases and liquids until they become one solid mass. (D) Gravity pushes rocks and dust particles outward from a dense center.',\n",
              "       'A polished metal ball looks very shiny and bright on a sunny day. What makes the ball look shiny? (A) The ball makes light. (B) The ball reflects light. (C) The ball absorbs light and then releases it. (D) The ball absorbs light and keeps it inside.',\n",
              "       ...,\n",
              "       'The amount of which greenhouse gas in the air will increase the most if large forests are cut down to be used for building materials without planting new trees in their place? (1) ozone (2) methane (3) water vapor (4) carbon dioxide',\n",
              "       'The visible light spectrum can be subdivided according to (A) the types of waves. (B) the sizes of particles. (C) a range of colors. (D) a type of energy.',\n",
              "       'A scientist crosses a red-flowered plant with a white-flowered plant, and all offspring have red flowers. What will most likely result if these red-flowered offspring are crossed with white-flowered plants? (A) All of the offspring will have red flowers. (B) All of the offspring will have white flowers. (C) The offspring will have either red or white flowers. (D) The offspring will have neither red nor white flowers.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ian7gSDE3khR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75cf353-5480-461b-aabd-6821f918410a"
      },
      "source": [
        "categories"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matter_properties of objects_TEXT', 'celestial_FEATURES_STELLAR',\n",
              "       'energy_LIGHT_REFLECT', ...,\n",
              "       'Life_functions_features and functions_PLANT_PHOTOSYNTH',\n",
              "       'energy_LIGHT_electromagnetic spectrum',\n",
              "       'Life_reproduction_DNA inheritance_DOMRECESS'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fepGiggpqOQx"
      },
      "source": [
        "# val_features = test_features.values\n",
        "# val_labels = test_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN1zRXMOXwLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ea674e-8fb8-47ce-f75f-010eb784a2df"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "!pip install inflection\n",
        "\n",
        "from bokeh.io import output_file, output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.util.hex import hexbin\n",
        "from bokeh.models import HoverTool\n",
        "from bokeh import colors\n",
        "import inflection\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "ps = PorterStemmer()\n",
        "from gzip import open as gopen\n",
        "from pandas.core.common import flatten\n",
        "import gensim.models.poincare as poincare\n",
        "def get_cleaned_taxonomy(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = ' '.join(value.lower().split(\"_\"))\n",
        "      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n",
        "      cleaned_taxonomy.append( value )\n",
        "  return cleaned_taxonomy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting inflection\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: inflection\n",
            "Successfully installed inflection-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPAl0TNuX6mx"
      },
      "source": [
        "\n",
        "# course_taxonomy\n",
        "\n",
        "poincare_emb_data = get_cleaned_taxonomy(categories)\n",
        "poincare_val = get_cleaned_taxonomy(val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aedZzkBsqEeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc02652e-0781-4e5c-f9ec-1723d5c5bd1e"
      },
      "source": [
        "poincare_emb_data[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'energy light reflect'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ocuHxzCy16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050c4fd0-0c37-4ab8-968f-26381fb8f132"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "wnl = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjDKIFSENir_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe32caa-6da3-4973-ac7d-1ad593f74033"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-large-nli-stsb-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.24G/1.24G [01:10<00:00, 17.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_model = SentenceTransformer('bert-large-nli-stsb-mean-tokens')"
      ],
      "metadata": {
        "id": "0XlCt0Oicof1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdBbsrO9zp2p"
      },
      "source": [
        "# taxonomy_vectors = []\n",
        "taxonomy_vectors = model.encode(poincare_emb_data)\n",
        "# taxonomy_vectors = np.vstack(taxonomy_vectors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJUSQmOq7v8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15cc5b9c-0950-4051-c64e-fea92622de47"
      },
      "source": [
        "taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "taxonomy_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5597, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTlCYX9Q34JG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2247cef-e627-4ed3-c516-1fcffc180dc2"
      },
      "source": [
        "# taxonomy_vectors_val = []\n",
        "# for feature in poincare_val:\n",
        "taxonomy_vectors_val = model.encode(poincare_val)\n",
        "taxonomy_vectors_val = np.vstack(taxonomy_vectors_val)\n",
        "taxonomy_vectors_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(778, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p834oM1Pzzu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01534f0a-7638-4347-d500-10257c36432e"
      },
      "source": [
        "set(train_data[\"Question\"].values).intersection(set(test_data[\"Question\"].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ZeuHc63khU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c499d288-d483-4244-f5dc-65f3b20e1459"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in question_answer:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card\n",
            "Token IDs: tensor([  101,  1037,  3076,  2003,  2356,  2000,  3288,  2242,  2008,  5683,\n",
            "         5931,  2000,  2465,  1012,  2029,  2052,  2022,  2190,  2005,  2032,\n",
            "         2000,  3288,  1029,  1006,  1037,  1007, 10005,  1006,  1038,  1007,\n",
            "         7720,  1006,  1039,  1007,  5472, 23298,  1006,  1040,  1007,  6202,\n",
            "         4003,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VjkhiN3pAfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9aebf8-e47a-46e9-e794-787f793065b7"
      },
      "source": [
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "for sent in val_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card\n",
            "Token IDs: tensor([  101,  1037,  3076,  2003,  2356,  2000,  3288,  2242,  2008,  5683,\n",
            "         5931,  2000,  2465,  1012,  2029,  2052,  2022,  2190,  2005,  2032,\n",
            "         2000,  3288,  1029,  1006,  1037,  1007, 10005,  1006,  1038,  1007,\n",
            "         7720,  1006,  1039,  1007,  5472, 23298,  1006,  1040,  1007,  6202,\n",
            "         4003,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDW74Ny3khj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12ba2d5-598d-4d81-aa00-b8c111488e08"
      },
      "source": [
        "num_classes = len(list(set(categories)))\n",
        "num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaLk5Ab3khl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "train_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n",
        "val_poincare_tensor = torch.tensor(taxonomy_vectors_val,dtype=torch.float)\n",
        "\n",
        "val_dataset = TensorDataset(input_ids_val,attention_masks_val,val_poincare_tensor)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, train_poincare_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lTinod3kho"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vduf9fOMviK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545be752-0454-4023-90f1-859d4af8aa3a"
      },
      "source": [
        "# !pip install transformers==2.8.0\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2wp8WlEi9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7108cfd2-a7cb-44bd-a4c4-ab55f6a8199f"
      },
      "source": [
        "set(question_answer).intersection(set(test_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6jdKp0uhO3"
      },
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "\n",
        "from tqdm import tqdm\n",
        "import geoopt\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "cos_label = nn.CosineSimilarity(dim=1, eps=1e-5)\n",
        "\n",
        "dist = torch.nn.PairwiseDistance(p=2.0, eps=1e-06)\n",
        "nn.PairwiseDistance(p=2)\n",
        "class MHSA(nn.Module):\n",
        "  def __init__(self,\n",
        "         emb_dim,\n",
        "         kqv_dim,\n",
        "         num_heads=2):\n",
        "    super(MHSA, self).__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    self.kqv_dim = kqv_dim\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.w_k = nn.Linear(emb_dim, kqv_dim * num_heads, bias=False)\n",
        "    self.w_q = nn.Linear(emb_dim, kqv_dim * num_heads, bias=False)\n",
        "    self.w_v = nn.Linear(emb_dim, kqv_dim * num_heads, bias=False)\n",
        "    self.w_out = nn.Linear(kqv_dim * num_heads, emb_dim)\n",
        "\n",
        "  def forward(self, query, key, value):\n",
        "    # print(\"query\",query.shape)\n",
        "    b, t = query.shape\n",
        "    e = self.kqv_dim\n",
        "    h = self.num_heads\n",
        "    keys = self.w_k(key).view(b, h, e)\n",
        "    values = self.w_v(value).view(b, h, e)\n",
        "    queries = self.w_q(query).view(b, h, e)\n",
        "\n",
        "    # keys = keys.transpose(2, 1)\n",
        "    # queries = queries.transpose(2, 1)\n",
        "    # values = values.transpose(2, 1)\n",
        "\n",
        "    dot = queries @ keys.transpose(2, 1)  #(b*h*e) @ (b*e*h)\n",
        "    dot = dot / np.sqrt(e)  # (b*h*h)\n",
        "    dot = F.softmax(dot, dim=2)\n",
        "\n",
        "    out = dot @ values   # (b*h*h) @ (b*h*e) = (b*h*e)\n",
        "    out = out.contiguous().view(b, h * e)\n",
        "    out = self.w_out(out)\n",
        "    return out\n",
        "# Neural Classifierwork\n",
        "\n",
        "# Discussion TODOS\n",
        "# try hierarhical interaction (TODO)\n",
        "\n",
        "# try bringing in modalities (image, or video)\n",
        "\n",
        "# Go from classical algorithm -> deep learning\n",
        "\n",
        "class MulticlassClassifier(nn.Module):\n",
        "    def __init__(self,bert_model_path):\n",
        "        super(MulticlassClassifier,self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=False)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(768, 1024)\n",
        "        self.fc2 = nn.Linear(576, 1024)\n",
        "        self.fc3 = nn.Linear(2048,1024)\n",
        "        self.multi_head_attention = MHSA(1024, 512,8)\n",
        "        self.multihead_attn = torch.nn.MultiheadAttention(embed_dim = 1024,  num_heads = 16, batch_first=True)\n",
        "\n",
        "\n",
        "    def forward(self,tokens,masks, targets=None, skip_attention=False):\n",
        "        # print(\"tokens\", tokens.shape)\n",
        "        outputs = self.bert(tokens, attention_mask=masks)[2]\n",
        "        # outputs[2] = outputs[2].permute(0,2,1)\n",
        "        output_1 = outputs[-1].permute(1,0,2)\n",
        "        # print(outputs[1].shape,outputs[0].shape)\n",
        "        output_1 = torch.mean(output_1, dim=0)\n",
        "        # output_2 = outputs[-2].permute(1,0,2)\n",
        "        # output_2 = torch.mean(output_2, dim=0)\n",
        "        # print(\"output_2\", output_2.shape, output_1.shape)\n",
        "        pooled_output = outputs[-1] #output_1 # torch.cat((output_1, output_2), dim=1)\n",
        "        # print(\"pooled_output\", pooled_output.shape)\n",
        "        x = self.fc1(pooled_output)\n",
        "        # print(\"x shape\",x.shape)\n",
        "        targets_curr_batch = []\n",
        "        for index_1, input_x in enumerate(x):\n",
        "            # print(input_x.shape, torch.mean(input_x,dim=0).shape)\n",
        "            distance = cos_label(torch.mean(input_x,dim=0).reshape(1,-1), unique_poincare_tensor)\n",
        "            distances,indices = torch.topk(distance,1,largest=True)\n",
        "\n",
        "            target_distances = (F.normalize(unique_poincare_tensor[indices],p=2,dim=1) - F.normalize(unique_poincare_tensor,p=2,dim=1)).pow(2).sum(1) #cos_label(unique_poincare_tensor[indices].reshape(1,-1), unique_poincare_tensor)\n",
        "            distances,indices = torch.topk(target_distances,5,largest=False)\n",
        "            targets_curr_batch.append(unique_poincare_tensor[indices].reshape(1,5,1024))\n",
        "            # print(\"here\")\n",
        "        # print(len(targets_curr_batch))\n",
        "        targets_batch = torch.cat(targets_curr_batch, dim=0)\n",
        "        # print(\"targets_batch\",targets_batch.shape)\n",
        "        attn_output, attn_output_weights = self.multihead_attn(targets_batch, x, x)\n",
        "        attn_out = torch.mean(attn_output,dim=1)\n",
        "        # x = torch.cat((torch.mean(x,dim=1),attn_out),1)\n",
        "\n",
        "\n",
        "        # print(\"X shape\",x.shape)\n",
        "        return attn_out\n",
        "\n",
        "class MyHingeLoss(torch.nn.Module):\n",
        "    def __init__(self, margin):\n",
        "        super(MyHingeLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        loss=0\n",
        "        for i in range(len(output)):\n",
        "            v_image = F.normalize(output[i],p=2,dim=0)\n",
        "            t_label = F.normalize(target[i],p=2,dim=0)\n",
        "\n",
        "            for i in range(5):\n",
        "                j = randint(0, len(output)-1)\n",
        "                while j == i:\n",
        "                    j = randint(0, len(output)-1)\n",
        "                t_j = F.normalize(target[j],p=2,dim=0)\n",
        "                loss+= torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n",
        "        return loss / (len(output)*5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHYyjxMDIx2U"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KLfgh1K44qY"
      },
      "source": [
        "# Training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tmAMlw3khr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9fdca86a07c34ab4b18b56ae2d30ceea",
            "29faee0296504936ae99dc0259c31637",
            "35abecc0c0064463a31d3c544563856e",
            "193b8ecf25984135adc70b2b8202b41d",
            "d324e5d8e7cb40a48ba0a278c55dfaf3",
            "0a5afebaf86047ebba37058574e2e00e",
            "e87f32991f954e7c8aec7e3ed3f05444",
            "8842a6ae612346d1865d537ccfa6565f",
            "988964ecd37d471f893d7523bb040915",
            "fd6ce4cfe5bd451b9c6126cdbc18d6d1",
            "1afe70289cb04d4f9263e5de1c3d882a",
            "f995a5f98f5f4c2a983c2f83354daa9e",
            "bff1c6dff7a747c6a58011942070ff34",
            "8732dd7ad5c7498b883cc2d0876b4358",
            "f20360be6f4e46399a6fe3d93230ff3f",
            "8f2e223875cc4682b9cf50b1a2bea249",
            "3a85e569614d4a05949d779a1465c9f7",
            "963cec7dc7364f21b4420c6b17d1d6a7",
            "e8f39618be3b42d48df9d96a49c7c427",
            "bbe48b722d80495aa01347b73cb6bb2f",
            "a3692f6266014db198f42be50f7ec10c",
            "f2cb16a60e1a44dd87d62f3d1a59e4fb"
          ]
        },
        "outputId": "b1668260-c746-4215-bae9-94fe98dd9c1e"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# Loads BertModel, the pretrained BERT model with a single \n",
        "model = MulticlassClassifier('bert-base-uncased')\n",
        "# model.load_state_dict(torch.load('model_euclidean_SENT_BERT_cos_1/model_weights'))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fdca86a07c34ab4b18b56ae2d30ceea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f995a5f98f5f4c2a983c2f83354daa9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MulticlassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=768, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=576, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "  (multi_head_attention): MHSA(\n",
              "    (w_k): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "    (w_q): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "    (w_v): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "    (w_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "  )\n",
              "  (multihead_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4paz_8iTZ9o"
      },
      "source": [
        "# mobius_params = []\n",
        "# bert_params = []\n",
        "\n",
        "# def mobius_params():\n",
        "#   for param in model.named_parameters():\n",
        "#     if 'fc' in param[0]:\n",
        "#       yield param[1]\n",
        "# def bert_params():\n",
        "#   for param in model.named_parameters():\n",
        "#     if 'bert' in param[0]:\n",
        "#       yield param[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQ2Y9Jb3kht"
      },
      "source": [
        "optimizer_1 = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "# optimizer_2 = radam_.RiemannianAdam(mobius_params(), lr=0.01, stabilize=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrYqErOD3khx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8f224a-6378-4331-e61b-31a001c04fe8"
      },
      "source": [
        "len(train_dataloader) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWVSE9LM3kh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2717a69f-d0da-4e2e-beb1-0d32e27bdebb"
      },
      "source": [
        "1935 * 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer_1, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Function to calculate the accuracy of our predictions vs labels\n",
        "# def flat_accuracy(preds, labels):\n",
        "#     pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#     labels_flat = labels.flatten()\n",
        "#     return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "source": [
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsInxVoqbsFW"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di68jXK5WaYr"
      },
      "source": [
        "criterion = MyHingeLoss(0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRcFqo9Ya6h6"
      },
      "source": [
        "\n",
        "# course_taxonomy\n",
        "train_labels = list(set(train_data[\"QCLabel\"].values))\n",
        "emb_data_train = get_cleaned_taxonomy(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee04c8fd-26eb-4eb2-b989-ffd325a6b892",
        "id": "R7YLX-ZCa6h7"
      },
      "source": [
        "# taxonomy_vectors = []\"\"\n",
        "taxonomy_vectors = sent_model.encode(emb_data_train)\n",
        "taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "taxonomy_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(416, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQJ8KR5na6h7"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "unique_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_poincare_tensor = unique_poincare_tensor.to(device)"
      ],
      "metadata": {
        "id": "vFKXxjBq7u66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LhAy2hZ3kh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7264b62d-2ede-4f93-db53-26676a17f766"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import f1_score\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=6, verbose=True)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad() \n",
        "        optimizer_1.zero_grad()       \n",
        "\n",
        "        logits = model(b_input_ids, \n",
        "                             b_input_mask)\n",
        "        \n",
        "        loss = criterion.forward(logits,b_labels)\n",
        "\n",
        "  \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer_1.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_f1 = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "          logits = model(b_input_ids, \n",
        "                              b_input_mask)\n",
        "          \n",
        "        loss = criterion(logits,b_labels)\n",
        "\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy().round()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        # total_eval_f1 += f1_score(label_ids,logits, average='macro')\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    # avg_val_accuracy = total_eval_f1 / len(validation_dataloader)\n",
        "    # print(\"  f1score: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break  \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3\"\n",
        "    !mv model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3 \"/content/drive/My Drive/research_lo_content_taxonomy_classification/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:34.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (inf --> 0.013559).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:10\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 2 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:43.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:17.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:29\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.013559 --> 0.012606).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:09\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 3 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.012606 --> 0.011575).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:09\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 4 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.011575 --> 0.011035).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:09\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 5 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.011035 --> 0.010347).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:09\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 6 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:36.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:43.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:29\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.010347 --> 0.009837).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:09\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 7 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:34.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 1 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 8 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 2 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 9 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 3 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 10 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:34.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:43.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:29\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.009837 --> 0.009477).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:09\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 11 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 1 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 12 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 2 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 13 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:34.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:09.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:16.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:28\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 3 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 14 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 4 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 15 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 5 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 16 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.009477 --> 0.009360).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:08\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 17 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:14.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.009360 --> 0.008852).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:09\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 18 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:14.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 1 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 19 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:14.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 2 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 20 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:34.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:14.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 3 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 21 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:27\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 4 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 22 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:14.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:26\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 5 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:07\n",
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n",
            "\n",
            "======== Epoch 23 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:35.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    175.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    175.    Elapsed: 0:02:13.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:26\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 6 out of 6\n",
            "Early stopping\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:01:11 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDWFZVminDiI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "7dad5fc2-f7e6-4491-e238-cbfd2708ce02"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1           2.51e-02     1.36e-02       0:02:27         0:00:10\n",
              "2           1.14e-02     1.26e-02       0:02:29         0:00:09\n",
              "3           8.67e-03     1.16e-02       0:02:28         0:00:09\n",
              "4           7.65e-03     1.10e-02       0:02:28         0:00:09\n",
              "5           6.78e-03     1.03e-02       0:02:28         0:00:09\n",
              "6           6.29e-03     9.84e-03       0:02:29         0:00:09\n",
              "7           5.92e-03     9.99e-03       0:02:28         0:00:07\n",
              "8           6.07e-03     9.97e-03       0:02:28         0:00:07\n",
              "9           5.60e-03     1.06e-02       0:02:28         0:00:07\n",
              "10          5.26e-03     9.48e-03       0:02:29         0:00:09\n",
              "11          5.00e-03     9.94e-03       0:02:28         0:00:07\n",
              "12          5.00e-03     9.63e-03       0:02:28         0:00:07\n",
              "13          4.95e-03     1.00e-02       0:02:28         0:00:07\n",
              "14          4.99e-03     9.56e-03       0:02:27         0:00:07\n",
              "15          4.73e-03     9.86e-03       0:02:27         0:00:07\n",
              "16          4.78e-03     9.36e-03       0:02:27         0:00:08\n",
              "17          4.85e-03     8.85e-03       0:02:27         0:00:09\n",
              "18          4.55e-03     9.45e-03       0:02:27         0:00:07\n",
              "19          4.67e-03     9.74e-03       0:02:27         0:00:07\n",
              "20          4.59e-03     8.92e-03       0:02:27         0:00:07\n",
              "21          4.72e-03     9.61e-03       0:02:27         0:00:07\n",
              "22          4.46e-03     9.34e-03       0:02:26         0:00:07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3f55493-db7d-49e6-bc88-49113f739cf3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.51e-02</td>\n",
              "      <td>1.36e-02</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.14e-02</td>\n",
              "      <td>1.26e-02</td>\n",
              "      <td>0:02:29</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.67e-03</td>\n",
              "      <td>1.16e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.65e-03</td>\n",
              "      <td>1.10e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.78e-03</td>\n",
              "      <td>1.03e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.29e-03</td>\n",
              "      <td>9.84e-03</td>\n",
              "      <td>0:02:29</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.92e-03</td>\n",
              "      <td>9.99e-03</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.07e-03</td>\n",
              "      <td>9.97e-03</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.60e-03</td>\n",
              "      <td>1.06e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.26e-03</td>\n",
              "      <td>9.48e-03</td>\n",
              "      <td>0:02:29</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.00e-03</td>\n",
              "      <td>9.94e-03</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5.00e-03</td>\n",
              "      <td>9.63e-03</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.95e-03</td>\n",
              "      <td>1.00e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4.99e-03</td>\n",
              "      <td>9.56e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4.73e-03</td>\n",
              "      <td>9.86e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4.78e-03</td>\n",
              "      <td>9.36e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4.85e-03</td>\n",
              "      <td>8.85e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4.55e-03</td>\n",
              "      <td>9.45e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4.67e-03</td>\n",
              "      <td>9.74e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4.59e-03</td>\n",
              "      <td>8.92e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.72e-03</td>\n",
              "      <td>9.61e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.46e-03</td>\n",
              "      <td>9.34e-03</td>\n",
              "      <td>0:02:26</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3f55493-db7d-49e6-bc88-49113f739cf3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3f55493-db7d-49e6-bc88-49113f739cf3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3f55493-db7d-49e6-bc88-49113f739cf3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RACcsko3kh_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "5517a9cf-ec62-4ee8-ec17-ee408c5f9b1e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1           2.51e-02     1.36e-02       0:02:27         0:00:10\n",
              "2           1.14e-02     1.26e-02       0:02:29         0:00:09\n",
              "3           8.67e-03     1.16e-02       0:02:28         0:00:09\n",
              "4           7.65e-03     1.10e-02       0:02:28         0:00:09\n",
              "5           6.78e-03     1.03e-02       0:02:28         0:00:09\n",
              "6           6.29e-03     9.84e-03       0:02:29         0:00:09\n",
              "7           5.92e-03     9.99e-03       0:02:28         0:00:07\n",
              "8           6.07e-03     9.97e-03       0:02:28         0:00:07\n",
              "9           5.60e-03     1.06e-02       0:02:28         0:00:07\n",
              "10          5.26e-03     9.48e-03       0:02:29         0:00:09\n",
              "11          5.00e-03     9.94e-03       0:02:28         0:00:07\n",
              "12          5.00e-03     9.63e-03       0:02:28         0:00:07\n",
              "13          4.95e-03     1.00e-02       0:02:28         0:00:07\n",
              "14          4.99e-03     9.56e-03       0:02:27         0:00:07\n",
              "15          4.73e-03     9.86e-03       0:02:27         0:00:07\n",
              "16          4.78e-03     9.36e-03       0:02:27         0:00:08\n",
              "17          4.85e-03     8.85e-03       0:02:27         0:00:09\n",
              "18          4.55e-03     9.45e-03       0:02:27         0:00:07\n",
              "19          4.67e-03     9.74e-03       0:02:27         0:00:07\n",
              "20          4.59e-03     8.92e-03       0:02:27         0:00:07\n",
              "21          4.72e-03     9.61e-03       0:02:27         0:00:07\n",
              "22          4.46e-03     9.34e-03       0:02:26         0:00:07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7118d14b-b848-41b7-8195-5b014572d9b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.51e-02</td>\n",
              "      <td>1.36e-02</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.14e-02</td>\n",
              "      <td>1.26e-02</td>\n",
              "      <td>0:02:29</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.67e-03</td>\n",
              "      <td>1.16e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.65e-03</td>\n",
              "      <td>1.10e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.78e-03</td>\n",
              "      <td>1.03e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.29e-03</td>\n",
              "      <td>9.84e-03</td>\n",
              "      <td>0:02:29</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.92e-03</td>\n",
              "      <td>9.99e-03</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.07e-03</td>\n",
              "      <td>9.97e-03</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.60e-03</td>\n",
              "      <td>1.06e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.26e-03</td>\n",
              "      <td>9.48e-03</td>\n",
              "      <td>0:02:29</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.00e-03</td>\n",
              "      <td>9.94e-03</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5.00e-03</td>\n",
              "      <td>9.63e-03</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.95e-03</td>\n",
              "      <td>1.00e-02</td>\n",
              "      <td>0:02:28</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4.99e-03</td>\n",
              "      <td>9.56e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4.73e-03</td>\n",
              "      <td>9.86e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4.78e-03</td>\n",
              "      <td>9.36e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4.85e-03</td>\n",
              "      <td>8.85e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4.55e-03</td>\n",
              "      <td>9.45e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4.67e-03</td>\n",
              "      <td>9.74e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4.59e-03</td>\n",
              "      <td>8.92e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.72e-03</td>\n",
              "      <td>9.61e-03</td>\n",
              "      <td>0:02:27</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.46e-03</td>\n",
              "      <td>9.34e-03</td>\n",
              "      <td>0:02:26</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7118d14b-b848-41b7-8195-5b014572d9b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7118d14b-b848-41b7-8195-5b014572d9b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7118d14b-b848-41b7-8195-5b014572d9b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(10000000000000000000000000):\n",
        "    i=j"
      ],
      "metadata": {
        "id": "4nk_J8VYtknD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5TicdiP3kiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "e83844d3-168f-450b-e7c7-8cac25f44f46"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbiTDpVv3kiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6efa3a5b-6c24-4394-e61e-0036066de56c"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "output_dir = 'model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/vocab.txt',\n",
              " 'model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/special_tokens_map.json',\n",
              " 'model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2UQ29a3kiI"
      },
      "source": [
        "# !pip install joblib\n",
        "# import joblib\n",
        "# joblib.dump(LE, \"label_encoder\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F5PxZm9vAOI"
      },
      "source": [
        "import json\n",
        "torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlb0IpVJO1XQ"
      },
      "source": [
        "# with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n",
        "#     json.dump(model.config, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpGY8vSDI6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87be2a63-69bb-48aa-eec0-6d0d9d515421"
      },
      "source": [
        "!zip -r model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3.zip model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3\n",
        "# files.download('model_euclidean_1.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/ (stored 0%)\n",
            "updating: model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/model_weights (deflated 8%)\n",
            "updating: model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/special_tokens_map.json (deflated 40%)\n",
            "updating: model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/vocab.txt (deflated 53%)\n",
            "updating: model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3/tokenizer_config.json (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r  model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3 \"/content/drive/MyDrive/research_lo_content_taxonomy_classification/\""
      ],
      "metadata": {
        "id": "A0L5bUuWInJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp   model_euclidean_SENT_BERT_cos_QC_attention_minus_hard_neg_V3.zip \"/content/drive/MyDrive/research_lo_content_taxonomy_classification/\""
      ],
      "metadata": {
        "id": "_vygUpCvIuMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA1GBuz-03Sp"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKdRT1UUz4vC"
      },
      "source": [
        "# Run this cell and next if you want to test on LO zero shot setting If you want to test on ARC skip them.\n",
        "import pandas as pd\n",
        "lo_data = pd.read_csv(\"what_you_learnt_lo_labelled.csv\", delimiter=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2kDnBDF0I3e"
      },
      "source": [
        "test_features = lo_data[\"learning_objectives\"].values\n",
        "labels = lo_data[\"taxonomy\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvFDCDIxKDOf"
      },
      "source": [
        "# !zip -r label_encoder_categorized_reduced.zip label_encoder\n",
        "# files.download('label_encoder_categorized_reduced.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4178_yLFMWmx"
      },
      "source": [
        "# run from this cell to test on ARC data\n",
        "test_features = test_features.values\n",
        "labels = test_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpmBJuIC2nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db8d65e-0ce6-4ae2-81ab-6d064abaeac2"
      },
      "source": [
        "test_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Robert is a fisherman who wants to find a way to catch more fish. He decided to try different sizes of hooks. Robert caught 4 catfish, 3 trout, and 7 perch while using worms for bait. Which is the independent (manipulated) variable in Robert's investigation? (A) type of bait (B) size of hook (C) type of fish caught (D) number of fish caught\",\n",
              "       'Which of these factors causes water to evaporate the fastest? (A) high temperatures (B) high humidity (C) slow winds (D) slow runoff',\n",
              "       'Which statement is true about the particles of a liquid compared to the particles of a gas? (A) Particles of a liquid are a slower and further apart. (B) Particles of a liquid are faster and farther apart. (C) Particles of a liquid are slower and closer together. (D) Particles of a liquid are faster and closer together.',\n",
              "       ...,\n",
              "       'Which of these is not an inherited trait in humans? (A) height (B) hair color (C) skin color (D) intelligence',\n",
              "       'In order to survive, all animals need (A) heat, water, and soil (B) sunlight, soil, and heat (C) sunlight, air, and food (D) food, water, and air',\n",
              "       'Scientists claim that the continents of South America and Africa were once a single landmass. All of the following observations support this claim except (A) the mountains on these continents have similar rocks of the same age. (B) these continents appear to fit together like the pieces of a puzzle. (C) similar fish live in the ocean off the coasts of these continents. (D) the same kinds of fossils have been found on these continents.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRZ54gFokNh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15433d16-5fab-4b77-ce48-dc7edf394982"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['science_INFERENCE_experiment design',\n",
              "       'matter_Change of state_EVAPoration', 'matter_chemistry_atomic',\n",
              "       ..., 'Life_reproduction_DNA inheritance_inheritance',\n",
              "       'Life_functions_FUNCT_animalESS', 'EARTH_INNER_PLATE_CONTDRIFT'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohj1x7frQJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa651770-2e26-4920-c738-f86cc6a0cf72"
      },
      "source": [
        "len(list(set(labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVWhJ4o0YxZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af757b1c-34d9-40b8-efc3-0bbd2a1ee35c"
      },
      "source": [
        "len(list(set(train_data[\"QCLabel\"].values)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oww-EQlFbQWL"
      },
      "source": [
        "def get_cleaned_taxonomy_lo(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = ' '.join(value.lower().split(\">>\"))\n",
        "      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n",
        "      cleaned_taxonomy.append( value )\n",
        "  return cleaned_taxonomy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXLemgwUbS_r"
      },
      "source": [
        "#when testing for Lo data\n",
        "test_labels = list(set(lo_data[\"taxonomy\"].values))\n",
        "emb_data_test = get_cleaned_taxonomy_lo(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91PVN-_ye8Aq"
      },
      "source": [
        "import pandas as pd\n",
        "targets_1 = pd.read_csv(\"targets_ARC.csv\")\n",
        "targets = targets_1[\"targets\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjinn0gXkNuP"
      },
      "source": [
        "# When testing for ARC data\n",
        "# course_taxonomy\n",
        "test_labels = targets\n",
        "emb_data_test = get_cleaned_taxonomy(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wYoTCt12Wkf"
      },
      "source": [
        "targets = np.array(targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp86I3HkhvwB",
        "outputId": "f98e046c-1316-403d-d9f3-84c58ebcb744"
      },
      "source": [
        "len(emb_data_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0gGbZbEgS_y"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sent_model = SentenceTransformer('bert-large-nli-stsb-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wl0RJ3SSW4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f780ce20-ffb9-419e-94aa-6e95379ebad6"
      },
      "source": [
        "# taxonomy_vectors = []\"\"\n",
        "taxonomy_vectors = sent_model.encode(emb_data_test)\n",
        "taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "taxonomy_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nso39n1N_po_"
      },
      "source": [
        "# model = MulticlassClassifier('bert-base-uncased')\n",
        "# model.load_state_dict(torch.load('model_euclidean_SENT_BERT_cos_QC_attention_V3/model_weights'))\n",
        "# model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe4qYkV2C4fX"
      },
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "# labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n",
        "\n",
        "# Create the DataLoader.\n",
        "# prediction_data = TensorDataset(test_input_ids, test_attention_masks, test_poincare_tensor)\n",
        "# prediction_sampler = SequentialSampler(prediction_data)\n",
        "# prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNdlve8AJcCO"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6aMBHkAQZjT"
      },
      "source": [
        "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "def dist_without_grad( u, v):\n",
        "  sqdist = torch.sum((u - v) ** 2, dim=-1)\n",
        "  squnorm = torch.sum(u ** 2, dim=-1)\n",
        "  sqvnorm = torch.sum(v ** 2, dim=-1)\n",
        "  x = 1 + 2 * sqdist / ((1 - squnorm) * (1 - sqvnorm)) + 1e-7\n",
        "  z = torch.sqrt(x ** 2 - 1)\n",
        "  return torch.log(x + z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBN7kS5ebZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13bc7fc-bb91-464e-9682-48de0e43ac69"
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1400"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe0otXOPg7z0"
      },
      "source": [
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j0Q68gjYl8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9167a808-3595-4246-9fd5-cd5006121e21"
      },
      "source": [
        "test_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352,)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA-1RvWKfV7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d54a42-43ae-409f-9b5f-d09ed362185f"
      },
      "source": [
        "test_poincare_tensor.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([352, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPCktQT9DVT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7c44cf-8c31-4290-d69b-47887f8d2c02"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "input_ids = test_input_ids.to('cuda')\n",
        "attention_masks = test_attention_masks.to('cuda')\n",
        "test_poincare_tensor = test_poincare_tensor.to('cuda')\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "for input_id,attention_mask in zip(input_ids, attention_masks):\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_id.reshape(1,-1),attention_mask.reshape(1,-1))\n",
        "    \n",
        "  distances = cos(outputs,test_poincare_tensor)#torch.topk(cos(outputs,test_poincare_tensor),20,largest=True)\n",
        "  distances,indices = torch.topk(distances,5,largest=True)\n",
        "  predictions.append(targets[indices.cpu().numpy()])\n",
        "print(len(predictions))\n",
        "\n",
        "\n",
        "print('    DONE.')\n",
        "# predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 1,400 test sentences...\n",
            "1400\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5wj2gXYFkrQ"
      },
      "source": [
        "# labels=test_data['QCLabel'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjon8k2B2GHc"
      },
      "source": [
        "targets_1 = pd.read_csv(\"targets_ARC.csv\")\n",
        "\n",
        "labels = targets_1[\"targets\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOt8hvs-CZfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb1f06e-2e33-4b90-d181-6836d3c5f5f0"
      },
      "source": [
        "from sklearn .preprocessing import LabelEncoder\n",
        "LE= LabelEncoder()\n",
        "labels = LE.fit_transform(labels)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([107, 168,  77, 183, 281, 254, 142, 249,  81, 103, 312, 299, 171,\n",
              "       337, 179, 208, 285, 155, 335, 342, 137, 243, 188,  69, 217, 273,\n",
              "        16, 344,  88, 316, 132,  85, 118,  20, 244, 125, 348, 332, 164,\n",
              "       280,  33, 256, 251, 100, 216, 278, 279, 287,   3, 204,  71, 269,\n",
              "       334, 196,  72, 158,   7, 172, 173, 325, 297,  11, 295, 195, 180,\n",
              "        89, 308,  48, 274,  43, 264, 139, 104, 230,  95, 241, 154, 231,\n",
              "        37,  87, 229, 145,  75, 190, 286, 234, 101,  51, 199,  68, 283,\n",
              "        29, 112, 326, 184, 296, 162, 189, 343, 303,  82, 201, 122,  73,\n",
              "       108, 141,   6,  14, 257,  97, 330, 111,  39, 175, 213, 300,  67,\n",
              "       311, 255, 152, 338, 349,  46, 130, 347, 177, 176, 320, 246, 220,\n",
              "         1, 110, 121, 271, 277, 282,  53, 310, 322, 319, 307, 170,  98,\n",
              "       167, 236, 309, 346, 131,  25, 209, 315,  49, 293,  52, 259, 106,\n",
              "       181, 268, 267, 197, 126,  38,  34, 317,  83, 219, 266, 265, 245,\n",
              "        94, 305, 324, 124, 105,  22,   2, 214, 146, 260,  80, 138, 238,\n",
              "       331, 123, 233, 345, 192, 228, 115, 207, 288, 341, 144, 247, 242,\n",
              "       148, 151,  64, 327, 136,  10,  78, 150, 329, 163,  21, 153, 147,\n",
              "       321, 198,  63, 248,   9,  91, 222, 211,  79,  26, 302,  90, 340,\n",
              "       140,  18,  96, 294, 127,  30,  66, 284,  13,  36, 262, 159,  62,\n",
              "        60,  19, 350, 252,  28,   5, 232, 298, 275, 304, 215, 119,  99,\n",
              "       133, 117, 351,  15,  44, 221, 250, 272,  86,   8, 339, 191,  12,\n",
              "       227, 240,  92, 193, 174,  24,  41, 235, 289, 314, 333, 291, 182,\n",
              "       313, 186,  57,  70,  59, 113, 160, 161, 128,  76, 178, 149, 135,\n",
              "       116, 224,   4, 166, 102, 276,  27,  23, 318,  56,  84,  50, 187,\n",
              "       200, 237, 143,  35, 239, 203, 223, 206, 114,  47, 323,  45, 185,\n",
              "       134,  17,  65, 328, 253, 205, 292, 263,  40, 109, 258, 225,  93,\n",
              "       157, 301, 212, 120,  74, 336,  55, 306, 270, 165, 290, 202,   0,\n",
              "       194, 210, 226,  58, 261,  54,  61, 218,  31,  32,  42, 169, 156,\n",
              "       129])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adb4gTNgGKUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3abccd-f822-4129-f996-bc559d9f1bf9"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([107, 168,  77, 183, 281, 254, 142, 249,  81, 103, 312, 299, 171,\n",
              "       337, 179, 208, 285, 155, 335, 342, 137, 243, 188,  69, 217, 273,\n",
              "        16, 344,  88, 316, 132,  85, 118,  20, 244, 125, 348, 332, 164,\n",
              "       280,  33, 256, 251, 100, 216, 278, 279, 287,   3, 204,  71, 269,\n",
              "       334, 196,  72, 158,   7, 172, 173, 325, 297,  11, 295, 195, 180,\n",
              "        89, 308,  48, 274,  43, 264, 139, 104, 230,  95, 241, 154, 231,\n",
              "        37,  87, 229, 145,  75, 190, 286, 234, 101,  51, 199,  68, 283,\n",
              "        29, 112, 326, 184, 296, 162, 189, 343, 303,  82, 201, 122,  73,\n",
              "       108, 141,   6,  14, 257,  97, 330, 111,  39, 175, 213, 300,  67,\n",
              "       311, 255, 152, 338, 349,  46, 130, 347, 177, 176, 320, 246, 220,\n",
              "         1, 110, 121, 271, 277, 282,  53, 310, 322, 319, 307, 170,  98,\n",
              "       167, 236, 309, 346, 131,  25, 209, 315,  49, 293,  52, 259, 106,\n",
              "       181, 268, 267, 197, 126,  38,  34, 317,  83, 219, 266, 265, 245,\n",
              "        94, 305, 324, 124, 105,  22,   2, 214, 146, 260,  80, 138, 238,\n",
              "       331, 123, 233, 345, 192, 228, 115, 207, 288, 341, 144, 247, 242,\n",
              "       148, 151,  64, 327, 136,  10,  78, 150, 329, 163,  21, 153, 147,\n",
              "       321, 198,  63, 248,   9,  91, 222, 211,  79,  26, 302,  90, 340,\n",
              "       140,  18,  96, 294, 127,  30,  66, 284,  13,  36, 262, 159,  62,\n",
              "        60,  19, 350, 252,  28,   5, 232, 298, 275, 304, 215, 119,  99,\n",
              "       133, 117, 351,  15,  44, 221, 250, 272,  86,   8, 339, 191,  12,\n",
              "       227, 240,  92, 193, 174,  24,  41, 235, 289, 314, 333, 291, 182,\n",
              "       313, 186,  57,  70,  59, 113, 160, 161, 128,  76, 178, 149, 135,\n",
              "       116, 224,   4, 166, 102, 276,  27,  23, 318,  56,  84,  50, 187,\n",
              "       200, 237, 143,  35, 239, 203, 223, 206, 114,  47, 323,  45, 185,\n",
              "       134,  17,  65, 328, 253, 205, 292, 263,  40, 109, 258, 225,  93,\n",
              "       157, 301, 212, 120,  74, 336,  55, 306, 270, 165, 290, 202,   0,\n",
              "       194, 210, 226,  58, 261,  54,  61, 218,  31,  32,  42, 169, 156,\n",
              "       129])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbohQzAhlYRN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azkCfK-bCoXd"
      },
      "source": [
        "final_predictions = []\n",
        "for prediction in predictions:\n",
        "  final_predictions.append(LE.transform(prediction))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQrlczKxMwzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3a1cbd-b435-4dad-fd12-0d42b4f38368"
      },
      "source": [
        "len(final_predictions[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwPWqwSkeVKg"
      },
      "source": [
        "test_labels = LE.transform(test_data[\"QCLabel\"].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfhsZh6EeYHK",
        "outputId": "9b3de708-ff05-40ba-eea1-795b756f57b4"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=10)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=10)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 10)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1400, 10) (1400,)\n",
            "update_recall:  0.85\n",
            "recall 0.85\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1190.0, 210.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[350, 349, 348, ..., 341, 340, 337],\n",
            "       [285, 283, 282, ...,  46,  45,  44],\n",
            "       [287, 269, 256, ..., 239,  82,  77],\n",
            "       ...,\n",
            "       [331, 329, 304, ..., 189, 188, 146],\n",
            "       [172, 171, 138, ..., 101,  95,  86],\n",
            "       [347,  26,  17, ...,   7,   6,   2]]), indices=array([[3, 0, 2, ..., 8, 9, 4],\n",
            "       [3, 8, 4, ..., 7, 2, 9],\n",
            "       [7, 0, 6, ..., 8, 3, 5],\n",
            "       ...,\n",
            "       [6, 9, 8, ..., 2, 1, 5],\n",
            "       [8, 2, 1, ..., 7, 9, 3],\n",
            "       [9, 4, 6, ..., 1, 2, 5]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is-KTAENfB6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c32f44-fb62-4952-f499-69e649482761"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=20)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=20)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 20)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1400, 20) (1400,)\n",
            "update_recall:  0.905\n",
            "recall 0.905\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1267.0, 133.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[351, 350, 349, ..., 198,  81,  80],\n",
            "       [291, 287, 285, ...,  38,  35,  31],\n",
            "       [287, 272, 271, ...,  82,  78,  77],\n",
            "       ...,\n",
            "       [334, 333, 331, ..., 188, 156, 146],\n",
            "       [182, 181, 180, ..., 101,  95,  86],\n",
            "       [347, 341, 340, ...,   6,   2,   1]]), indices=array([[10,  3,  0, ..., 17, 16, 15],\n",
            "       [12, 10,  3, ..., 16, 14, 19],\n",
            "       [ 7, 18, 19, ...,  3, 11,  5],\n",
            "       ...,\n",
            "       [17, 13,  6, ...,  1, 10,  5],\n",
            "       [17, 10, 14, ...,  7,  9,  3],\n",
            "       [ 9, 14, 15, ...,  2,  5, 12]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI1jhndp6cEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c623d07-6557-410e-c51d-bf58aec7c21b"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 15)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 15)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 15)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1400, 15) (1400,)\n",
            "precision 0.05919047619047619\n",
            "update_recall:  0.8878571428571429\n",
            "recall 0.8878571428571429\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1243.0, 157.0, 1243.0, 19757.0]\n",
            "TMP_RANK:  TopKV2(values=array([[351, 350, 349, ..., 337, 336, 335],\n",
            "       [291, 287, 285, ...,  45,  44,  35],\n",
            "       [287, 269, 266, ...,  82,  78,  77],\n",
            "       ...,\n",
            "       [333, 331, 329, ..., 188, 156, 146],\n",
            "       [181, 180, 172, ..., 101,  95,  86],\n",
            "       [347, 341,  26, ...,   6,   2,   1]]), indices=array([[10,  3,  0, ...,  4, 13, 12],\n",
            "       [12, 10,  3, ...,  2,  9, 14],\n",
            "       [ 7,  0, 14, ...,  3, 11,  5],\n",
            "       ...,\n",
            "       [13,  6,  9, ...,  1, 10,  5],\n",
            "       [10, 14,  8, ...,  7,  9,  3],\n",
            "       [ 9, 14,  4, ...,  2,  5, 12]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaA9z5n3mZz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab40460-ac5d-4c1f-f2fb-c49822c08293"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 10)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 10)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 10)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1400, 10) (1400,)\n",
            "precision 0.085\n",
            "update_recall:  0.85\n",
            "recall 0.85\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1190.0, 210.0, 1190.0, 12810.0]\n",
            "TMP_RANK:  TopKV2(values=array([[350, 349, 348, ..., 341, 340, 337],\n",
            "       [285, 283, 282, ...,  46,  45,  44],\n",
            "       [287, 269, 256, ..., 239,  82,  77],\n",
            "       ...,\n",
            "       [331, 329, 304, ..., 189, 188, 146],\n",
            "       [172, 171, 138, ..., 101,  95,  86],\n",
            "       [347,  26,  17, ...,   7,   6,   2]]), indices=array([[3, 0, 2, ..., 8, 9, 4],\n",
            "       [3, 8, 4, ..., 7, 2, 9],\n",
            "       [7, 0, 6, ..., 8, 3, 5],\n",
            "       ...,\n",
            "       [6, 9, 8, ..., 2, 1, 5],\n",
            "       [8, 2, 1, ..., 7, 9, 3],\n",
            "       [9, 4, 6, ..., 1, 2, 5]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkKaMSEJnJUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa089b98-6d67-4b3f-d2fc-ea38ce30692f"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1400, 5) (1400,)\n",
            "precision 0.14914285714285713\n",
            "update_recall:  0.7457142857142857\n",
            "recall 0.7457142857142857\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1044.0, 356.0, 1044.0, 5956.0]\n",
            "TMP_RANK:  TopKV2(values=array([[349, 348, 344, 342, 337],\n",
            "       [285, 281,  47,  46,  45],\n",
            "       [269, 268, 254,  82,  77],\n",
            "       ...,\n",
            "       [194, 193, 192, 189, 188],\n",
            "       [180, 171, 138, 137,  86],\n",
            "       [336,   9,   8,   7,   6]]), indices=array([[0, 1, 2, 3, 4],\n",
            "       [2, 0, 4, 3, 1],\n",
            "       [0, 1, 4, 2, 3],\n",
            "       ...,\n",
            "       [0, 4, 3, 2, 1],\n",
            "       [4, 2, 1, 0, 3],\n",
            "       [4, 0, 3, 1, 2]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 3)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 3)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 3)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz_vHGa7GUi-",
        "outputId": "40d99edc-2ab3-49b6-df40-2ce128e71bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1400, 3) (1400,)\n",
            "precision 0.22\n",
            "update_recall:  0.66\n",
            "recall 0.66\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 924.0, 476.0, 924.0, 3276.0]\n",
            "TMP_RANK:  TopKV2(values=array([[349, 348, 344],\n",
            "       [285, 281,  45],\n",
            "       [269, 268,  82],\n",
            "       ...,\n",
            "       [194, 189, 188],\n",
            "       [171, 138, 137],\n",
            "       [  9,   7,   6]]), indices=array([[0, 1, 2],\n",
            "       [2, 0, 1],\n",
            "       [0, 1, 2],\n",
            "       ...,\n",
            "       [0, 2, 1],\n",
            "       [2, 1, 0],\n",
            "       [0, 1, 2]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPqYvRNIrRg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c92789-f10e-4b8d-a71e-8190f44e93ac"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1400, 1) (1400,)\n",
            "precision 0.4564285714285714\n",
            "update_recall:  0.4564285714285714\n",
            "recall 0.4564285714285714\n",
            "STREAM_VARS:  [639.0, 761.0, 639.0, 761.0]\n",
            "TMP_RANK:  TopKV2(values=array([[349],\n",
            "       [281],\n",
            "       [269],\n",
            "       ...,\n",
            "       [194],\n",
            "       [137],\n",
            "       [  9]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       ...,\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUzf5IbMDfHp"
      },
      "source": [
        "# LO classification o/p"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnSjuzMDDhwe",
        "outputId": "7dda6d4c-2c06-4b22-ca23-775d2b5b716d"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 1) (417,)\n",
            "precision 0.7697841726618705\n",
            "update_recall:  0.7697841726618705\n",
            "recall 0.7697841726618705\n",
            "STREAM_VARS:  [321.0, 96.0, 321.0, 96.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 0],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 4],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [21],\n",
            "       [ 0],\n",
            "       [34],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 4],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [32],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [ 6],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [34],\n",
            "       [34],\n",
            "       [34],\n",
            "       [34],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [45],\n",
            "       [22],\n",
            "       [22],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [18],\n",
            "       [18],\n",
            "       [36],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [36],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [24],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [24],\n",
            "       [19],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [24],\n",
            "       [24],\n",
            "       [19],\n",
            "       [25],\n",
            "       [25],\n",
            "       [19],\n",
            "       [19],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [12],\n",
            "       [39],\n",
            "       [32],\n",
            "       [42],\n",
            "       [33],\n",
            "       [35],\n",
            "       [33],\n",
            "       [42],\n",
            "       [42],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [47],\n",
            "       [28],\n",
            "       [28],\n",
            "       [21],\n",
            "       [21],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [34],\n",
            "       [ 1],\n",
            "       [21],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [41],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [34],\n",
            "       [ 1],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [44],\n",
            "       [44],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [13],\n",
            "       [13],\n",
            "       [15],\n",
            "       [13],\n",
            "       [13],\n",
            "       [ 5],\n",
            "       [47],\n",
            "       [13],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [14],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [47],\n",
            "       [47],\n",
            "       [47],\n",
            "       [47],\n",
            "       [47],\n",
            "       [47],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [16],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [32],\n",
            "       [35],\n",
            "       [35],\n",
            "       [37],\n",
            "       [32],\n",
            "       [42],\n",
            "       [42],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [20],\n",
            "       [38],\n",
            "       [20],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [30],\n",
            "       [ 8],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [32],\n",
            "       [32],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 6],\n",
            "       [39],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 7],\n",
            "       [ 2],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 4],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [35],\n",
            "       [ 7],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [18],\n",
            "       [36],\n",
            "       [36],\n",
            "       [18],\n",
            "       [36],\n",
            "       [36],\n",
            "       [18],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [18],\n",
            "       [36],\n",
            "       [18],\n",
            "       [36],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [31],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [ 4],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [24],\n",
            "       [24],\n",
            "       [24],\n",
            "       [24],\n",
            "       [24],\n",
            "       [25],\n",
            "       [24],\n",
            "       [25],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXaBO4GEDhy_",
        "outputId": "7e2d3a5f-ec5c-4b7a-d2a0-dc878f4becfd"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 2)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 2)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 2)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 2) (417,)\n",
            "precision 0.4556354916067146\n",
            "update_recall:  0.9112709832134293\n",
            "recall 0.9112709832134293\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 380.0, 37.0, 380.0, 454.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5,  1],\n",
            "       [ 5,  1],\n",
            "       [ 5,  4],\n",
            "       [ 5,  1],\n",
            "       [ 7,  5],\n",
            "       [ 7,  5],\n",
            "       [34,  5],\n",
            "       [ 5,  0],\n",
            "       [ 5,  1],\n",
            "       [ 5,  2],\n",
            "       [ 5,  4],\n",
            "       [ 5,  4],\n",
            "       [46,  0],\n",
            "       [27,  0],\n",
            "       [27,  0],\n",
            "       [ 4,  0],\n",
            "       [29,  0],\n",
            "       [ 2,  0],\n",
            "       [28, 21],\n",
            "       [ 4,  0],\n",
            "       [34, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [ 7,  4],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [32,  2],\n",
            "       [ 2,  1],\n",
            "       [ 2,  1],\n",
            "       [ 2,  1],\n",
            "       [ 4,  2],\n",
            "       [32,  6],\n",
            "       [ 6,  2],\n",
            "       [ 4,  2],\n",
            "       [41, 34],\n",
            "       [41, 34],\n",
            "       [41, 34],\n",
            "       [41, 34],\n",
            "       [22, 11],\n",
            "       [46, 22],\n",
            "       [22, 20],\n",
            "       [22, 20],\n",
            "       [22, 20],\n",
            "       [44, 22],\n",
            "       [28, 22],\n",
            "       [22,  3],\n",
            "       [45, 22],\n",
            "       [36, 22],\n",
            "       [22,  3],\n",
            "       [22,  9],\n",
            "       [22,  9],\n",
            "       [ 9,  3],\n",
            "       [45,  9],\n",
            "       [44,  9],\n",
            "       [22,  9],\n",
            "       [33,  9],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [18, 10],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [18, 17],\n",
            "       [36, 18],\n",
            "       [18, 17],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [18, 17],\n",
            "       [17, 11],\n",
            "       [18, 17],\n",
            "       [18, 17],\n",
            "       [18, 17],\n",
            "       [17, 11],\n",
            "       [24, 23],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [24, 23],\n",
            "       [24, 19],\n",
            "       [25, 19],\n",
            "       [25, 19],\n",
            "       [25, 24],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [25, 19],\n",
            "       [25, 24],\n",
            "       [25, 19],\n",
            "       [25, 19],\n",
            "       [24, 19],\n",
            "       [26, 12],\n",
            "       [39, 12],\n",
            "       [12,  4],\n",
            "       [26, 12],\n",
            "       [39, 12],\n",
            "       [26, 12],\n",
            "       [39, 12],\n",
            "       [26, 16],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 16],\n",
            "       [26,  4],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [12,  4],\n",
            "       [47, 39],\n",
            "       [42, 32],\n",
            "       [42, 33],\n",
            "       [33, 32],\n",
            "       [35, 33],\n",
            "       [42, 33],\n",
            "       [42, 35],\n",
            "       [42, 32],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [37, 28],\n",
            "       [47, 39],\n",
            "       [28, 21],\n",
            "       [35, 28],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28,  7],\n",
            "       [39,  7],\n",
            "       [21,  1],\n",
            "       [45, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [34,  1],\n",
            "       [21,  1],\n",
            "       [21,  1],\n",
            "       [ 5,  1],\n",
            "       [34,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [34,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [21,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41, 34],\n",
            "       [41,  1],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [18,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [17, 11],\n",
            "       [17, 11],\n",
            "       [44, 11],\n",
            "       [19, 11],\n",
            "       [11,  8],\n",
            "       [19, 11],\n",
            "       [31,  9],\n",
            "       [31, 13],\n",
            "       [38, 31],\n",
            "       [31, 13],\n",
            "       [31,  9],\n",
            "       [16, 13],\n",
            "       [16, 13],\n",
            "       [15, 14],\n",
            "       [14, 13],\n",
            "       [16, 13],\n",
            "       [13,  5],\n",
            "       [47, 13],\n",
            "       [14, 13],\n",
            "       [16, 13],\n",
            "       [16, 14],\n",
            "       [16, 14],\n",
            "       [14, 13],\n",
            "       [16, 13],\n",
            "       [16, 13],\n",
            "       [16, 14],\n",
            "       [16, 13],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [31, 16],\n",
            "       [38, 25],\n",
            "       [38, 24],\n",
            "       [38, 31],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [46, 35],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [47, 32],\n",
            "       [35, 28],\n",
            "       [42, 35],\n",
            "       [37,  8],\n",
            "       [42, 32],\n",
            "       [42, 32],\n",
            "       [42, 32],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [38, 32],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [42, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [30,  8],\n",
            "       [36,  8],\n",
            "       [30,  8],\n",
            "       [30, 11],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [30,  8],\n",
            "       [33, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [30,  8],\n",
            "       [32, 10],\n",
            "       [42, 32],\n",
            "       [45, 43],\n",
            "       [43, 15],\n",
            "       [45, 43],\n",
            "       [45, 43],\n",
            "       [43, 15],\n",
            "       [43, 27],\n",
            "       [43, 35],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [39,  6],\n",
            "       [39, 32],\n",
            "       [39,  6],\n",
            "       [ 7,  6],\n",
            "       [ 6,  2],\n",
            "       [32,  6],\n",
            "       [28,  7],\n",
            "       [35,  2],\n",
            "       [47,  7],\n",
            "       [ 7,  6],\n",
            "       [ 7,  4],\n",
            "       [ 7,  6],\n",
            "       [47,  7],\n",
            "       [ 7,  6],\n",
            "       [39,  6],\n",
            "       [35, 32],\n",
            "       [ 7,  6],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [14, 13],\n",
            "       [14, 13],\n",
            "       [14, 13],\n",
            "       [31, 13],\n",
            "       [14, 13],\n",
            "       [14, 13],\n",
            "       [14, 13],\n",
            "       [14, 13],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [38, 31],\n",
            "       [38, 15],\n",
            "       [45, 38],\n",
            "       [38, 33],\n",
            "       [38, 32],\n",
            "       [37,  4],\n",
            "       [26,  4],\n",
            "       [26,  4],\n",
            "       [27,  4],\n",
            "       [37, 28],\n",
            "       [37, 28],\n",
            "       [37,  4],\n",
            "       [37,  4],\n",
            "       [37,  4],\n",
            "       [39, 37],\n",
            "       [39, 37],\n",
            "       [40, 37],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [25, 24],\n",
            "       [24, 23],\n",
            "       [25, 19],\n",
            "       [40, 24],\n",
            "       [40, 24],\n",
            "       [41, 40],\n",
            "       [40, 19],\n",
            "       [40, 24],\n",
            "       [40, 19],\n",
            "       [40, 24],\n",
            "       [40, 16],\n",
            "       [40, 24],\n",
            "       [40, 16],\n",
            "       [40, 24],\n",
            "       [35, 33],\n",
            "       [42, 35],\n",
            "       [35, 33],\n",
            "       [35,  7],\n",
            "       [42, 35],\n",
            "       [42, 35]]), indices=array([[0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVAO6-ddDh1z",
        "outputId": "59055070-fd5e-4ab1-ab11-82194bb19436"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 3)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 3)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred,3)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 3) (417,)\n",
            "precision 0.31654676258992803\n",
            "update_recall:  0.9496402877697842\n",
            "recall 0.9496402877697842\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 396.0, 21.0, 396.0, 855.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5,  4,  1],\n",
            "       [41,  5,  1],\n",
            "       [ 5,  4,  1],\n",
            "       ...,\n",
            "       [35, 33,  7],\n",
            "       [42, 35, 32],\n",
            "       [42, 35,  8]]), indices=array([[0, 2, 1],\n",
            "       [2, 0, 1],\n",
            "       [0, 1, 2],\n",
            "       ...,\n",
            "       [0, 2, 1],\n",
            "       [1, 0, 2],\n",
            "       [1, 0, 2]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLX7Wx9CDh4r",
        "outputId": "86bf2b52-4bba-4aab-ac13-c78b4b2ea6bd"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 4)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 4)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 4)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 4) (417,)\n",
            "precision 0.24400479616306955\n",
            "update_recall:  0.9760191846522782\n",
            "recall 0.9760191846522782\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 407.0, 10.0, 407.0, 1261.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5,  4,  2,  1],\n",
            "       [41,  5,  2,  1],\n",
            "       [ 5,  4,  2,  1],\n",
            "       ...,\n",
            "       [35, 33, 32,  7],\n",
            "       [42, 35, 32,  8],\n",
            "       [42, 35, 32,  8]]), indices=array([[0, 2, 3, 1],\n",
            "       [2, 0, 3, 1],\n",
            "       [0, 1, 3, 2],\n",
            "       ...,\n",
            "       [0, 2, 3, 1],\n",
            "       [1, 0, 2, 3],\n",
            "       [1, 0, 3, 2]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV492QBBDh7l",
        "outputId": "ce2e9db8-4aba-4e0b-a74a-0bc941884d73"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 5) (417,)\n",
            "precision 0.1971223021582734\n",
            "update_recall:  0.9856115107913669\n",
            "recall 0.9856115107913669\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 411.0, 6.0, 411.0, 1674.0]\n",
            "TMP_RANK:  TopKV2(values=array([[34,  5,  4,  2,  1],\n",
            "       [41,  5,  4,  2,  1],\n",
            "       [29,  5,  4,  2,  1],\n",
            "       ...,\n",
            "       [42, 35, 33, 32,  7],\n",
            "       [42, 35, 33, 32,  8],\n",
            "       [42, 35, 33, 32,  8]]), indices=array([[4, 0, 2, 3, 1],\n",
            "       [2, 0, 4, 3, 1],\n",
            "       [4, 0, 1, 3, 2],\n",
            "       ...,\n",
            "       [4, 0, 2, 3, 1],\n",
            "       [1, 0, 4, 2, 3],\n",
            "       [1, 0, 4, 3, 2]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGbi4DEZkwhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3368f1-fd70-4f5a-bdb5-2d5f4bc5690b"
      },
      "source": [
        "y_true = np.array(labels)\n",
        "final_predictions = np.array(final_predictions).squeeze()\n",
        "final_predictions.shape\n",
        "len(final_predictions[final_predictions==y_true])/len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3918918918918919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN1UA_4uBu_S"
      },
      "source": [
        "categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdD0JiYgEX4k"
      },
      "source": [
        "!cp -r /content/model_euclidean_SENT_BERT_cos_QC_attention_V3.zip \"/content/drive/My Drive/research_lo_content_taxonomy_classification\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}