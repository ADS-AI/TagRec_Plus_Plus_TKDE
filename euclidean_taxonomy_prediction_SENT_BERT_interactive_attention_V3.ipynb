{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR9av2JU3kf6",
        "outputId": "d118f60f-4efd-4a0a-e1de-017c2b8f1c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da-zaZJUGMFU",
        "outputId": "1e15d779-b162-4141-8222-67318693c7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slZnjEXG5_-Z",
        "outputId": "2d4ca4f5-c8b2-488f-b9bf-3f4309e13ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers==0.2.6.1 in /usr/local/lib/python3.7/dist-packages (0.2.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (1.7.3)\n",
            "Requirement already satisfied: transformers>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (2.8.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.2.6.1) (3.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->sentence-transformers==0.2.6.1) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.7.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (1.24.37)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (2022.6.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (0.0.53)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers>=2.8.0->sentence-transformers==0.2.6.1) (0.1.96)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.37 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers==0.2.6.1) (1.27.37)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers==0.2.6.1) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers==0.2.6.1) (0.6.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.37->boto3->transformers>=2.8.0->sentence-transformers==0.2.6.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.37->boto3->transformers>=2.8.0->sentence-transformers==0.2.6.1) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.37->boto3->transformers>=2.8.0->sentence-transformers==0.2.6.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers==0.2.6.1) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers==0.2.6.1) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.8.0->sentence-transformers==0.2.6.1) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers==0.2.6.1) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install sentence-transformers==0.2.6.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlE6vskY9VmG"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_SENT_BERT_cos_attention_2_V2/\" /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdTHR92Lrb-J",
        "outputId": "578d39f9-a1e8-4295-b168-a339b5f0b188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/My, /content/drive/My.zip or /content/drive/My.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_SENT_BERT_cos_attention_2_V3.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzKeqoCs3kgA",
        "outputId": "330a3a53-9190-4953-9c71-53a5f19d60b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.1.96)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.21.6)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.53)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2022.6.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.24.37)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.7.1)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.37 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.27.37)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.37->boto3->transformers==2.8.0) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.37->boto3->transformers==2.8.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.37->boto3->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==2.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf-OXnTs-ZhS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZFv4UU8sLTM",
        "outputId": "6063f320-f012-43a5-93ba-624374b0bec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/geoopt/geoopt.git\n",
            "  Cloning https://github.com/geoopt/geoopt.git to /tmp/pip-req-build-ki0uasus\n",
            "  Running command git clone -q https://github.com/geoopt/geoopt.git /tmp/pip-req-build-ki0uasus\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from geoopt==0.5.0) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geoopt==0.5.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from geoopt==0.5.0) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.11.0->geoopt==0.5.0) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ferrine/hyrnn.git\n",
            "  Cloning https://github.com/ferrine/hyrnn.git to /tmp/pip-req-build-d435y1yp\n",
            "  Running command git clone -q https://github.com/ferrine/hyrnn.git /tmp/pip-req-build-d435y1yp\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->hyrnn==0.0.0) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/geoopt/geoopt.git\n",
        "! pip install git+https://github.com/ferrine/hyrnn.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GsADhaO93kgD",
        "outputId": "8e60a59a-9cd8-4d0e-ee8e-839c69217540"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          board_syllabus  \\\n",
              "0      social science>>geography : our environment>>w...   \n",
              "1      social science>>history : our pasts - iii>>wea...   \n",
              "2      social science>>civics : social and political ...   \n",
              "3      social science>>civics : social and political ...   \n",
              "4                            science>>components of food   \n",
              "...                                                  ...   \n",
              "40890             science>>synthetic fibres and plastics   \n",
              "40891  physics>>physics : part - ii>>ray optics and o...   \n",
              "40892  social science>>history : india and the contem...   \n",
              "40893                   science>>garbage in, garbage out   \n",
              "40894                    science>>some natural phenomena   \n",
              "\n",
              "                                         question_answer  \n",
              "0       Identify the different processes involved in ...  \n",
              "1       The word &#39;Chintz&#39; comes from which la...  \n",
              "2       Which disease is responsible for the deaths o...  \n",
              "3      Patients usually have to wait for hours in the...  \n",
              "4       How can deficiency diseases be prevented? Def...  \n",
              "...                                                  ...  \n",
              "40890               Name the monomer of polyester. Ester  \n",
              "40891   A convex lens and a concave lens, each having...  \n",
              "40892   Peasants who opposed collectivisation and res...  \n",
              "40893   Cancer is one of the fatal diseases causeddue...  \n",
              "40894   Fill in the blanks : (a) The process of trans...  \n",
              "\n",
              "[40895 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6762cf3-f50e-4c08-8afd-473847e6bf44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>social science&gt;&gt;geography : our environment&gt;&gt;w...</td>\n",
              "      <td>Identify the different processes involved in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>social science&gt;&gt;history : our pasts - iii&gt;&gt;wea...</td>\n",
              "      <td>The word &amp;#39;Chintz&amp;#39; comes from which la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>social science&gt;&gt;civics : social and political ...</td>\n",
              "      <td>Which disease is responsible for the deaths o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>social science&gt;&gt;civics : social and political ...</td>\n",
              "      <td>Patients usually have to wait for hours in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>science&gt;&gt;components of food</td>\n",
              "      <td>How can deficiency diseases be prevented? Def...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40890</th>\n",
              "      <td>science&gt;&gt;synthetic fibres and plastics</td>\n",
              "      <td>Name the monomer of polyester. Ester</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40891</th>\n",
              "      <td>physics&gt;&gt;physics : part - ii&gt;&gt;ray optics and o...</td>\n",
              "      <td>A convex lens and a concave lens, each having...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40892</th>\n",
              "      <td>social science&gt;&gt;history : india and the contem...</td>\n",
              "      <td>Peasants who opposed collectivisation and res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40893</th>\n",
              "      <td>science&gt;&gt;garbage in, garbage out</td>\n",
              "      <td>Cancer is one of the fatal diseases causeddue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40894</th>\n",
              "      <td>science&gt;&gt;some natural phenomena</td>\n",
              "      <td>Fill in the blanks : (a) The process of trans...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40895 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6762cf3-f50e-4c08-8afd-473847e6bf44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6762cf3-f50e-4c08-8afd-473847e6bf44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6762cf3-f50e-4c08-8afd-473847e6bf44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"train_taxonomy_prediction.csv\")\n",
        "val_data = pd.read_csv(\"validation_taxonomy_prediction.csv\")\n",
        "test_data = pd.read_csv(\"test_taxonomy_prediction.csv\")\n",
        "\n",
        "train_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQhO6qqt6lge"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E5kvcEZcwUi"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/research_lo_content_taxonomy_classification/model_euclidean_SENT_BERT_cos_attention_2_V3 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD4IAgG1XQGp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_sentence(question):\n",
        "  # print(question)\n",
        "  question = re.sub('<[^>]*>', ' ',question)\n",
        "  question = re.sub(' +', ' ', question)\n",
        "  question = re.sub('\\xa0','',question)\n",
        "  question = question.rstrip()\n",
        "  question = re.sub('nan','',question)\n",
        "  question = re.sub(u'\\u2004','',question)\n",
        "  question = re.sub(u'\\u2009','',question)\n",
        "\n",
        "  # question = question.decode(\"utf-8\")\n",
        "  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n",
        "  question = re.sub('&nbsp','',question)\n",
        "  question = re.sub('&ndash','',question)\n",
        "  question = re.sub('\\r','',question)\n",
        "  question = re.sub('\\t','',question)\n",
        "  question = re.sub('\\n',' ',question)\n",
        "\n",
        "  question = re.sub('MathType@.*','',question)\n",
        "  question = re.sub('&thinsp','',question)\n",
        "  question = re.sub('&times','',question)\n",
        "  question = re.sub('\\u200b','',question)\n",
        "  question = re.sub('&rarr;;;','',question)\n",
        "\n",
        "  return question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNrGNk8f3kgh"
      },
      "outputs": [],
      "source": [
        "# final_data_1 = final_data.loc[0:71003,:]\n",
        "# final_data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIrS5sxE3kgk",
        "outputId": "a1ad1127-a4b0-4718-910c-dfee00600bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mgc72PQYV1Y",
        "outputId": "a6b7152a-5b80-4452-ba25-1c0dd283623e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "science                                                       493\n",
              "science>>sound                                                364\n",
              "science>>life processes                                       285\n",
              "science>>acids, bases and salts                               281\n",
              "computer science>>introduction to computer                    254\n",
              "                                                             ... \n",
              "physics>>physics : part - ii>>atoms                            85\n",
              "physics>>physics : part - ii>>oscillations                     83\n",
              "physical science>>physical science (physics)>>force>>force     83\n",
              "science>>light, shadows and reflections                        82\n",
              "social science>>the mauryan empire>>the mauryan empire         82\n",
              "Name: board_syllabus, Length: 312, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "train_data[\"board_syllabus\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3lYOb2K3kgy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# LE = LabelEncoder()\n",
        "# final_data['label'] = LE.fit_transform(final_data['board_syllabus'])\n",
        "# final_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp64MkNB3kg1"
      },
      "outputs": [],
      "source": [
        "# def get_labels(prediction):\n",
        "#     predicted_label =  LE.inverse_transform([prediction])\n",
        "#     return predicted_label[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPgTmJPS3kg4"
      },
      "outputs": [],
      "source": [
        "# get_labels(330)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrQ1BBx0vWUQ"
      },
      "outputs": [],
      "source": [
        "# train_data = pd.concat([train_data,val_data])\n",
        "# train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Fuhr8z0tcd_K",
        "outputId": "47e8af5d-b458-4e1c-b5da-8aada61c0eb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         board_syllabus  \\\n",
              "0                science>>diversity in living organisms   \n",
              "1     computer science[c++]>>linked lists, stacks an...   \n",
              "2     social science>>geography : the earth our habi...   \n",
              "3                                        science>>sound   \n",
              "4                     science>>respiration in organisms   \n",
              "...                                                 ...   \n",
              "2148  physics>>physics : part - i>>units and measure...   \n",
              "2149                  science>>separation of substances   \n",
              "2150  social science>>history : our pasts - i>>build...   \n",
              "2151                    science>>acids, bases and salts   \n",
              "2152                    science>>getting to know plants   \n",
              "\n",
              "                                        question_answer  \n",
              "0                   Coelenterates shows two body forms.  \n",
              "1      The following function is supposed to return ...  \n",
              "2      The plains are known as food baskets. Why? Th...  \n",
              "3     The amount of sound energy passing each second...  \n",
              "4      When we breathe out, the concentration of wat...  \n",
              "...                                                 ...  \n",
              "2148   (A)Add to correct significant figure? (B) Fin...  \n",
              "2149   Explain the process of sieving. Sieving is us...  \n",
              "2150   This is a cave painting . Answer the followin...  \n",
              "2151   What are Acid, Base &amp; Salts? jjhkhjkhjkhj...  \n",
              "2152   The part of a plant which holds it into the s...  \n",
              "\n",
              "[2153 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-850dbd77-0eb4-4a6c-862f-da9cd3aa318c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>science&gt;&gt;diversity in living organisms</td>\n",
              "      <td>Coelenterates shows two body forms.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>computer science[c++]&gt;&gt;linked lists, stacks an...</td>\n",
              "      <td>The following function is supposed to return ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>social science&gt;&gt;geography : the earth our habi...</td>\n",
              "      <td>The plains are known as food baskets. Why? Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>science&gt;&gt;sound</td>\n",
              "      <td>The amount of sound energy passing each second...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>science&gt;&gt;respiration in organisms</td>\n",
              "      <td>When we breathe out, the concentration of wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2148</th>\n",
              "      <td>physics&gt;&gt;physics : part - i&gt;&gt;units and measure...</td>\n",
              "      <td>(A)Add to correct significant figure? (B) Fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>science&gt;&gt;separation of substances</td>\n",
              "      <td>Explain the process of sieving. Sieving is us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>social science&gt;&gt;history : our pasts - i&gt;&gt;build...</td>\n",
              "      <td>This is a cave painting . Answer the followin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>science&gt;&gt;acids, bases and salts</td>\n",
              "      <td>What are Acid, Base &amp;amp; Salts? jjhkhjkhjkhj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>science&gt;&gt;getting to know plants</td>\n",
              "      <td>The part of a plant which holds it into the s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2153 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-850dbd77-0eb4-4a6c-862f-da9cd3aa318c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-850dbd77-0eb4-4a6c-862f-da9cd3aa318c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-850dbd77-0eb4-4a6c-862f-da9cd3aa318c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijn1nIpByb3e"
      },
      "outputs": [],
      "source": [
        "train_features = train_data[\"question_answer\"]\n",
        "test_features = test_data[\"question_answer\"]\n",
        "train_labels = train_data[\"board_syllabus\"]\n",
        "test_labels = test_data[\"board_syllabus\"]\n",
        "val_features = val_data[\"question_answer\"]\n",
        "val_labels = val_data[\"board_syllabus\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prM_km_83khD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfhPstXJ03oz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkyM7gqv3khI"
      },
      "outputs": [],
      "source": [
        "question_answer = train_features.values\n",
        "categories = train_labels.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFkS_H_83khL",
        "outputId": "8dcabc25-78d2-43df-8e82-b2e85b5b6602"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' Identify the different processes involved in the &#39;water cycle&#39; from the options given below. i. Evaporation ii. Condensation iii. Sublimation iv. Precipitation i, ii and iv only',\n",
              "       ' The word &#39;Chintz&#39; comes from which language? Hindi',\n",
              "       ' Which disease is responsible for the deaths of 5 lakh people in India? Tuberculosis',\n",
              "       ...,\n",
              "       ' Peasants who opposed collectivisation and resisted the authorities were: deported and exiled',\n",
              "       ' Cancer is one of the fatal diseases causeddue tothe harmful gases released during burning of plastic.',\n",
              "       ' Fill in the blanks : (a) The process of transferring of charge from a charged object to the earth is called _____________. (b) The process of electric discharge can occur between two or more_______, or between ________ and the __________. (c) The uppermost layer of the earth called the _________. (a) E arthing (b) Clouds, clouds ,earth (c) C rust'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "question_answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ian7gSDE3khR",
        "outputId": "9b507443-eecb-4dd7-c5ab-316c0c6b4408"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['social science>>geography : our environment>>water',\n",
              "       'social science>>history : our pasts - iii>>weavers, iron smelter & factory owners',\n",
              "       'social science>>civics : social and political life - ii>>role of the government in health',\n",
              "       ...,\n",
              "       'social science>>history : india and the contemporary world - i>>socialism in europe and the russian revolution',\n",
              "       'science>>garbage in, garbage out',\n",
              "       'science>>some natural phenomena'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fepGiggpqOQx"
      },
      "outputs": [],
      "source": [
        "# val_features = test_features.values\n",
        "# val_labels = test_labels.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN1zRXMOXwLK",
        "outputId": "5767fb81-2552-4e2a-c653-75371f9cf530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: inflection in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "!pip install inflection\n",
        "\n",
        "from bokeh.io import output_file, output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.util.hex import hexbin\n",
        "from bokeh.models import HoverTool\n",
        "from bokeh import colors\n",
        "import inflection\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "ps = PorterStemmer()\n",
        "from gzip import open as gopen\n",
        "from pandas.core.common import flatten\n",
        "import gensim.models.poincare as poincare\n",
        "def get_cleaned_taxonomy(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = ' '.join(value.split(\">>\"))\n",
        "      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n",
        "      cleaned_taxonomy.append( value )\n",
        "  return cleaned_taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPAl0TNuX6mx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# course_taxonomy\n",
        "\n",
        "poincare_emb_data = get_cleaned_taxonomy(categories)\n",
        "poincare_val = get_cleaned_taxonomy(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aedZzkBsqEeK",
        "outputId": "647a19bb-fa13-485b-b3ca-7f1c51dc4bcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'social science civics : social and political life - ii role of the government in health'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "poincare_emb_data[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_ocuHxzCy16",
        "outputId": "dcb03103-fbab-41bb-8a0f-bc15ad47551f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "wnl = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjDKIFSENir_"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sent_model = SentenceTransformer('bert-large-nli-stsb-mean-tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdBbsrO9zp2p"
      },
      "outputs": [],
      "source": [
        "# taxonomy_vectors = []\n",
        "taxonomy_vectors = sent_model.encode(poincare_emb_data)\n",
        "# taxonomy_vectors = np.vstack(taxonomy_vectors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJUSQmOq7v8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2793f73c-04e2-43e6-a83a-f3bfe5655dd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40895, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "taxonomy_vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTlCYX9Q34JG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b71e1f-9966-4b4e-a131-d02af33eec5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2153, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# taxonomy_vectors_val = []\n",
        "# for feature in poincare_val:\n",
        "taxonomy_vectors_val = sent_model.encode(poincare_val)\n",
        "taxonomy_vectors_val = np.vstack(taxonomy_vectors_val)\n",
        "taxonomy_vectors_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-DEKAOHv-VD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "166d3396-1c5b-4520-ba24-16bd3a819a54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         board_syllabus  \\\n",
              "0                          physics>>physics : part - ii   \n",
              "1     social science>>geography : the earth our habi...   \n",
              "2                science>>diversity in living organisms   \n",
              "3           physics>>physics : part - i>>physical world   \n",
              "4     social science>>history : our pasts - iii>>tri...   \n",
              "...                                                 ...   \n",
              "4779  political science>>political science : indian ...   \n",
              "4780                                   science>>tissues   \n",
              "4781     computer science[c++]>>programming methodology   \n",
              "4782           chemistry>>chemistry : part i>>solutions   \n",
              "4783       science>>periodic classification of elements   \n",
              "\n",
              "                                        question_answer  \n",
              "0      (a) Describe a simple experiment (or activity...  \n",
              "1      What is the average weather in a place over m...  \n",
              "2      Which of the following is correct for the cha...  \n",
              "3      The branch of Physics that deals with the mic...  \n",
              "4      Why did tribals view traders as a major cause...  \n",
              "...                                                 ...  \n",
              "4779   Which one of the following is not true about ...  \n",
              "4780   Which of the following is a fluid matrix of t...  \n",
              "4781   Program formatting has more effect when a con...  \n",
              "4782  Cryoscopic constant is related to depression i...  \n",
              "4783   The elements present in same period have same...  \n",
              "\n",
              "[4784 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a7284ea-b01f-4a8f-8659-f3a413ca56e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>physics&gt;&gt;physics : part - ii</td>\n",
              "      <td>(a) Describe a simple experiment (or activity...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>social science&gt;&gt;geography : the earth our habi...</td>\n",
              "      <td>What is the average weather in a place over m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>science&gt;&gt;diversity in living organisms</td>\n",
              "      <td>Which of the following is correct for the cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>physics&gt;&gt;physics : part - i&gt;&gt;physical world</td>\n",
              "      <td>The branch of Physics that deals with the mic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>social science&gt;&gt;history : our pasts - iii&gt;&gt;tri...</td>\n",
              "      <td>Why did tribals view traders as a major cause...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4779</th>\n",
              "      <td>political science&gt;&gt;political science : indian ...</td>\n",
              "      <td>Which one of the following is not true about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4780</th>\n",
              "      <td>science&gt;&gt;tissues</td>\n",
              "      <td>Which of the following is a fluid matrix of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4781</th>\n",
              "      <td>computer science[c++]&gt;&gt;programming methodology</td>\n",
              "      <td>Program formatting has more effect when a con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4782</th>\n",
              "      <td>chemistry&gt;&gt;chemistry : part i&gt;&gt;solutions</td>\n",
              "      <td>Cryoscopic constant is related to depression i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4783</th>\n",
              "      <td>science&gt;&gt;periodic classification of elements</td>\n",
              "      <td>The elements present in same period have same...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4784 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a7284ea-b01f-4a8f-8659-f3a413ca56e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a7284ea-b01f-4a8f-8659-f3a413ca56e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a7284ea-b01f-4a8f-8659-f3a413ca56e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXHqIRoxd6YR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ec75c7f3-3202-498b-fec0-c3366696f702"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          board_syllabus  \\\n",
              "0      social science>>geography : our environment>>w...   \n",
              "1      social science>>history : our pasts - iii>>wea...   \n",
              "2      social science>>civics : social and political ...   \n",
              "3      social science>>civics : social and political ...   \n",
              "4                            science>>components of food   \n",
              "...                                                  ...   \n",
              "40890             science>>synthetic fibres and plastics   \n",
              "40891  physics>>physics : part - ii>>ray optics and o...   \n",
              "40892  social science>>history : india and the contem...   \n",
              "40893                   science>>garbage in, garbage out   \n",
              "40894                    science>>some natural phenomena   \n",
              "\n",
              "                                         question_answer  \n",
              "0       Identify the different processes involved in ...  \n",
              "1       The word &#39;Chintz&#39; comes from which la...  \n",
              "2       Which disease is responsible for the deaths o...  \n",
              "3      Patients usually have to wait for hours in the...  \n",
              "4       How can deficiency diseases be prevented? Def...  \n",
              "...                                                  ...  \n",
              "40890               Name the monomer of polyester. Ester  \n",
              "40891   A convex lens and a concave lens, each having...  \n",
              "40892   Peasants who opposed collectivisation and res...  \n",
              "40893   Cancer is one of the fatal diseases causeddue...  \n",
              "40894   Fill in the blanks : (a) The process of trans...  \n",
              "\n",
              "[40895 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-079fb032-dabf-4809-bf85-ae408f9df734\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>social science&gt;&gt;geography : our environment&gt;&gt;w...</td>\n",
              "      <td>Identify the different processes involved in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>social science&gt;&gt;history : our pasts - iii&gt;&gt;wea...</td>\n",
              "      <td>The word &amp;#39;Chintz&amp;#39; comes from which la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>social science&gt;&gt;civics : social and political ...</td>\n",
              "      <td>Which disease is responsible for the deaths o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>social science&gt;&gt;civics : social and political ...</td>\n",
              "      <td>Patients usually have to wait for hours in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>science&gt;&gt;components of food</td>\n",
              "      <td>How can deficiency diseases be prevented? Def...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40890</th>\n",
              "      <td>science&gt;&gt;synthetic fibres and plastics</td>\n",
              "      <td>Name the monomer of polyester. Ester</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40891</th>\n",
              "      <td>physics&gt;&gt;physics : part - ii&gt;&gt;ray optics and o...</td>\n",
              "      <td>A convex lens and a concave lens, each having...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40892</th>\n",
              "      <td>social science&gt;&gt;history : india and the contem...</td>\n",
              "      <td>Peasants who opposed collectivisation and res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40893</th>\n",
              "      <td>science&gt;&gt;garbage in, garbage out</td>\n",
              "      <td>Cancer is one of the fatal diseases causeddue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40894</th>\n",
              "      <td>science&gt;&gt;some natural phenomena</td>\n",
              "      <td>Fill in the blanks : (a) The process of trans...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40895 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-079fb032-dabf-4809-bf85-ae408f9df734')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-079fb032-dabf-4809-bf85-ae408f9df734 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-079fb032-dabf-4809-bf85-ae408f9df734');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p834oM1Pzzu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974512bd-f011-49e3-a7fc-8a5c7fdc0c8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "set(train_data[\"question_answer\"].values).intersection(set(test_data[\"question_answer\"].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_ZeuHc63khU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5050d792-3e4f-4cb0-d8a6-2f9bc626bef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Identify the different processes involved in the &#39;water cycle&#39; from the options given below. i. Evaporation ii. Condensation iii. Sublimation iv. Precipitation i, ii and iv only\n",
            "Token IDs: tensor([  101,  6709,  1996,  2367,  6194,  2920,  1999,  1996,  1004,  1001,\n",
            "         4464,  1025,  2300,  5402,  1004,  1001,  4464,  1025,  2013,  1996,\n",
            "         7047,  2445,  2917,  1012,  1045,  1012,  9345, 17822,  3370,  2462,\n",
            "         1012, 24707,  3619,  3370,  3523,  1012,  4942, 17960,  3370,  4921,\n",
            "         1012, 13511,  1045,  1010,  2462,  1998,  4921,  2069,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in question_answer:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VjkhiN3pAfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e9afec-7594-475c-ea03-4783a15b7c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Identify the different processes involved in the &#39;water cycle&#39; from the options given below. i. Evaporation ii. Condensation iii. Sublimation iv. Precipitation i, ii and iv only\n",
            "Token IDs: tensor([  101,  6709,  1996,  2367,  6194,  2920,  1999,  1996,  1004,  1001,\n",
            "         4464,  1025,  2300,  5402,  1004,  1001,  4464,  1025,  2013,  1996,\n",
            "         7047,  2445,  2917,  1012,  1045,  1012,  9345, 17822,  3370,  2462,\n",
            "         1012, 24707,  3619,  3370,  3523,  1012,  4942, 17960,  3370,  4921,\n",
            "         1012, 13511,  1045,  1010,  2462,  1998,  4921,  2069,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "for sent in val_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNDW74Ny3khj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4629d1b0-5b7d-44ea-92f7-88bfe398282a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "num_classes = len(list(set(categories)))\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmaLk5Ab3khl"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "train_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n",
        "val_poincare_tensor = torch.tensor(taxonomy_vectors_val,dtype=torch.float)\n",
        "\n",
        "val_dataset = TensorDataset(input_ids_val,attention_masks_val,val_poincare_tensor)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, train_poincare_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_lTinod3kho"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vduf9fOMviK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae73c656-3331-4556-f7cd-c25c6112013d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers==2.8.0\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY11ZeWFNM7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13b4f7c-2f03-4f1e-a3c5-ed2fa68ab82b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40895, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "train_poincare_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H2wp8WlEi9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66abca00-6bb1-4093-9e40-51526466fce3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "set(question_answer).intersection(set(test_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN6jdKp0uhO3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "\n",
        "from tqdm import tqdm\n",
        "import geoopt\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "cos_label = nn.CosineSimilarity(dim=1, eps=1e-5)\n",
        "\n",
        "dist = torch.nn.PairwiseDistance(p=2.0, eps=1e-06)\n",
        "nn.PairwiseDistance(p=2)\n",
        "class MHSA(nn.Module):\n",
        "  def __init__(self,\n",
        "         emb_dim,\n",
        "         kqv_dim,\n",
        "         num_heads=2):\n",
        "    super(MHSA, self).__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    self.kqv_dim = kqv_dim\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.w_k = nn.Linear(emb_dim, kqv_dim * num_heads, bias=False)\n",
        "    self.w_q = nn.Linear(emb_dim, kqv_dim * num_heads, bias=False)\n",
        "    self.w_v = nn.Linear(emb_dim, kqv_dim * num_heads, bias=False)\n",
        "    self.w_out = nn.Linear(kqv_dim * num_heads, emb_dim)\n",
        "\n",
        "  def forward(self, query, key, value):\n",
        "    # print(\"query\",query.shape)\n",
        "    b, t = query.shape\n",
        "    e = self.kqv_dim\n",
        "    h = self.num_heads\n",
        "    keys = self.w_k(key).view(b, h, e)\n",
        "    values = self.w_v(value).view(b, h, e)\n",
        "    queries = self.w_q(query).view(b, h, e)\n",
        "\n",
        "    # keys = keys.transpose(2, 1)\n",
        "    # queries = queries.transpose(2, 1)\n",
        "    # values = values.transpose(2, 1)\n",
        "\n",
        "    dot = queries @ keys.transpose(2, 1)  #(b*h*e) @ (b*e*h)\n",
        "    dot = dot / np.sqrt(e)  # (b*h*h)\n",
        "    dot = F.softmax(dot, dim=2)\n",
        "\n",
        "    out = dot @ values   # (b*h*h) @ (b*h*e) = (b*h*e)\n",
        "    out = out.contiguous().view(b, h * e)\n",
        "    out = self.w_out(out)\n",
        "    return out\n",
        "# Neural Classifierwork\n",
        "\n",
        "# Discussion TODOS\n",
        "# try hierarhical interaction (TODO)\n",
        "\n",
        "# try bringing in modalities (image, or video)\n",
        "\n",
        "# Go from classical algorithm -> deep learning\n",
        "\n",
        "class MulticlassClassifier(nn.Module):\n",
        "    def __init__(self,bert_model_path):\n",
        "        super(MulticlassClassifier,self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=False)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(768, 1024)\n",
        "        self.fc2 = nn.Linear(576, 1024)\n",
        "        self.fc3 = nn.Linear(1024, 512)\n",
        "        self.act = torch.nn.ReLU()\n",
        "        self.fc4 = nn.Linear(512, 1024)\n",
        "\n",
        "        self.multi_head_attention = MHSA(1024, 64,16)\n",
        "        self.multihead_attn = torch.nn.MultiheadAttention(embed_dim = 1024,  num_heads = 4, batch_first=True)\n",
        "\n",
        "\n",
        "    def forward(self,tokens,masks, targets=None, skip_attention=False):\n",
        "        # print(\"tokens\", tokens.shape)\n",
        "        outputs = self.bert(tokens, attention_mask=masks)[2]\n",
        "        # outputs[2] = outputs[2].permute(0,2,1)\n",
        "        # print(outputs[-2].shape)\n",
        "        output_1 = outputs[-1].permute(1,0,2)\n",
        "        # print(outputs[1].shape,outputs[0].shape)\n",
        "        output_1 = torch.mean(output_1, dim=0)\n",
        "        # output_2 = outputs[-2].permute(1,0,2)\n",
        "        # output_2 = torch.mean(output_2, dim=0)\n",
        "        # print(\"output_2\", output_2.shape, output_1.shape)\n",
        "        pooled_output = outputs[-1] # output_1 # torch.cat((output_1, output_2), dim=1)\n",
        "        # print(\"pooled_output\", pooled_output.shape)\n",
        "        x = self.fc1(pooled_output)\n",
        "        # x = self.fc2(x)\n",
        "        \n",
        "        targets_curr_batch = []\n",
        "        for index_1, input_x in enumerate(x):\n",
        "            # print(input_x.shape, torch.mean(input_x,dim=0).shape)\n",
        "            distance = cos_label(torch.mean(input_x,dim=0).reshape(1,-1), unique_poincare_tensor)\n",
        "            distances,indices = torch.topk(distance,1,largest=True)\n",
        "\n",
        "            target_distances = (F.normalize(unique_poincare_tensor[indices],p=2,dim=1) - F.normalize(unique_poincare_tensor,p=2,dim=1)).pow(2).sum(1) #cos_label(unique_poincare_tensor[indices].reshape(1,-1), unique_poincare_tensor)\n",
        "            distances,indices = torch.topk(target_distances,5,largest=False)\n",
        "            targets_curr_batch.append(unique_poincare_tensor[indices].reshape(1,5,1024))\n",
        "            # print(\"here\")\n",
        "        # print(len(targets_curr_batch))\n",
        "        targets_batch = torch.cat(targets_curr_batch, dim=0)\n",
        "        # print(\"targets_batch\",targets_batch.shape)\n",
        "        # if not skip_attention:\n",
        "          # print(\"here attention\")\n",
        "        attn_output, attn_output_weights = self.multihead_attn(targets_batch, x, x)\n",
        "        # target_attn_output, attn_output_weights = self.multihead_attn(x, targets_batch, targets_batch)\n",
        "\n",
        "        x = torch.sum(attn_output,dim=1)\n",
        "        # target_final = torch.mean(target_attn_output, dim=1)\n",
        "        # x = self.act(x)\n",
        "        # x = self.fc4(x)\n",
        "        # print(\"X shape\",targets_batch.unsqueeze(dim=1).shape,x.shape,attn_output.shape)\n",
        "        return x\n",
        "\n",
        "class MyHingeLoss(torch.nn.Module):\n",
        "    def __init__(self, margin):\n",
        "        super(MyHingeLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    # def forward_val(self, output, target):\n",
        "    #     cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "    #     loss = 0\n",
        "    #     num_compare = 4\n",
        "    #     count = 0\n",
        "    #     for i in range(len(output)):\n",
        "    #         v_image = output[i]\n",
        "    #         t_label = target[i]\n",
        "    #         for j in range(num_compare):\n",
        "    #             if j != i:\n",
        "    #                 count += 1\n",
        "    #                 t_j = target[j]\n",
        "    #                 loss += torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n",
        "    #     return loss / count\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        loss=0\n",
        "        for i in range(len(output)):\n",
        "            v_image = F.normalize(output[i],p=2,dim=0)\n",
        "            t_label = F.normalize(target[i],p=2,dim=0)\n",
        "            # j = randint(0, len(output)-1)\n",
        "            # while j == i:\n",
        "            #     j = randint(0, len(output)-1)\n",
        "            distance = cos_label(t_label, target)\n",
        "            # print(distance.shape)\n",
        "            delta = min(len(target)-2,8)\n",
        "            distances,indices = torch.topk(distance,len(target)-delta,largest=True)\n",
        "            # print(indices)\n",
        "            # index_target = random.choice(indices)\n",
        "            # while index_target == i:\n",
        "            #     # print(\"here***\", index_target,i)\n",
        "            #     index_target = random.choice(indices)\n",
        "            count = 0\n",
        "            for index_target in indices:\n",
        "                if index_target!=i:\n",
        "                    count=count+1\n",
        "                    t_j = F.normalize(target[index_target],p=2,dim=0)\n",
        "                    loss+= torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n",
        "            # print(\"count\",count)\n",
        "        return loss / (len(output) * count)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAcOo5z1qTQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a13c70-cfe3-4438-c75b-ef7f2b4b1934"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "a= torch.tensor([[-0.4821,  1.059], [-0.4821,  1.059]])\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHYyjxMDIx2U"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2tmAMlw3khr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "776c8053-ed06-47be-91f8-50bc6b3e4e3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MulticlassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=768, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=576, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (act): ReLU()\n",
              "  (fc4): Linear(in_features=512, out_features=1024, bias=True)\n",
              "  (multi_head_attention): MHSA(\n",
              "    (w_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "    (w_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "    (w_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "    (w_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (multihead_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# Loads BertModel, the pretrained BERT model with a single \n",
        "model = MulticlassClassifier('bert-base-uncased')\n",
        "model.load_state_dict(torch.load('model_euclidean_SENT_BERT_cos_attention_2_V3/model_weights'))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4paz_8iTZ9o"
      },
      "outputs": [],
      "source": [
        "# mobius_params = []\n",
        "# bert_params = []\n",
        "\n",
        "# def mobius_params():\n",
        "#   for param in model.named_parameters():\n",
        "#     if 'fc' in param[0]:\n",
        "#       yield param[1]\n",
        "# def bert_params():\n",
        "#   for param in model.named_parameters():\n",
        "#     if 'bert' in param[0]:\n",
        "#       yield param[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awQ2Y9Jb3kht"
      },
      "outputs": [],
      "source": [
        "optimizer_1 = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "# optimizer_2 = radam_.RiemannianAdam(mobius_params(), lr=0.01, stabilize=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrYqErOD3khx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fb6edd-8599-4a45-d41f-d7dbf8b73ca1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1278"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "len(train_dataloader) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWVSE9LM3kh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ddc2700-3b42-49d6-81c6-6d12e811b203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "1935 * 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "outputs": [],
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer_1, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import numpy as np\n",
        "\n",
        "# # Function to calculate the accuracy of our predictions vs labels\n",
        "# def flat_accuracy(preds, labels):\n",
        "#     pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#     labels_flat = labels.flatten()\n",
        "#     return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsInxVoqbsFW"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di68jXK5WaYr"
      },
      "outputs": [],
      "source": [
        "criterion = MyHingeLoss(0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRcFqo9Ya6h6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# course_taxonomy\n",
        "train_labels = list(set(train_data[\"board_syllabus\"].values))\n",
        "emb_data_train = get_cleaned_taxonomy(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7YLX-ZCa6h7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97f0a0d-7a57-433c-b3a6-1d880d1b35b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# taxonomy_vectors = []\"\"\n",
        "taxonomy_vectors = sent_model.encode(emb_data_train)\n",
        "taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "taxonomy_vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQJ8KR5na6h7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "unique_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFKXxjBq7u66"
      },
      "outputs": [],
      "source": [
        "unique_poincare_tensor = unique_poincare_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LhAy2hZ3kh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e111d1-9191-4169-f107-67fc5adc7ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:56.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:55.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:53.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:51.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:50.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:48.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:46.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:45.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:43.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:41.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:40.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:38.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:36.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:35.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:33.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:31.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:30.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:28.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:26.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:24.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:23.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:21.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:19.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:17.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:16.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:14.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:12.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:11.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:09.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:07.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:31:03\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (inf --> 0.005910).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:38\n",
            "Saving model to model_euclidean_SENT_BERT_cos_attention_2_V3/\n",
            "\n",
            "======== Epoch 2 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:01:00.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:58.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:52.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:50.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:49.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:46.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:44.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:42.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:40.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:39.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:37.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:35.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:33.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:32.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:30.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:28.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:26.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:25.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:23.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:21.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:19.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:17.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:16.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:14.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:12.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:11.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:09.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:07.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:03\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.005910 --> 0.004605).  Saving model ...\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:38\n",
            "Saving model to model_euclidean_SENT_BERT_cos_attention_2_V3/\n",
            "\n",
            "======== Epoch 3 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:01:00.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:58.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:55.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:49.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:46.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:44.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:42.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:40.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:38.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:37.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:35.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:33.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:31.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:29.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:28.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:26.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:24.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:22.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:21.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:19.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:17.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:15.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:14.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:12.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:10.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:08.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:07.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:02\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.004605 --> 0.004273).  Saving model ...\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:38\n",
            "Saving model to model_euclidean_SENT_BERT_cos_attention_2_V3/\n",
            "\n",
            "======== Epoch 4 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:01:00.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:58.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:49.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:47.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:46.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:44.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:42.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:41.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:39.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:37.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:36.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:34.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:33.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:31.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:29.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:28.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:26.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:24.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:23.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:21.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:19.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:18.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:16.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:14.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:12.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:11.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:09.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:04\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.004273 --> 0.003821).  Saving model ...\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:38\n",
            "Saving model to model_euclidean_SENT_BERT_cos_attention_2_V3/\n",
            "\n",
            "======== Epoch 5 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:01:00.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:58.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:57.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:56.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:54.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:54.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:52.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:51.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:51.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:49.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:49.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:47.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:45.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:43.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:42.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:40.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:38.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:36.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:34.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:33.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:31.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:29.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:27.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:25.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:24.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:22.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:20.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:18.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:16.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:14.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:13.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:08\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.003821 --> 0.003650).  Saving model ...\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:38\n",
            "Saving model to model_euclidean_SENT_BERT_cos_attention_2_V3/\n",
            "\n",
            "======== Epoch 6 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:01:00.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:58.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:57.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:55.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:54.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:52.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:50.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:47.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:43.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:40.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:38.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:37.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:35.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:33.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:31.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:30.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:28.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:26.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:24.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:23.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:21.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:19.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:18.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:16.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:14.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:13.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:11.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:09.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:05\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.003650 --> 0.003632).  Saving model ...\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:38\n",
            "Saving model to model_euclidean_SENT_BERT_cos_attention_2_V3/\n",
            "\n",
            "======== Epoch 7 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:01:00.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:58.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:55.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:49.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:46.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:43.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:41.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:40.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:38.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:36.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:35.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:33.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:31.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:29.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:28.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:26.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:24.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:22.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:20.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:19.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:17.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:15.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:13.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:11.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:10.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:08.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:03\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 1 out of 6\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 8 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:55.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:53.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:51.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:49.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:48.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:46.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:44.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:42.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:41.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:39.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:37.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:35.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:34.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:32.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:30.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:29.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:27.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:25.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:24.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:22.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:20.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:19.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:17.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:15.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:14.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:12.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:10.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:08.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:07.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:02\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.003632 --> 0.003577).  Saving model ...\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:38\n",
            "Saving model to model_euclidean_SENT_BERT_cos_attention_2_V3/\n",
            "\n",
            "======== Epoch 9 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:01:00.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:58.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:57.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:55.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:50.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:46.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:44.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:43.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:41.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:39.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:38.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:36.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:35.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:33.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:31.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:29.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:28.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:26.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:24.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:22.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:21.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:19.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:18.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:17.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:15.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:13.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:12.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:10.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:31:05\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 1 out of 6\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 10 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:55.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:53.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:51.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:50.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:48.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:46.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:44.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:43.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:41.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:39.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:37.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:35.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:33.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:31.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:29.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:27.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:26.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:24.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:23.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:21.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:20.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:18.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:16.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:13.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:12.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:09.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:07.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:05.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:03.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:30:58\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 2 out of 6\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 11 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:56.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:54.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:52.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:50.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:48.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:46.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:44.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:42.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:40.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:38.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:36.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:34.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:33.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:31.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:29.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:27.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:25.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:23.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:21.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:19.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:17.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:15.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:14.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:12.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:10.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:08.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:06.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:04.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:02.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:00.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:30:55\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 3 out of 6\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 12 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:55.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:53.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:51.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:49.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:47.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:45.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:43.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:41.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:39.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:37.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:35.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:33.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:31.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:29.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:27.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:26.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:24.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:22.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:20.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:18.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:16.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:14.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:12.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:10.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:08.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:07.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:05.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:03.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:01.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:30:56\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 4 out of 6\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 13 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:56.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:54.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:52.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:50.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:49.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:47.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:45.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:43.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:41.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:39.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:37.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:35.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:33.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:31.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:29.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:27.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:25.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:24.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:22.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:20.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:18.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:16.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:14.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:12.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:11.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:09.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:07.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:05.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:03.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:01.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:30:56\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 5 out of 6\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 14 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of  1,278.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,278.    Elapsed: 0:01:56.\n",
            "  Batch   120  of  1,278.    Elapsed: 0:02:54.\n",
            "  Batch   160  of  1,278.    Elapsed: 0:03:52.\n",
            "  Batch   200  of  1,278.    Elapsed: 0:04:50.\n",
            "  Batch   240  of  1,278.    Elapsed: 0:05:49.\n",
            "  Batch   280  of  1,278.    Elapsed: 0:06:47.\n",
            "  Batch   320  of  1,278.    Elapsed: 0:07:45.\n",
            "  Batch   360  of  1,278.    Elapsed: 0:08:43.\n",
            "  Batch   400  of  1,278.    Elapsed: 0:09:41.\n",
            "  Batch   440  of  1,278.    Elapsed: 0:10:39.\n",
            "  Batch   480  of  1,278.    Elapsed: 0:11:38.\n",
            "  Batch   520  of  1,278.    Elapsed: 0:12:36.\n",
            "  Batch   560  of  1,278.    Elapsed: 0:13:34.\n",
            "  Batch   600  of  1,278.    Elapsed: 0:14:32.\n",
            "  Batch   640  of  1,278.    Elapsed: 0:15:30.\n",
            "  Batch   680  of  1,278.    Elapsed: 0:16:28.\n",
            "  Batch   720  of  1,278.    Elapsed: 0:17:26.\n",
            "  Batch   760  of  1,278.    Elapsed: 0:18:24.\n",
            "  Batch   800  of  1,278.    Elapsed: 0:19:22.\n",
            "  Batch   840  of  1,278.    Elapsed: 0:20:21.\n",
            "  Batch   880  of  1,278.    Elapsed: 0:21:19.\n",
            "  Batch   920  of  1,278.    Elapsed: 0:22:17.\n",
            "  Batch   960  of  1,278.    Elapsed: 0:23:15.\n",
            "  Batch 1,000  of  1,278.    Elapsed: 0:24:13.\n",
            "  Batch 1,040  of  1,278.    Elapsed: 0:25:11.\n",
            "  Batch 1,080  of  1,278.    Elapsed: 0:26:09.\n",
            "  Batch 1,120  of  1,278.    Elapsed: 0:27:07.\n",
            "  Batch 1,160  of  1,278.    Elapsed: 0:28:05.\n",
            "  Batch 1,200  of  1,278.    Elapsed: 0:29:03.\n",
            "  Batch 1,240  of  1,278.    Elapsed: 0:30:01.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:30:57\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 6 out of 6\n",
            "Early stopping\n",
            "\n",
            "Training complete!\n",
            "Total training took 7:23:30 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import f1_score\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=6, verbose=True)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad() \n",
        "        optimizer_1.zero_grad()       \n",
        "\n",
        "        logits = model(b_input_ids, \n",
        "                             b_input_mask,b_labels)\n",
        "        \n",
        "        loss = criterion.forward(logits,b_labels)\n",
        "\n",
        "  \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer_1.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_f1 = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "          logits = model(b_input_ids, \n",
        "                              b_input_mask,b_labels)\n",
        "          \n",
        "        loss = criterion(logits,b_labels)\n",
        "\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy().round()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        # total_eval_f1 += f1_score(label_ids,logits, average='macro')\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    # avg_val_accuracy = total_eval_f1 / len(validation_dataloader)\n",
        "    # print(\"  f1score: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break  \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'model_euclidean_SENT_BERT_cos_attention_2_V3/'\n",
        "    if early_stopping.counter==0:\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        print(\"Saving model to %s\" % output_dir)\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "        torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "\n",
        "        !rm -rf \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_SENT_BERT_cos_attention_2_V3\"\n",
        "        !mv model_euclidean_SENT_BERT_cos_attention_2_V3 \"/content/drive/My Drive/research_lo_content_taxonomy_classification/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDn6bRbr0fs3"
      },
      "outputs": [],
      "source": [
        "for i in range(1000000000000000000000000000000000000000000):\n",
        "    j=i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RACcsko3kh_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD7V6JOkotRE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "o5TicdiP3kiC",
        "outputId": "03f946db-6030-4902-8bf8-7e115ecc5384"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbiTDpVv3kiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51503dc-c016-480f-89f7-1c040656b6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to model_euclidean_SENT_BERT_cos_attention_2_V3/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_euclidean_SENT_BERT_cos_attention_2_V3/vocab.txt',\n",
              " 'model_euclidean_SENT_BERT_cos_attention_2_V3/special_tokens_map.json',\n",
              " 'model_euclidean_SENT_BERT_cos_attention_2_V3/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "output_dir = 'model_euclidean_SENT_BERT_cos_attention_2_V3/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U2UQ29a3kiI"
      },
      "outputs": [],
      "source": [
        "# !pip install joblib\n",
        "# import joblib\n",
        "# joblib.dump(LE, \"label_encoder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F5PxZm9vAOI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vlb0IpVJO1XQ"
      },
      "outputs": [],
      "source": [
        "# with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n",
        "#     json.dump(model.config, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpGY8vSDI6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23bd8b36-c945-4813-f4fd-52b01c3157f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: model_euclidean_SENT_BERT_cos_attention_2_V3/ (stored 0%)\n",
            "updating: model_euclidean_SENT_BERT_cos_attention_2_V3/tokenizer_config.json (stored 0%)\n",
            "updating: model_euclidean_SENT_BERT_cos_attention_2_V3/vocab.txt (deflated 53%)\n",
            "updating: model_euclidean_SENT_BERT_cos_attention_2_V3/special_tokens_map.json (deflated 40%)\n",
            "updating: model_euclidean_SENT_BERT_cos_attention_2_V3/model_weights (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r model_euclidean_SENT_BERT_cos_attention_2_V3.zip model_euclidean_SENT_BERT_cos_attention_2_V3\n",
        "# files.download('model_euclidean_1.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvFDCDIxKDOf"
      },
      "outputs": [],
      "source": [
        "# !zip -r label_encoder_categorized_reduced.zip label_encoder\n",
        "# files.download('label_encoder_categorized_reduced.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4178_yLFMWmx"
      },
      "outputs": [],
      "source": [
        "test_features = test_features.values\n",
        "labels = test_labels.values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lo classification"
      ],
      "metadata": {
        "id": "MWOP2Ee5PlqX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKdRT1UUz4vC"
      },
      "source": [
        "# Run this cell and next if you want to test on LO zero shot setting If you want to test on ARC skip them.\n",
        "import pandas as pd\n",
        "lo_data = pd.read_csv(\"what_you_learnt_lo_labelled.csv\", delimiter=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2kDnBDF0I3e"
      },
      "source": [
        "test_features = lo_data[\"learning_objectives\"].values\n",
        "labels = lo_data[\"taxonomy\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oww-EQlFbQWL"
      },
      "source": [
        "def get_cleaned_taxonomy_lo(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = ' '.join(value.lower().split(\">>\"))\n",
        "      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n",
        "      cleaned_taxonomy.append( value )\n",
        "  return cleaned_taxonomy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXLemgwUbS_r"
      },
      "source": [
        "#when testing for Lo data\n",
        "test_labels = list(set(lo_data[\"taxonomy\"].values))\n",
        "emb_data_test = get_cleaned_taxonomy_lo(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZpmBJuIC2nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5633d1fa-fac6-4dc4-d178-c0f738c5a186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['A complete chemical equation represents the reactants products and their physical states symbolically.',\n",
              "       'A chemical equation is balanced so that the numbers of atoms of each type involved in a chemical reaction are the same on the reactant and product sides of theequation. Equations must always be balanced.',\n",
              "       'In a combination reaction two or more substances combine to form a new singlesubstance.',\n",
              "       'Decomposition reactions are opposite to combination reactions. In a decomposition reaction a single substance decomposes to give two or more substances.',\n",
              "       'Reactions in which heat is given out along with the products are called exothermic reactions.',\n",
              "       'Reactions in which energy is absorbed are known as endothermic reactions.',\n",
              "       'When an element displaces another element from its compound a displacement reaction occurs.',\n",
              "       'Precipitation reactions produce insoluble salts.',\n",
              "       'Two different atoms or groups of atoms (ions) are exchanged in double displacement reactions.',\n",
              "       'Reactions also involve the gain or loss of oxygen or hydrogen by substances.',\n",
              "       'Oxidation is the gain of oxygen or loss of hydrogen.',\n",
              "       'Reduction is the loss of oxygen or gain of hydrogen.',\n",
              "       'Acid-base indicators are dyes or mixtures of dyes which are used to indicate the presence of acids and bases.',\n",
              "       'When an acid reacts with a metal hydrogen gas is evolved and a corresponding salt is formed.',\n",
              "       'When a base reacts with a metal along with the evolution of hydrogen gas a salt is formed which has a negative ion composed of the metal and oxygen.',\n",
              "       'Acidic and basic solutions in water conduct electricity because they produce hydrogen and hydroxide ions respectively.',\n",
              "       'Mixing concentrated acids or bases with water is a highly exothermic process.',\n",
              "       'Acids and bases neutralise each other to form corresponding salts and water.',\n",
              "       'Water of crystallisation is the fixed number of water molecules present in one formula unit of a salt.',\n",
              "       'Salts have various uses in everyday life and in industries.',\n",
              "       'Elements can be classified as metals and non-metals.',\n",
              "       'Metals are lustrous malleable ductile and are good conductors of heat and electricity. They are solids at room temperature, except mercury which is a liquid.',\n",
              "       'Metals can form positive ions by losing electrons to non-metals.',\n",
              "       'Different metals have different reactivities with water and dilute acids.',\n",
              "       'A list of common metals arranged in order of their decreasing reactivity is known as an activity series.',\n",
              "       'Metals above hydrogen in the Activity series can displace hydrogen from dilute acids.',\n",
              "       'A more reactive metal displaces a less reactive metal from its salt solution.',\n",
              "       'Metals occur in nature as free elements or in the form of their compounds.',\n",
              "       'The extraction of metals from their ores and then refining them for use is known as metallurgy.',\n",
              "       'An alloy is a homogeneous mixture of two or more metals or a metal and a non-metal.',\n",
              "       'The surface of some metals such as iron is corroded when they are exposed to moist air for a long period of time. This phenomenon is known as corrosion.',\n",
              "       'Non-metals form negatively charged ions by gaining electrons when reacting with metals.',\n",
              "       'Non-metals form oxides which are either acidic or neutral.',\n",
              "       'Non-metals do not displace hydrogen from dilute acids. They react with hydrogen to form hydrides.',\n",
              "       'Carbon is a versatile element that forms the basis for all living organisms and many of the things we use.',\n",
              "       'This large variety of compounds is formed by carbon because of its tetravalency and the property of catenation that it exhibits.',\n",
              "       'Covalent bonds are formed by the sharing of electrons between two atoms so that both can achieve a completely filled outermost shell.',\n",
              "       'The ability of carbon to form chains gives rise to a homologous series of compounds in which the same functional group is attached to carbon chains of different lengths.',\n",
              "       'The functional groups such as alcohols aldehydes ketones and carboxylic acids bestow characteristic properties to the carbon compounds that contain them.',\n",
              "       'Carbon and its compounds are some of our major sources of fuels.',\n",
              "       'Ethanol and ethanoic acid are carbon compounds of importance in our daily lives.',\n",
              "       'The action of soaps and detergents is based on the presence of both hydrophobic and hydrophilic groups in the molecule and this helps to emulsify the oily dirt and hence its removal.',\n",
              "       'Elements are classified on the basis of similarities in their properties.',\n",
              "       'Mendeléev arranged the elements in increasing order of their atomic masses and according to their chemical properties.',\n",
              "       'Elements thus arranged show periodicity of properties including atomic size, valency or combining capacity and metallic and non-metallic character.',\n",
              "       'Elements in the Modern Periodic Table are arranged in 18 vertical columns called groups and 7 horizontal rows called periods.',\n",
              "       'Movement of various types can be taken as an indication of life.',\n",
              "       'Maintenance of life requires processes like nutrition respiration transport of materials within the body and excretion of waste products.',\n",
              "       'Autotrophic nutrition involves the intake of simple inorganic materials from the environment and using an external energy source like the Sun to synthesise complex high-energy organic material',\n",
              "       'Heterotrophic nutrition involves the intake of complex material prepared by other organisms.',\n",
              "       'In human beings the food eaten is broken down by various steps along the alimentary canal and the digested food is absorbed in the small intestine to be sent  to all cells in the body.',\n",
              "       'During the process of respiration organic compounds such as glucose are broken down to provide energy in the form of ATP. ATP is used to provide energy for other  reactions in the cell.',\n",
              "       'Respiration may be aerobic or anaerobic. Aerobic respiration makes more energy available to the organism.',\n",
              "       'In human beings the transport of materials such as oxygen carbon dioxide foodand excretory products is a function of the circulatory system. The circulatory system consists of the heart, blood and blood vessels.',\n",
              "       'In highly differentiated plants transport of water minerals food and other materials is a function of the vascular tissue which consists of xylem and phloem.',\n",
              "       'In human beings excretory products in the form of soluble nitrogen compounds are removed by the nephrons in the kidneys.',\n",
              "       'Plants use a variety of techniques to get rid of waste material. For example waste material may be stored in the cell-vacuoles or as gum and resin removed in the falling leaves or excreted into the surrounding soil.',\n",
              "       'Control and coordination are the functions of the nervous system and hormones in our bodies.',\n",
              "       'The responses of the nervous system can be classified as reflex action voluntary action or involuntary action.',\n",
              "       'The nervous system uses electrical impulses to transmit messages.',\n",
              "       'The nervous system gets information from our sense organs and acts through our muscles.',\n",
              "       'Chemical coordination is seen in both plants and animals.',\n",
              "       'Hormones produced in one part of an organism move to another part to achieve the desired effect.',\n",
              "       'A feedback mechanism regulates the action of the hormones.',\n",
              "       'Reproduction unlike other life processes is not essential to maintain the life of an individual organism.',\n",
              "       'Reproduction involves creation of a DNA copy and additional cellular apparatus by the cell involved in the process.',\n",
              "       'Various organisms use different modes of reproduction depending on their body design.',\n",
              "       'In fission many bacteria and protozoa simply divide into two or more daughter cells.',\n",
              "       'Organisms such as hydra can regenerate if they are broken into pieces. They can also give out buds which mature into new individuals.',\n",
              "       'Roots stems and leaves of some plants develop into new plants through vegetative propagation',\n",
              "       'These are examples of asexual reproduction where new generations are created from a single individual.',\n",
              "       'Sexual reproduction involves two individuals for the creation of a new individual.',\n",
              "       'DNA copying mechanisms creates variations which are useful for ensuring the survival of the species. Modes of sexual reproduction allow for greater variation to be generated.',\n",
              "       'Reproduction in flowering plants involves transfer of pollen grains from the anther to the stigma which is referred to as pollination. This is followed by fertilisation.',\n",
              "       'Changes in the body at puberty such as increase in breast size in girls and new facial hair growth in boys are signs of sexual maturation.',\n",
              "       'The male reproductive system in human beings consists of testes which produce sperms vas deferens seminal vesicles prostate gland urethra and penis.',\n",
              "       'The female reproductive system in human beings consists of ovaries fallopian tubes uterus and vagina.',\n",
              "       'Sexual reproduction in human beings involves the introduction of sperm in the vagina of the female. Fertilisation occurs in the fallopian tube.',\n",
              "       'Speciation may take place when variation is combined with geographical isolation.',\n",
              "       'Evolutionary relationships are traced in the classification of organisms.',\n",
              "       'Tracing common ancestors back in time leads us to the idea that at some point of time non-living material must have given rise to life.',\n",
              "       'Evolution can be worked out by the study of not just living species but also fossils.',\n",
              "       'Complex organs may have evolved because of the survival advantage of even the intermediate stages.',\n",
              "       'Organs or features may be adapted to new functions during the course of evolution.',\n",
              "       'Light seems to travel in straight lines.',\n",
              "       'Mirrors and lenses form images of objects. Images can be either real or virtual, depending on the position of the object.',\n",
              "       'The reflecting surfaces of all types obey the laws of reflection. The refracting surfaces obey the laws of refraction.',\n",
              "       'Mirror formula gives the relationship between the object-distance (u) image-distance (v) and focal length (f) of a spherical mirror.',\n",
              "       'The focal length of a spherical mirror is equal to half its radius of curvature.',\n",
              "       'The magnification produced by a spherical mirror is the ratio of the height of the image to the height of the object.',\n",
              "       'A light ray travelling obliquely from a denser medium to a rarer medium bends away from the normal.',\n",
              "       'A light ray bends towards the normal when it travels obliquely from a rarer to a denser medium.',\n",
              "       'The speed of light is different in different media.',\n",
              "       'The refractive index of a transparent medium is the ratio of the speed of light in vacuum to that in the medium.',\n",
              "       'Power of a lens is the reciprocal of its focal length.',\n",
              "       'Lens formula gives the relationship between the object-distance (u) image-distance (v) and the focal length (f) of a spherical lens.',\n",
              "       'The ability of the eye to focus on both near and distant objects by adjusting its focal length is called the accommodation of the eye.',\n",
              "       'The smallest distance at which the eye can see objects clearly without strain is called the near point of the eye or the least distance of distinct vision. For a young adult with normal vision it is about 25 cm.',\n",
              "       'The common refractive defects of vision include myopia hypermetropia and presbyopia.',\n",
              "       'Myopia (short-sightedness – the image of distant objects is focussed before the retina) is corrected by using a concave lens of suitable power.',\n",
              "       'Hypermetropia (far-sightedness – the image of nearby objects is focussed beyond the retina) is corrected by using a convex lens of suitable power.',\n",
              "       'The splitting of white light into its component colours is called dispersion.',\n",
              "       'Scattering of light causes the blue colour of sky and the reddening of the Sun at sunrise and sunset.',\n",
              "       'A stream of electrons moving through a conductor constitutes an electric current. Conventionally, the direction of current is taken opposite to the direction of flow of electrons.',\n",
              "       'The SI unit of electric current is ampere.',\n",
              "       'To set the electrons in motion in an electric circuit we use a cell or a battery. A cell generates a potential difference across its terminals. It is measured in volts (V).',\n",
              "       'Resistance is a property that resists the flow of electrons in a conductor.',\n",
              "       'The potential difference across the ends of a resistor is directly  proportional to the current through it, provided its temperature remains the same.',\n",
              "       'The resistance of a conductor depends directly on its length inversely on its area of cross-section and also on the material of the conductor.',\n",
              "       'The equivalent resistance of several resistors in series is equal to the sum of their individual resistances.',\n",
              "       'A magnetic field exists in the region surrounding a magnet in which the force of the magnet can be detected.',\n",
              "       'Field lines are used to represent a magnetic field.',\n",
              "       'A metallic wire carrying an electric current has associated with it a magnetic field.',\n",
              "       'The field lines about the wire consist of a series of concentric circles whose direction is given by the right-hand rule.',\n",
              "       'The pattern of the magnetic field around a conductor due to an electric current flowing through it depends on the shape of the conductor.',\n",
              "       'The magnetic field of a solenoid carrying a current is similar to that of a bar magnet.',\n",
              "       'An electromagnet consists of a core of soft iron wrapped around with a coil of insulated copper wire.',\n",
              "       'A current-carrying conductor when placed in a magnetic field experiences a force.',\n",
              "       'If the direction of the field and that of the current are mutually perpendicular to each other, then the force acting on the conductor will be perpendicular to both and will be given by Fleming’s left-hand rule',\n",
              "       'The phenomenon of electromagnetic induction is the production of induced current in a coil placed in a region where the magnetic field changes with time.',\n",
              "       'A generator converts mechanical energy into electrical energy. It works on the basis of electromagnetic induction.',\n",
              "       'Fuse is the most important safety device used for protecting the circuits due to short-circuiting or overloading of the circuits.',\n",
              "       'Many of the sources ultimately derive their energy from the Sun.',\n",
              "       'The producers make the energy from sunlight available to the rest of the ecosystem.',\n",
              "       'The various components of an ecosystem are interdependent.',\n",
              "       'There is a loss of energy as we go from one trophic level to the next, this limits the number of trophic levels in a food-chain.',\n",
              "       'The use of chemicals like CFCs has endangered the ozone layer. Since the ozone layer protects against the ultraviolet radiation from the Sun, this could damage the environment.',\n",
              "       'The waste we generate may be biodegradable or non-biodegradable.',\n",
              "       'The disposal of the waste we generate is causing serious environmental problems.',\n",
              "       'Our resources like forests wildlife water coal and petroleum need to be used in a sustainable manner.',\n",
              "       'Matter is made up of small particles.',\n",
              "       'The matter around us exists in three states— solid liquid and gas.',\n",
              "       'The forces of attraction between the particles are maximum in solids, intermediate in liquids and minimum in gases.',\n",
              "       'The spaces in between the constituent particles and kinetic energy of the particles are minimum in the case of solids, intermediate in liquids and maximum in gases.',\n",
              "       'The states of matter are inter-convertible. The state of matter can be changed by changing temperature or pressure.',\n",
              "       'Sublimation is the change of solid state directly to gaseous state without going through liquid state.',\n",
              "       'Deposition is the change of gaseous state directly to solid state without going through liquid state.',\n",
              "       'Boiling is a bulk phenomenon. Particles from the bulk (whole) of the liquid change into vapour state.',\n",
              "       'Evaporation is a surface phenomenon. Particles from the surface gain enough energy to overcome the forces of attraction present in the liquid and change into the vapour state.',\n",
              "       'The rate of evaporation depends upon the surface area exposed to the atmosphere the temperature the humidity and the wind speed.',\n",
              "       'Evaporation causes cooling.',\n",
              "       'Latent heat of vaporisation is the heat energy required to change 1 kg of a liquid to gas at atmospheric pressure at its boiling point.',\n",
              "       'Latent heat of fusion is the amount of heat energy required to change 1 kg of solid into liquid at its melting point.',\n",
              "       'A mixture contains more than one substance (element and/ or compound) mixed in any proportion.',\n",
              "       'Mixtures can be separated into pure substances using appropriate separation techniques.',\n",
              "       'A solution is a homogeneous mixture of two or more substances. The major component of a solution is called the solvent and the minor the solute.',\n",
              "       'The concentration of a solution is the amount of solute present per unit volume or per unit mass of the solution.',\n",
              "       'Materials that are insoluble in a solvent and have particles that are visible to naked eyes, form a suspension. A suspension is a heterogeneous mixture.',\n",
              "       'Colloids are heterogeneous mixtures in which the particle size is too small to be seen with the naked eye, but is big enough to scatter light.',\n",
              "       'The particles are called the dispersed phase and the medium in which they are distributed is called the dispersion medium.',\n",
              "       'An element is a form of matter that cannot be broken down by chemical reactions into simpler substances.',\n",
              "       'A compound is a substance composed of two or more different types of elements chemically combined in a fixed proportion.',\n",
              "       'Properties of a compound are different from its constituent elements whereas a mixture shows the properties of its constituting elements or compounds.',\n",
              "       'During a chemical reaction the sum of the masses of the reactants and products remains unchanged. This is known as the Law of Conservation of Mass.',\n",
              "       'According to the Law of Definite Proportions in a pure chemical compound elements are always present in a definite proportion by mass.',\n",
              "       'An atom is the smallest particle of the element that cannot usually exist independently and retain all its chemical properties.',\n",
              "       'A molecule is the smallest particle of an element or a compound capable of independent existence under ordinary conditions. It shows all the properties of the substance.',\n",
              "       'A chemical formula of a compound shows its constituent elements and the number of atoms of each combining element.',\n",
              "       'Clusters of atoms that act as an ion are called polyatomic ions.',\n",
              "       'The chemical formula of a molecular compound is determined by the valency of each element.',\n",
              "       'In ionic compounds the charge on each ion is used to determine the chemical formula of the compound.',\n",
              "       'Mass of 1 mole of a substance is called its molar mass.',\n",
              "       'Rutherford’s model of the atom proposed that a very tiny nucleus is present inside the atom and electrons revolve around this nucleus.',\n",
              "       'Valency is the combining capacity of an atom.',\n",
              "       'The atomic number of an element is the same as the number of protons in the nucleus of its atom.',\n",
              "       'The mass number of an atom is equal to the number of nucleons in its nucleus.',\n",
              "       'Isotopes are atoms of the same element, which have different mass numbers.',\n",
              "       'Elements are defined by the number of protons they possess.',\n",
              "       'Isobars are atoms having the same mass number but different atomic numbers.',\n",
              "       'The fundamental organisational unit of life is the cell.',\n",
              "       'Cells are enclosed by a plasma membrane composed of lipids and proteins.',\n",
              "       'The cell membrane is an active part of the cell. It regulates the movement of materials between the ordered interior of the cell and the outer environment.',\n",
              "       'In plant cells a cell wall composed mainly of cellulose is located outside the cell membrane.',\n",
              "       'The presence of the cell wall enables the cells of plants fungi and bacteria to exist in hypotonic media without bursting.',\n",
              "       'The nucleus in eukaryotes is separated from the cytoplasm by double-layered membrane and it directs the life processes of the cell.',\n",
              "       'The ER functions both as a passageway for intracellular transport and as a manufacturing surface. Chromoplasts that contain chlorophyll are called chloroplasts and they perform photosynthesis.',\n",
              "       'The primary function of leucoplasts is storage.',\n",
              "       'Most mature plant cells have a large central vacuole that helps to maintain the turgidity of the cell and stores important substances including wastes.',\n",
              "       'Prokaryotic cells have no membrane-bound organelles their chromosomes are composed of only nucleic acid and they have only very small ribosomes as organelles.',\n",
              "       'Cells in organisms divide for growth of body for repalcing dead cells and for forming gametes for reproduction.',\n",
              "       'Tissue is a group of cells similar in structure and function.',\n",
              "       'Plant tissues are of two main types – meristematic and permanent.',\n",
              "       'Meristematic tissue is the dividing tissue present in the growing regions of the plant.',\n",
              "       'Permanent tissues are derived from meristematic tissue once they lose the ability to divide. They are classified as simple and complex tissues.',\n",
              "       'Animal tissues can be epithelial connective muscular and nervous tissue.',\n",
              "       'Depending on shape and function epithelial tissue is classified as squamous cuboidal columnar ciliated and glandular.',\n",
              "       'The different types of connective tissues in our body include areolar tissue adipose tissue bone tendon ligament cartilage and blood.',\n",
              "       'Striated, unstriated and cardiac are three types of muscle tissues.',\n",
              "       'Nervous tissue is made of neurons that receive and conduct impulses.',\n",
              "       'Classification helps us in exploring the diversity of life forms.',\n",
              "       'The classification of life forms is related to their evolution.',\n",
              "       'Plantae and Animalia are further divided into subdivisions on the basis of increasing complexity of body organisation.',\n",
              "       'Plants are divided into five groups: Thallophytes Bryophytes Pteridophytes Gymnosperms and Angiosperms.',\n",
              "       'The binomial nomenclature makes for a uniform way of identification of the vast diversity of life around us.',\n",
              "       'The binomial nomenclature is made up of two words – a generic name and a specific name.',\n",
              "       'Motion is a change of position; it can be described in terms of the distance moved or the displacement.',\n",
              "       'The motion of an object could be uniform or non-uniform depending on whether its velocity is constant or changing.',\n",
              "       'The speed of an object is the distance covered per unit time, and velocity is the displacement per unit time.',\n",
              "       'The acceleration of an object is the change in velocity per unit time.',\n",
              "       'If an object moves in a circular path with uniform speed, its motion is called uniform circular motion.',\n",
              "       'The natural tendency of objects to resist a change in their state of rest or of uniform motion is called inertia.',\n",
              "       'The mass of an object is a measure of its inertia. Its SI unit is kilogram (kg).',\n",
              "       'Force of friction always opposes motion of objects.',\n",
              "       'The rate of change of momentum of an object is proportional to the applied unbalanced force in the direction of the force.',\n",
              "       'The momentum of an object is the product of its mass and velocity and has the same direction as that of the velocity.',\n",
              "       'To every action, there is an equal and opposite reaction and they act on two different bodies.',\n",
              "       'In an isolated system (where there is no external force), the total momentum remains conserved.',\n",
              "       'An object continues to be in a state of rest or of uniform motion along a straight line unless acted upon by an unbalanced force.',\n",
              "       'The law of gravitation states that the force of attraction between any two objects is proportional to the product of their masses and inversely proportional to the square of the distance between them.',\n",
              "       'Gravitation is a weak force unless large masses are involved.',\n",
              "       'The force of gravity decreases with altitude. It also varies on the surface of the earth, decreasing from poles to the equator.',\n",
              "       'The weight of a body is the force with which the earth attracts it.',\n",
              "       'The weight is equal to the product of mass and acceleration due to gravity.',\n",
              "       'The weight may vary from place to place but the mass stays constant.',\n",
              "       'All objects experience a force of buoyancy when they are immersed in a fluid.',\n",
              "       'Objects having density less than that of the liquid in which they are immersed, float on the surface of the liquid. If the density of the object is more than the density of the liquid in which it is immersed then it sinks in the liquid.',\n",
              "       'Work done on an object is defined as the magnitude of the force multiplied by the distance moved by the object in the direction of the applied force.',\n",
              "       'Work done on an object by a force would be zero if the displacement of the object is zero.',\n",
              "       'An object having capability to do work is said to possess energy.',\n",
              "       'An object in motion possesses what is known as the kinetic energy of the object.',\n",
              "       'The energy possessed by a body due to its change in position or shape is called the potential energy.',\n",
              "       'According to the law of conservation of energy energy can only be transformed from one form to another; it can neither be created nor destroyed.',\n",
              "       'Sound is produced due to vibration of different objects.',\n",
              "       'Sound travels as a longitudinal wave through a material medium.',\n",
              "       'Sound travels as successive compressions and rarefactions in the medium.',\n",
              "       'In sound propagation it is the energy of the sound that travels and not the particles of the medium.',\n",
              "       'Sound cannot travel in vacuum.',\n",
              "       'The change in density from one maximum value to the minimum value and again to the maximum value makes one complete oscillation.',\n",
              "       'The distance between two consecutive compressions or two consecutive rarefactions is called the wavelength.',\n",
              "       'The time taken by the wave for one complete oscillation of the density or pressure of the medium is called the time period.',\n",
              "       'The number of complete oscillations per unit time is called the frequency.',\n",
              "       'The speed of sound depends primarily on the nature and the temperature of the transmitting medium.',\n",
              "       'The persistence of sound in an auditorium is the result of repeated reflections of sound and is called reverberation.',\n",
              "       'Sound properties such as pitch loudness and quality are determined by the corresponding wave properties.',\n",
              "       'Sound waves with frequencies below the audible range are termed “infrasonic” and those above the audible range are termed “ultrasonic”.',\n",
              "       'Health is a state of physical mental and social well-being.',\n",
              "       'Diseases are classified as acute or chronic depending on their duration.',\n",
              "       'Infectious agents belong to different categories of organisms and may be unicellular and microscopic or multicellular.',\n",
              "       'The category to which a disease-causing organism belongs decides the type of treatment.',\n",
              "       'Infectious agents are spread through air water physical contact or vectors.',\n",
              "       'Prevention of disease is more desirable than its successful treatment.',\n",
              "       'Infectious diseases can be prevented by public health hygiene measures that reduce exposure to infectious agents.',\n",
              "       'Infectious diseases can also be prevented by using immunisation.',\n",
              "       'Effective prevention of infectious diseases in the community requires that everyone should have access to public hygiene and immunisation.',\n",
              "       'Life on Earth depends on resources like soil water and air and energy from the Sun.',\n",
              "       'Uneven heating of air over land and water-bodies causes winds.',\n",
              "       'Evaporation of water from water -bodies and subsequent condensation give us rain.',\n",
              "       'Rainfall patterns depend on the prevailing wind patterns in an area.',\n",
              "       'Various nutrients are used again and again in a cyclic fashion. This leads to a certain balance between the various components of the biosphere.',\n",
              "       'Pollution of air water and soil affect the quality of life and harm the biodiversity.',\n",
              "       'We need to conserve our natural resources and use them in a sustainable manner.',\n",
              "       'Manure and fertilizers are the main sources of nutrient supply to crops.',\n",
              "       'Organic farming is a farming system with minimal or no use of chemicals as fertilizers herbicides pesticides etc. and with a maximum input of organic manures recyled farm wastes  and bio-agents, with healthy cropping systems.',\n",
              "       'Mixed farming is a system of farming on a particular farm which includes crop production, raising of livestock etc.',\n",
              "       'Mixed cropping is growing of two or more crops simultaneously on the same piece of land.',\n",
              "       'Growing two or more crops in definite row patterns is known as inter-cropping.',\n",
              "       'The growing of different crops on a piece of land in pre-planned succession is called crop rotation.',\n",
              "       'Varietal improvement is required for higher yield good quality biotic and abiotic resistance shortening the maturity duration wider adaptability and desirable agronomic characteristics.',\n",
              "       'Farm animals require proper care and management such as shelter feeding breeding and disease control. This is called animal husbandry.',\n",
              "       'Poultry farming is done to raise domestic fowls. Poultry production includes egg production and broiler production for poultry meat.',\n",
              "       'To enhance poultry production cross breeding is done between Indian and exotic breeds for variety improvement.',\n",
              "       'Marine fish capture is done by fishing nets guided by echo- sounders and satellites.',\n",
              "       'Composite fish culture system is commonly used for fish farming.',\n",
              "       'In order to provide food to our growing population we need to adopt certain agricultural practices.',\n",
              "       'Same kind of plants cultivated at a place constitute a crop.',\n",
              "       'In India crops can be broadly categorised into two types based on seasons - rabi and kharif crops.',\n",
              "       'It is necessary to prepare soil by tilling and levelling. Ploughs and levellers are used for this purpose.',\n",
              "       'Sowing of seeds at appropriate depths and distances gives good yield. Good variety of seeds are sown after selection of healthy seeds. Sowing is done by seed drills.',\n",
              "       'Soil needs replenishment and enrichment through the use of organic manure and fertilisers. Use of chemical fertilisers has increased tremendously with the introduction of new crop varieties.',\n",
              "       'Supply of water to crops at appropriate intervals is called irrigation.',\n",
              "       'Weeding involves removal of unwanted and uncultivated plants called weeds.',\n",
              "       'Harvesting is the cutting of the mature crop manually or by machines.',\n",
              "       'Separation of the grains from the chaff is called threshing.',\n",
              "       'Proper storage of grains is necessary to protect them from pests and microorganisms.',\n",
              "       'Food is also obtained from animals for which animals are reared. This is called animal husbandry.',\n",
              "       'Microorganisms are too small and are not visible to the unaided eye',\n",
              "       'They can live in all kinds of environment ranging from ice cold climate to hot springs and deserts to marshy lands.',\n",
              "       'Microorganisms are found in air water and in the bodies of plants and animals.',\n",
              "       'Microorganisms may be unicellular or multicellular.',\n",
              "       'Microorganisms include bacteria fungi protozoa and some algae. Viruses though different from the above mentioned living organisms are considered microbes.',\n",
              "       'Viruses are quite different from other microorganisms. They reproduce only inside the host organism: bacterium, plant or animal cell.',\n",
              "       'Some microorganisms are useful for commercial production of medicines and alcohol.',\n",
              "       'Some microorganisms decompose the organic waste and dead plants and animals into simple substances and clean up the environment.',\n",
              "       'Protozoans cause serious diseases like dysentery and malaria.',\n",
              "       'Some of the microorganisms grow on our food and cause food poisoning.',\n",
              "       'Some microorganisms reside in the root nodules of leguminous plants. They can fix nitrogen from air into soil and increase the soil fertility.',\n",
              "       'Some bacteria present in the soil fix nitrogen from the atmosphere and convert into nitrogenous compounds.',\n",
              "       'Certain bacteria convert compounds of nitrogen present in the soil into nitrogen gas which is released to the atmosphere.',\n",
              "       'Synthetic fibres and plastics like natural fibres are made of very large units called polymers. Polymers are made up of many smaller units',\n",
              "       'While natural fibres are obtained from plants and animals synthetic fibres are obtained by chemical processing of petrochemicals. Like natural fibres these fibres can also be woven into fabrics.',\n",
              "       'Synthetic fibres find uses ranging from many household articles like ropes buckets  furniture  containers  etc.  to highly specialised uses in aircrafts ships spacecrafts healthcare etc.',\n",
              "       'Depending upon the types of chemicals used for manufacturing synthetic fibres they are called Rayon Nylon Polyester and Acrylic.',\n",
              "       'The different types of fibres differ from one another in their strength water absorbing capacity nature of burning cost durability etc.',\n",
              "       'Today life without plastics cannot be imagined. Be it home or outside plastic is everywhere.',\n",
              "       'The waste created by plastics is not environment friendly. On burning plastics release poisonous gases. On dumping in the ground they may take years to degenerate. This is because of their non-biodegradable nature.',\n",
              "       'Metals are lustrous whereas non-metals have no lustre.',\n",
              "       'Generally metals are malleable and ductile. Non-metals do not have these properties.',\n",
              "       'Generally metals are good conductors of heat and electricity but non-metals are poor conductors.',\n",
              "       'On burning metals react with oxygen to produce metal oxides which are basic in nature. Non-metals react with oxygen to produce non- metallic oxides which are acidic in nature.',\n",
              "       'Some metals react with water to produce metal hydroxides and hydrogen gas. Generally non-metals do not react with water.',\n",
              "       'Metals react with acids and produce metal salts and hydrogen gas. Generally non-metals do not react with acids.',\n",
              "       'Some metals react with bases to produce hydrogen gas.',\n",
              "       'More reactive metals displace less reactive metals from their compounds in aqueous solutions.',\n",
              "       'Metals and non-metals are used widely in every day life.',\n",
              "       'Coal petroleum and natural gas are fossil fuels.',\n",
              "       'Fossil fuels were formed from the dead remains of living organisms millions of years ago.',\n",
              "       'Fossil fuels are exhaustible resources.',\n",
              "       'Coke coal tar and coal gas are the products of coal.',\n",
              "       'Petroleum gas petrol diesel kerosene paraffin wax lubricating oil are obtained by refining petroleum',\n",
              "       'Coal and petroleum resources are limited. We should use them judiciously.',\n",
              "       'The substances which burn in air are called combustible.',\n",
              "       'Oxygen (in air) is essential for combustion.',\n",
              "       'Ignition temperature is the lowest temperature at which a combustible substance catches fire.',\n",
              "       'During the process of combustion, heat and light are given out.',\n",
              "       'Inflammable substances have very low ignition temperature.',\n",
              "       'There are various types of combustions such as rapid combustion spontaneous combustion explosion etc.',\n",
              "       'There are three different zones of a flame - dark zone luminous zone and non-luminous zone.',\n",
              "       'An ideal fuel is cheap readily available readily combustible and easy to transport. It has high calorific value. It does not produce gases or residues that pollute the environment.',\n",
              "       'Fuels differ in their efficiency and cost.',\n",
              "       'Unburnt carbon particles in air are dangerous pollutants causing respiratory problems.',\n",
              "       'Incomplete combustion of a fuel gives poisonous carbon monoxide gas.',\n",
              "       'Biodiversity refers to the variety of living organisms in a specific area.',\n",
              "       'Plants and animals of a particular area are known as the flora and fauna of that area.',\n",
              "       'Endemic species are found only in a particular area.',\n",
              "       'Endangered species are those which are facing the danger of extinction.',\n",
              "       'Reforestation is the restocking of destroyed    forests by planting new trees.',\n",
              "       'Some organisms are single-celled while others contain large number of cells.',\n",
              "       'The single cell of unicellular organisms performs all the basic functions performed by a variety of cells in multicellular organisms.',\n",
              "       'The cell has three main parts: (i) the cell membrane (ii) cytoplasm which contains smaller components called organelles and (iii) the nucleus.',\n",
              "       'Nucleus is separated from cytoplasm by a nuclear membrane.',\n",
              "       'Nucleus is separated from cytoplasm by a nuclear membrane.',\n",
              "       'Plant cells differ from animal cells in having an additional layer around the cell membrane termed cell wall.',\n",
              "       'Coloured bodies called plastids are found in the plant cells only. Green plastids containing chlorophyll are called chloroplasts.',\n",
              "       'Plant cell has a big central vacuole unlike a number of small vacuoles in animal cells.',\n",
              "       'Reproduction resulting from the fusion of male and female gametes is called sexual reproduction.',\n",
              "       'The reproductive organs in the female include ovaries oviducts and uterus.',\n",
              "       'The reproductive organs in male include testes sperm ducts and penis.',\n",
              "       'The ovary produces female gametes called ova and the testes produce male gametes called sperms.',\n",
              "       'The fusion of ovum and sperm is called fertilisation. The fertilised egg is called a zygote.',\n",
              "       'Fertilisation that takes place inside the female body is called internal fertilisation. This is observed in human beings and other animals such as hens, cows and dogs.',\n",
              "       'The zygote divides repeatedly to give rise to an embryo.',\n",
              "       'Fertilisation that takes place outside the female body is called external fertilisation. This is observed in frogs fish starfish etc.',\n",
              "       'The embryo gets embedded in the wall of the uterus for further development.',\n",
              "       'The stage of the embryo in which all the body parts are identifiable is called foetus.',\n",
              "       'Animals such as hen frog lizard and butterfly which lay eggs are called oviparous animals.',\n",
              "       'The transformation of the larva into adult through drastic changes is called metamorphosis.',\n",
              "       'The type of reproduction in which only a single parent is involved is called asexual reproduction.',\n",
              "       'In hydra new individuals develop from buds. This method of asexual reproduction is called budding.',\n",
              "       'Amoeba reproduces by dividing itself into two. This type of asexual reproduction is called binary fission.',\n",
              "       'Force could be a push or a pull.',\n",
              "       'A force arises due to the interaction between two objects.',\n",
              "       'Force has magnitude as well as direction.',\n",
              "       'A change in the speed of an object or the direction of its motion or both implies a change in its state of motion.',\n",
              "       'Force acting on an object may cause a change in its state of motion or a change in its shape.',\n",
              "       'A force can act on an object with or without being in contact with it.',\n",
              "       'Force per unit area is called pressure.',\n",
              "       'Liquids and gases exert pressure on the walls of their containers.',\n",
              "       'The pressure exerted by air around us is known as atmospheric pressure.',\n",
              "       'Friction opposes the relative motion between two surfaces in contact. It acts on both the surfaces.',\n",
              "       'Friction depends on the nature of surfaces in contact.',\n",
              "       'For a given pair of surfaces friction depends upon the state of smoothness of those surfaces.',\n",
              "       'Friction depends on how hard the two surfaces press together.',\n",
              "       'Static friction comes into play when we try to move an object at rest.',\n",
              "       'Sliding friction comes into play when an object is sliding over another.',\n",
              "       'Sliding friction is smaller than static friction.',\n",
              "       'Friction is important for many of our activities.',\n",
              "       'Friction can be increased by making a surface rough.',\n",
              "       'The sole of the shoes and the tyres of the vehicle are treaded to increase friction.',\n",
              "       'When one body rolls over another body, rolling friction comes into play. Rolling friction is smaller than sliding friction.',\n",
              "       'In many machines friction is reduced by using ball bearings.',\n",
              "       'Fluid friction can be minimised by giving suitable shapes to bodies moving in fluids.',\n",
              "       'Sound is produced by vibrating objects.',\n",
              "       'In human beings the vibration of the vocal cords produces sound.',\n",
              "       'Sound travels through a medium (gas, liquid or solid). It cannot travel in vacuum.',\n",
              "       'The eardrum senses the vibrations of sound, It sends the signals to the brain. This process is called hearing.',\n",
              "       'The number of oscillations or vibrations per second is called the frequency of oscillation.',\n",
              "       'Larger the amplitude of vibration, the louder is the sound.',\n",
              "       'Higher the frequency of vibration the higher is the pitch and shriller is the sound.',\n",
              "       'Unpleasant sounds are called noise.',\n",
              "       'Attempts should be made to minimise noise pollution.',\n",
              "       'Some liquids are good conductors of electricity and some are poor conductors.',\n",
              "       'Most liquids that conduct electricity are solutions of acids, bases and salts.',\n",
              "       'The passage of an electric current through a conducting liquid causes chemical reactions. The resulting effects are called chemical effects of currents.',\n",
              "       'The process of depositing a layer of any desired metal on another material by means of electricity, is called electroplating.',\n",
              "       'There are two kinds of charges — positive charge and negative charge',\n",
              "       'Like charges repel and unlike charges attract each other.',\n",
              "       'The electrical charges produced by rubbing are called static charges.',\n",
              "       'When charges move they constitute an electric current.',\n",
              "       'An electroscope may be used to detect whether a body is charged or not.',\n",
              "       'The process of transfer of charge from a charged object to the earth is called earthing.',\n",
              "       'The process of electric discharge between clouds and the earth or between differentclouds causes lightning.',\n",
              "       'Lightning conductors can protect buildings from the effects of lightning.',\n",
              "       'Light is reflected from all surfaces.',\n",
              "       'Diffused or irregular reflection takes place from rough surfaces.',\n",
              "       'Regular reflection takes place when light is  incident on smooth, polished and regular surfaces.',\n",
              "       'The angle of incidence is equal to the angle of reflection.',\n",
              "       'Incident ray reflected ray and the normal drawn at the point of incidence to the reflecting surface, lie in the same plane.',\n",
              "       'Image formed in a plane mirror undergoes lateral inversion.',\n",
              "       'Two mirrors inclined to each other give multiple images.',\n",
              "       'Splitting of light into its constituent colours is known as dispersion.',\n",
              "       'The phases of the moon occur because we can see only that part of the moon which reflects the light of the Sun towards us.',\n",
              "       'Stars are celestial bodies that emit light of their own. Our sun is also a star.',\n",
              "       'It is convenient to express distances of stars in light years.',\n",
              "       'Stars appear to move from east to west.',\n",
              "       'The pole star appears to be stationary from the Earth, because it is situated close to the direction of the axis of rotation of the Earth.',\n",
              "       'Constellations are groups of stars that appear to form recognisable shapes.',\n",
              "       'The solar system consists of eight planets and a host of asteroids, comets and meteors.',\n",
              "       'A body revolving around another body is called a satellite.',\n",
              "       'Moon is the natural satellite of the Earth. Some planets also have natural satellites.',\n",
              "       'The artificial satellites revolve around the Earth. They are much closer than the moon.',\n",
              "       'Artificial satellites are used for weather forecasting, long distance communication and remote sensing.',\n",
              "       'Air pollution is the contamination of air by  impurities which may have a harmful impact  on the living organisms and the non-living components.',\n",
              "       'Pollutants are the substances which contaminate air and water.',\n",
              "       'Carbon monoxide nitrogen oxides carbon dioxide methane and sulphur dioxide are the major pollutants of air',\n",
              "       'Increasing levels of greenhouse gases like CO 2 are leading to global warming.',\n",
              "       'Water pollution is the contamination of water by substances harmful to life.',\n",
              "       'Water which is purified and fit for drinking is known as potable water'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "test_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRZ54gFokNh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc3b074-b220-4d80-92d7-71e066cfd11c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['physics>>physics : part - ii',\n",
              "       'social science>>geography : the earth our habitat>>india : climate, vegetation and wildlife',\n",
              "       'science>>diversity in living organisms', ...,\n",
              "       'computer science[c++]>>programming methodology',\n",
              "       'chemistry>>chemistry : part i>>solutions',\n",
              "       'science>>periodic classification of elements'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ohj1x7frQJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02425127-ad18-4c45-953d-c07467ce0650"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "len(list(set(labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVWhJ4o0YxZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c220d760-ecfd-4dda-b93d-ad301b941a4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "len(list(set(train_data[\"board_syllabus\"].values)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjinn0gXkNuP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# course_taxonomy\n",
        "test_labels = list(set(test_data[\"board_syllabus\"].values))\n",
        "emb_data_test = get_cleaned_taxonomy(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4jhpUczsPg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab562932-b1f3-4c46-9b1a-770654729bba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4784, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "test_data_labels = test_data[\"board_syllabus\"].values\n",
        "taxonomy_labels = get_cleaned_taxonomy(test_data_labels)\n",
        "taxonomy_label_vectors = sent_model.encode(taxonomy_labels)\n",
        "taxonomy_label_vectors = np.vstack(taxonomy_label_vectors)\n",
        "taxonomy_label_vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dorQwznCeMpR"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sent_model = SentenceTransformer('bert-large-nli-stsb-mean-tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wl0RJ3SSW4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1475dd5f-b135-4027-c754-f9a5879d78be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# taxonomy_vectors = []\"\"\n",
        "taxonomy_label_vectors = sent_model.encode(emb_data_test)\n",
        "taxonomy_label_vectors = np.vstack(taxonomy_label_vectors)\n",
        "taxonomy_label_vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nso39n1N_po_",
        "outputId": "2bf7937a-8fd1-4837-a91d-da4f1212dc20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MulticlassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=768, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=576, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (act): ReLU()\n",
              "  (fc4): Linear(in_features=512, out_features=1024, bias=True)\n",
              "  (multi_head_attention): MHSA(\n",
              "    (w_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "    (w_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "    (w_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "    (w_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (multihead_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "model = MulticlassClassifier('bert-base-uncased')\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/research_lo_content_taxonomy_classification/model_euclidean_SENT_BERT_cos_attention_2_V3/model_weights'))\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe4qYkV2C4fX"
      },
      "outputs": [],
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "# labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n",
        "\n",
        "# Create the DataLoader.\n",
        "# prediction_data = TensorDataset(test_input_ids, test_attention_masks, test_poincare_tensor)\n",
        "# prediction_sampler = SequentialSampler(prediction_data)\n",
        "# prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taxonomy_label_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpiASNzfEYII",
        "outputId": "0068486b-7941-4ef9-d912-d8a6a94aeed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNdlve8AJcCO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "test_poincare_tensor = torch.tensor(taxonomy_label_vectors,dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idBN7kS5ebZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16c07b3-3e2a-41ff-a696-478b88c69eeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4784"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe0otXOPg7z0"
      },
      "outputs": [],
      "source": [
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j0Q68gjYl8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101680a2-e2e6-43af-cc8a-0d6a9dfd7e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312,)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUsYj0YisOhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43dbc102-9a85-4177-f68f-280bab6e8337"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([312, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "test_poincare_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td0gVH-e_yOz",
        "outputId": "54d449e7-be3b-46c8-8c72-5dfaf1ffe406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: model_euclidean_SENT_BERT_cos_attention_2_V3/ (stored 0%)\n",
            "  adding: model_euclidean_SENT_BERT_cos_attention_2_V3/vocab.txt (deflated 53%)\n",
            "  adding: model_euclidean_SENT_BERT_cos_attention_2_V3/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_euclidean_SENT_BERT_cos_attention_2_V3/tokenizer_config.json (stored 0%)\n",
            "  adding: model_euclidean_SENT_BERT_cos_attention_2_V3/model_weights (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r model_euclidean_SENT_BERT_cos_attention_2_V3.zip model_euclidean_SENT_BERT_cos_attention_2_V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G8sJhA0qigP",
        "outputId": "3e9f2b33-da5f-4cf4-e504-37294bfef626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 417 test sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "417\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "input_ids = test_input_ids.to('cuda')\n",
        "attention_masks = test_attention_masks.to('cuda')\n",
        "test_poincare_tensor = test_poincare_tensor.to('cuda')\n",
        "taxonomy_label_vectors = torch.tensor(taxonomy_label_vectors).to('cuda')\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for index, (input_id,attention_mask) in enumerate(zip(input_ids, attention_masks)):\n",
        "  # print(\"index\",index)\n",
        "  with torch.no_grad():\n",
        "    max_cos_sim =0\n",
        "    outputs = model(input_id.reshape(1,-1),attention_mask.reshape(1,-1),  skip_attention=False)\n",
        "    # for target_tensor in test_poincare_tensor:\n",
        "    #   output_interim = model(input_id.reshape(1,-1),attention_mask.reshape(1,-1), target_tensor.reshape(1,-1) , skip_attention=False)\n",
        "    #   similarity = cos(output_interim,target_tensor)\n",
        "    #   if similarity > max_cos_sim:\n",
        "    #     max_cos_sim = similarity\n",
        "    #     outputs = output_interim\n",
        "      # distances = (F.normalize(outputs,p=2,dim=1) - F.normalize(test_poincare_tensor,p=2,dim=1)).pow(2).sum(1)\n",
        "    # distances,indices = torch.topk(distances,1,largest=False)\n",
        "    # # print(\"test_poincare_tensor[indices]\",indices, test_poincare_tensor[indices].shape)\n",
        "    # # for test_tensor in test_poincare_tensor[indices]:\n",
        "    # outputs = model(input_id.reshape(1,-1),attention_mask.reshape(1,-1), test_poincare_tensor[indices] , skip_attention=False)\n",
        "    \n",
        "  distances = cos(outputs,test_poincare_tensor)#torch.topk(cos(outputs,test_poincare_tensor),20,largest=True)\n",
        "  distances,indices = torch.topk(distances,2,largest=True)\n",
        "  predictions.append(test_labels[indices.cpu().numpy()])\n",
        "#   print(\"outputs\",predictions[-1][0])\n",
        "\n",
        "print(len(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GhAjlZK92dpA",
        "outputId": "48f99fbb-4953-4b60-a105-1c598f349742"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         board_syllabus  \\\n",
              "0                          physics>>physics : part - ii   \n",
              "1     social science>>geography : the earth our habi...   \n",
              "2                science>>diversity in living organisms   \n",
              "3           physics>>physics : part - i>>physical world   \n",
              "4     social science>>history : our pasts - iii>>tri...   \n",
              "...                                                 ...   \n",
              "4779  political science>>political science : indian ...   \n",
              "4780                                   science>>tissues   \n",
              "4781     computer science[c++]>>programming methodology   \n",
              "4782           chemistry>>chemistry : part i>>solutions   \n",
              "4783       science>>periodic classification of elements   \n",
              "\n",
              "                                        question_answer  \n",
              "0      (a) Describe a simple experiment (or activity...  \n",
              "1      What is the average weather in a place over m...  \n",
              "2      Which of the following is correct for the cha...  \n",
              "3      The branch of Physics that deals with the mic...  \n",
              "4      Why did tribals view traders as a major cause...  \n",
              "...                                                 ...  \n",
              "4779   Which one of the following is not true about ...  \n",
              "4780   Which of the following is a fluid matrix of t...  \n",
              "4781   Program formatting has more effect when a con...  \n",
              "4782  Cryoscopic constant is related to depression i...  \n",
              "4783   The elements present in same period have same...  \n",
              "\n",
              "[4784 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a198bd7-468f-4d2b-abf0-bed66de78948\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>physics&gt;&gt;physics : part - ii</td>\n",
              "      <td>(a) Describe a simple experiment (or activity...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>social science&gt;&gt;geography : the earth our habi...</td>\n",
              "      <td>What is the average weather in a place over m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>science&gt;&gt;diversity in living organisms</td>\n",
              "      <td>Which of the following is correct for the cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>physics&gt;&gt;physics : part - i&gt;&gt;physical world</td>\n",
              "      <td>The branch of Physics that deals with the mic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>social science&gt;&gt;history : our pasts - iii&gt;&gt;tri...</td>\n",
              "      <td>Why did tribals view traders as a major cause...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4779</th>\n",
              "      <td>political science&gt;&gt;political science : indian ...</td>\n",
              "      <td>Which one of the following is not true about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4780</th>\n",
              "      <td>science&gt;&gt;tissues</td>\n",
              "      <td>Which of the following is a fluid matrix of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4781</th>\n",
              "      <td>computer science[c++]&gt;&gt;programming methodology</td>\n",
              "      <td>Program formatting has more effect when a con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4782</th>\n",
              "      <td>chemistry&gt;&gt;chemistry : part i&gt;&gt;solutions</td>\n",
              "      <td>Cryoscopic constant is related to depression i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4783</th>\n",
              "      <td>science&gt;&gt;periodic classification of elements</td>\n",
              "      <td>The elements present in same period have same...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4784 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a198bd7-468f-4d2b-abf0-bed66de78948')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a198bd7-468f-4d2b-abf0-bed66de78948 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a198bd7-468f-4d2b-abf0-bed66de78948');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdY-7sVdDuuB"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmTe7iy3XQQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4e90c9-0220-4d0f-b16d-efedbf6acd85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,784 test sentences...\n",
            "4784\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "\n",
        "input_ids = test_input_ids.to('cuda')\n",
        "attention_masks = test_attention_masks.to('cuda')\n",
        "test_poincare_tensor = test_poincare_tensor.to('cuda')\n",
        "# taxonomy_label_vectors = torch.tensor(taxonomy_label_vectors).to('cuda')\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for index, (input_id,attention_mask) in enumerate(zip(input_ids, attention_masks)):\n",
        "  # print(\"index\",index)\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_id.reshape(1,-1),attention_mask.reshape(1,-1),skip_attention=False)\n",
        "    \n",
        "  distances = cos(outputs,test_poincare_tensor)#torch.topk(cos(outputs,test_poincare_tensor),20,largest=True)\n",
        "  distances,indices = torch.topk(distances,3,largest=True)\n",
        "  predictions.append(test_labels[indices.cpu().numpy()])\n",
        "#   print(\"outputs\",predictions[-1][0])\n",
        "\n",
        "print(len(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r73Yqo__Dssf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5898178-373c-4960-f357-27c652c7069f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAaqEDFBWZcU",
        "outputId": "31711188-dc3f-4d4d-b2ac-bec22198cbff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0.0828, -0.0705]), torch.Size([2, 128]), torch.Size([1, 128]))"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input1 = torch.randn(2, 128)\n",
        "input2 = torch.randn(1, 128)\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "output = cos(input1, input2)\n",
        "output, input1.shape, input2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JaJBFbQW7Xh"
      },
      "outputs": [],
      "source": [
        "if output <0:\n",
        "  print(\"here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNKgkK7-fCcQ",
        "outputId": "94182697-8d33-443a-de90-acdc78b16b2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 66, 237, 116, ...,  49,   8, 152])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTfINIhem49F",
        "outputId": "07005481-23b6-45b9-e555-7650b69e178e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['science', 'physics>>physics : part - ii',\n",
              "       'chemistry>>chemistry : part i>>states of matter',\n",
              "       'science>>motion', 'science>>components of food'], dtype='<U116')"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LJCr2Bi89Zw5",
        "outputId": "0245a378-4ad0-40d5-bd81-896754acb114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.13.1\n",
            "  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6 MB 104 kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.47.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-hub==0.7.0\n",
            "  Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (1.15.0)\n",
            "Installing collected packages: tensorflow-hub\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.12.0\n",
            "    Uninstalling tensorflow-hub-0.12.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.12.0\n",
            "Successfully installed tensorflow-hub-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.13.1\n",
        "! pip install tensorflow-hub==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5wj2gXYFkrQ"
      },
      "outputs": [],
      "source": [
        "labels=test_data['board_syllabus'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOt8hvs-CZfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf2beec-7dc3-449e-8781-6a78caaf0d0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66, 237, 116, ...,  49,   8, 152])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "from sklearn .preprocessing import LabelEncoder\n",
        "LE= LabelEncoder()\n",
        "labels = LE.fit_transform(labels)\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adb4gTNgGKUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6de7315-7ac6-4adb-ce00-0b1d320874df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66, 237, 116, ...,  49,   8, 152])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbohQzAhlYRN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azkCfK-bCoXd"
      },
      "outputs": [],
      "source": [
        "final_predictions = []\n",
        "for prediction in predictions:\n",
        "  final_predictions.append(LE.transform(prediction))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQrlczKxMwzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8585c710-c627-47c3-9c68-9776493940bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "len(final_predictions[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy5sU-c8YZqE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "39f6c890-9b10-4854-ac9c-c2f4b63c3872"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         board_syllabus  \\\n",
              "0                          physics>>physics : part - ii   \n",
              "1     social science>>geography : the earth our habi...   \n",
              "2                science>>diversity in living organisms   \n",
              "3           physics>>physics : part - i>>physical world   \n",
              "4     social science>>history : our pasts - iii>>tri...   \n",
              "...                                                 ...   \n",
              "4779  political science>>political science : indian ...   \n",
              "4780                                   science>>tissues   \n",
              "4781     computer science[c++]>>programming methodology   \n",
              "4782           chemistry>>chemistry : part i>>solutions   \n",
              "4783       science>>periodic classification of elements   \n",
              "\n",
              "                                        question_answer  \n",
              "0      (a) Describe a simple experiment (or activity...  \n",
              "1      What is the average weather in a place over m...  \n",
              "2      Which of the following is correct for the cha...  \n",
              "3      The branch of Physics that deals with the mic...  \n",
              "4      Why did tribals view traders as a major cause...  \n",
              "...                                                 ...  \n",
              "4779   Which one of the following is not true about ...  \n",
              "4780   Which of the following is a fluid matrix of t...  \n",
              "4781   Program formatting has more effect when a con...  \n",
              "4782  Cryoscopic constant is related to depression i...  \n",
              "4783   The elements present in same period have same...  \n",
              "\n",
              "[4784 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a294bf7-18b7-4943-8d03-977609718100\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>board_syllabus</th>\n",
              "      <th>question_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>physics&gt;&gt;physics : part - ii</td>\n",
              "      <td>(a) Describe a simple experiment (or activity...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>social science&gt;&gt;geography : the earth our habi...</td>\n",
              "      <td>What is the average weather in a place over m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>science&gt;&gt;diversity in living organisms</td>\n",
              "      <td>Which of the following is correct for the cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>physics&gt;&gt;physics : part - i&gt;&gt;physical world</td>\n",
              "      <td>The branch of Physics that deals with the mic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>social science&gt;&gt;history : our pasts - iii&gt;&gt;tri...</td>\n",
              "      <td>Why did tribals view traders as a major cause...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4779</th>\n",
              "      <td>political science&gt;&gt;political science : indian ...</td>\n",
              "      <td>Which one of the following is not true about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4780</th>\n",
              "      <td>science&gt;&gt;tissues</td>\n",
              "      <td>Which of the following is a fluid matrix of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4781</th>\n",
              "      <td>computer science[c++]&gt;&gt;programming methodology</td>\n",
              "      <td>Program formatting has more effect when a con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4782</th>\n",
              "      <td>chemistry&gt;&gt;chemistry : part i&gt;&gt;solutions</td>\n",
              "      <td>Cryoscopic constant is related to depression i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4783</th>\n",
              "      <td>science&gt;&gt;periodic classification of elements</td>\n",
              "      <td>The elements present in same period have same...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4784 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a294bf7-18b7-4943-8d03-977609718100')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a294bf7-18b7-4943-8d03-977609718100 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a294bf7-18b7-4943-8d03-977609718100');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWbRY6heYOyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8833764b-2264-4742-a6e1-c7b24e301eb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['science>>tissues'], dtype='<U116')"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "predictions[-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5ZOR-cHuNm5",
        "outputId": "ccc8a81d-fa33-45fd-c328-a8b504d039f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4784, 3) (4784,)\n",
            "update_recall:  0.8536789297658863\n",
            "recall 0.8536789297658863\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 4084.0, 700.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[100,  66,   0],\n",
            "       [243, 237, 222],\n",
            "       [287, 162, 116],\n",
            "       ...,\n",
            "       [ 49,  42,  35],\n",
            "       [ 15,   8,   6],\n",
            "       [204, 203, 152]]), indices=array([[1, 0, 2],\n",
            "       [0, 1, 2],\n",
            "       [2, 0, 1],\n",
            "       ...,\n",
            "       [0, 2, 1],\n",
            "       [1, 0, 2],\n",
            "       [2, 1, 0]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=3)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=3)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 3)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=3)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=3)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 3)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SivAUTmt9rZo",
        "outputId": "12f27aff-82fe-4a34-92ca-074d3b1fdb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4784, 3) (4784,)\n",
            "update_recall:  0.8536789297658863\n",
            "recall 0.8536789297658863\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4084.0, 700.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[100,  66,   0],\n",
            "       [243, 237, 222],\n",
            "       [287, 162, 116],\n",
            "       ...,\n",
            "       [ 49,  42,  35],\n",
            "       [ 15,   8,   6],\n",
            "       [204, 203, 152]]), indices=array([[1, 0, 2],\n",
            "       [0, 1, 2],\n",
            "       [2, 0, 1],\n",
            "       ...,\n",
            "       [0, 2, 1],\n",
            "       [1, 0, 2],\n",
            "       [2, 1, 0]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ManVio1UstLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a43b41-63eb-430d-aee3-669157aba0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4784, 1) (4784,)\n",
            "update_recall:  0.6538461538461539\n",
            "recall 0.6538461538461539\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3128.0, 1656.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 66],\n",
            "       [243],\n",
            "       [162],\n",
            "       ...,\n",
            "       [ 49],\n",
            "       [  8],\n",
            "       [152]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       ...,\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIGUMVo5BN0M",
        "outputId": "cbdc784b-9425-432d-c67d-204e854a768f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4784, 1) (4784,)\n",
            "update_recall:  0.6538461538461539\n",
            "recall 0.6538461538461539\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 3128.0, 1656.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 66],\n",
            "       [243],\n",
            "       [162],\n",
            "       ...,\n",
            "       [ 49],\n",
            "       [  8],\n",
            "       [152]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       ...,\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is-KTAENfB6C",
        "outputId": "b715dc68-294c-48db-f253-a9a5b79b41be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4784, 20) (4784,)\n",
            "update_recall:  0.9627926421404682\n",
            "recall 0.9627926421404682\n",
            "STREAM_VARS:  [4606.0, 178.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[155, 140, 118, ...,  57,   6,   0],\n",
            "       [246, 243, 242, ..., 216, 176,  21],\n",
            "       [302, 290, 287, ...,  39,  32,  30],\n",
            "       ...,\n",
            "       [167, 163, 145, ...,  35,  32,  30],\n",
            "       [305, 282, 202, ...,   6,   2,   0],\n",
            "       [291, 287, 273, ..., 100,  64,   3]]), indices=array([[11,  2,  3, ..., 14, 17, 12],\n",
            "       [11,  2, 18, ...,  6,  1, 13],\n",
            "       [18, 12, 13, ..., 19, 10, 14],\n",
            "       ...,\n",
            "       [14, 16, 17, ...,  2, 12, 18],\n",
            "       [11, 19, 10, ...,  3,  5,  9],\n",
            "       [ 3,  1, 12, ...,  5, 17,  2]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=20)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=20)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 20)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvwRAcBiEnJx",
        "outputId": "a9787070-717c-4940-b995-f11ce12d2157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4784, 15) (4784,)\n",
            "update_recall:  0.9529682274247492\n",
            "recall 0.9529682274247492\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4559.0, 225.0, 0.0, 0.0]\n",
            "TMP_RANK:  TopKV2(values=array([[155, 140, 118, ...,  66,  57,   0],\n",
            "       [246, 243, 238, ..., 216, 176,  21],\n",
            "       [290, 287, 286, ...,  45,  32,  30],\n",
            "       ...,\n",
            "       [167, 114, 100, ...,  36,  35,  32],\n",
            "       [305, 202,  96, ...,   6,   2,   0],\n",
            "       [291, 287, 273, ..., 110, 100,   3]]), indices=array([[11,  2,  3, ...,  1, 14, 12],\n",
            "       [11,  2, 10, ...,  6,  1, 13],\n",
            "       [12, 13,  5, ...,  1, 10, 14],\n",
            "       ...,\n",
            "       [14,  9,  8, ..., 10,  2, 12],\n",
            "       [11, 10, 14, ...,  3,  5,  9],\n",
            "       [ 3,  1, 12, ...,  8,  5,  2]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=15)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=15)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 15)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA47wLR8fVwh",
        "outputId": "8c6cf5e9-a114-405d-c242-21b69708c9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4784, 5) (4784,)\n",
            "precision 0.17926421404682275\n",
            "update_recall:  0.8963210702341137\n",
            "recall 0.8963210702341137\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4288.0, 496.0, 4288.0, 19632.0]\n",
            "TMP_RANK:  TopKV2(values=array([[100,  70,  67,  66,   0],\n",
            "       [243, 237, 228, 222, 221],\n",
            "       [287, 162, 152, 146, 116],\n",
            "       ...,\n",
            "       [ 53,  49,  42,  41,  35],\n",
            "       [ 15,   9,   8,   6,   2],\n",
            "       [204, 203, 179, 152, 131]]), indices=array([[1, 3, 4, 0, 2],\n",
            "       [0, 1, 4, 2, 3],\n",
            "       [2, 0, 3, 4, 1],\n",
            "       ...,\n",
            "       [3, 0, 2, 4, 1],\n",
            "       [1, 4, 0, 2, 3],\n",
            "       [2, 1, 3, 0, 4]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "#new one\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNZLD_H1sdkZ",
        "outputId": "a4355182-57f3-4677-bc18-8f168d9a73ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4784, 5) (4784,)\n",
            "precision 0.17926421404682275\n",
            "update_recall:  0.8963210702341137\n",
            "recall 0.8963210702341137\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4288.0, 496.0, 4288.0, 19632.0]\n",
            "TMP_RANK:  TopKV2(values=array([[100,  70,  67,  66,   0],\n",
            "       [243, 237, 228, 222, 221],\n",
            "       [287, 162, 152, 146, 116],\n",
            "       ...,\n",
            "       [ 53,  49,  42,  41,  35],\n",
            "       [ 15,   9,   8,   6,   2],\n",
            "       [204, 203, 179, 152, 131]]), indices=array([[1, 3, 4, 0, 2],\n",
            "       [0, 1, 4, 2, 3],\n",
            "       [2, 0, 3, 4, 1],\n",
            "       ...,\n",
            "       [3, 0, 2, 4, 1],\n",
            "       [1, 4, 0, 2, 3],\n",
            "       [2, 1, 3, 0, 4]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "#new one\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))/\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI1jhndp6cEW",
        "outputId": "a38d8387-d260-41b6-b660-c0257e1fd01d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4784, 15) (4784,)\n",
            "precision 0.06337792642140468\n",
            "update_recall:  0.9506688963210702\n",
            "recall 0.9506688963210702\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4548.0, 236.0, 4548.0, 67212.0]\n",
            "TMP_RANK:  TopKV2(values=array([[301, 164, 145, ...,  66,  62,   0],\n",
            "       [243, 241, 240, ..., 222, 221, 176],\n",
            "       [171, 170, 162, ...,  45,  44,  33],\n",
            "       ...,\n",
            "       [ 55,  54,  53, ...,  33,  32,  29],\n",
            "       [109,  76,  71, ...,   6,   2,   0],\n",
            "       [171, 169, 166, ..., 104, 103,   3]]), indices=array([[13, 12, 11, ...,  0, 14,  5],\n",
            "       [ 0, 13, 10, ...,  4,  1,  5],\n",
            "       [ 8,  3,  1, ..., 10, 14, 11],\n",
            "       ...,\n",
            "       [ 2,  7,  9, ..., 13, 14,  5],\n",
            "       [11, 13,  7, ...,  6,  4,  9],\n",
            "       [10,  9,  2, ...,  5,  1,  4]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 15)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 15)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 15)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt1pCvY6XH_k",
        "outputId": "33ff999f-0124-47cc-a87e-c64d9e4b882e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4784, 15) (4784,)\n",
            "precision 0.062165551839464886\n",
            "update_recall:  0.9324832775919732\n",
            "recall 0.9324832775919732\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 4461.0, 323.0, 4461.0, 67299.0]\n",
            "TMP_RANK:  TopKV2(values=array([[301, 287,  85, ...,  66,  57,   0],\n",
            "       [288, 248, 246, ..., 176,  96,  88],\n",
            "       [304, 303, 302, ..., 188,  26,   0],\n",
            "       ...,\n",
            "       [ 55,  54,  53, ...,  37,  36,  35],\n",
            "       [291, 282, 229, ...,   9,   8,   2],\n",
            "       [291, 288, 287, ...,  91,  50,   3]]), indices=array([[12,  7, 11, ...,  0, 10,  3],\n",
            "       [ 6, 13, 11, ...,  2,  8, 12],\n",
            "       [12,  6,  1, ..., 11,  3, 14],\n",
            "       ...,\n",
            "       [13,  6,  1, ..., 12,  3,  4],\n",
            "       [13,  9,  8, ..., 10,  0,  2],\n",
            "       [ 6, 14,  4, ..., 13, 11,  2]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "#new \n",
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 15)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 15)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 15)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaA9z5n3mZz0",
        "outputId": "7bcbfb8d-136a-4222-fc64-18f35cbeb47b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4784, 10) (4784,)\n",
            "precision 0.09289297658862876\n",
            "update_recall:  0.9289297658862876\n",
            "recall 0.9289297658862876\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4444.0, 340.0, 4444.0, 43396.0]\n",
            "TMP_RANK:  TopKV2(values=array([[118, 100,  77, ...,  68,  67,  66],\n",
            "       [243, 241, 237, ..., 222, 221, 176],\n",
            "       [171, 162, 155, ..., 103, 102, 100],\n",
            "       ...,\n",
            "       [ 55,  54,  52, ...,  41,  35,  29],\n",
            "       [ 76,  70,  24, ...,   8,   6,   2],\n",
            "       [179, 169, 166, ..., 103,  64,   3]]), indices=array([[9, 7, 4, ..., 1, 2, 0],\n",
            "       [0, 7, 2, ..., 4, 3, 1],\n",
            "       [8, 0, 6, ..., 9, 7, 4],\n",
            "       ...,\n",
            "       [5, 8, 9, ..., 3, 2, 6],\n",
            "       [6, 7, 5, ..., 0, 9, 2],\n",
            "       [4, 8, 2, ..., 1, 7, 3]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 10)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 10)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 10)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK5X-r7choHg",
        "outputId": "e3f36642-7dde-40ed-ea8a-ac2884a0411b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4784, 10) (4784,)\n",
            "precision 0.09337374581939799\n",
            "update_recall:  0.9337374581939799\n",
            "recall 0.9337374581939799\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4467.0, 317.0, 4467.0, 43373.0]\n",
            "TMP_RANK:  TopKV2(values=array([[140, 118, 100, ...,  79,  68,  66],\n",
            "       [243, 237, 236, ..., 221, 216, 176],\n",
            "       [286, 279, 162, ..., 107,  51,  45],\n",
            "       ...,\n",
            "       [114, 100,  54, ...,  42,  41,  35],\n",
            "       [ 27,  25,  24, ...,   6,   2,   0],\n",
            "       [291, 287, 163, ..., 110, 100,   3]]), indices=array([[2, 3, 6, ..., 5, 9, 1],\n",
            "       [2, 3, 8, ..., 0, 6, 1],\n",
            "       [5, 9, 0, ..., 8, 6, 1],\n",
            "       ...,\n",
            "       [9, 8, 6, ..., 1, 3, 2],\n",
            "       [8, 7, 2, ..., 3, 5, 9],\n",
            "       [3, 1, 9, ..., 8, 5, 2]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "#new one\n",
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 10)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 10)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 10)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkKaMSEJnJUX",
        "outputId": "cd651e89-a191-430b-f959-f1ddac168cc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4784, 5) (4784,)\n",
            "precision 0.17065217391304346\n",
            "update_recall:  0.8532608695652174\n",
            "recall 0.8532608695652174\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 4082.0, 702.0, 4082.0, 19838.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 77,  70,  68,  67,  66],\n",
            "       [243, 237, 222, 221, 176],\n",
            "       [162, 133, 131, 116, 100],\n",
            "       ...,\n",
            "       [ 49,  43,  42,  41,  35],\n",
            "       [ 15,  10,   9,   8,   2],\n",
            "       [179, 166, 152, 103,   3]]), indices=array([[4, 3, 1, 2, 0],\n",
            "       [0, 2, 4, 3, 1],\n",
            "       [0, 3, 2, 1, 4],\n",
            "       ...,\n",
            "       [0, 1, 4, 3, 2],\n",
            "       [1, 3, 4, 0, 2],\n",
            "       [4, 2, 0, 1, 3]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPqYvRNIrRg1",
        "outputId": "478d9a0f-67c1-45ff-c6d3-a6b07ec3208b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4784, 1) (4784,)\n",
            "precision 0.5296822742474916\n",
            "update_recall:  0.5296822742474916\n",
            "recall 0.5296822742474916\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2534.0, 2250.0, 2534.0, 2250.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 66],\n",
            "       [243],\n",
            "       [162],\n",
            "       ...,\n",
            "       [ 49],\n",
            "       [  8],\n",
            "       [152]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       ...,\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSZSJeRasv5F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LO classification"
      ],
      "metadata": {
        "id": "4kaDIslGUIdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXC5fljYULYs",
        "outputId": "21173148-90b4-41f6-f25a-5940689a75a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(417, 1) (417,)\n",
            "precision 0.8273381294964028\n",
            "update_recall:  0.8273381294964028\n",
            "recall 0.8273381294964028\n",
            "STREAM_VARS:  [345.0, 72.0, 345.0, 72.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [34],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [ 4],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [21],\n",
            "       [ 0],\n",
            "       [27],\n",
            "       [21],\n",
            "       [27],\n",
            "       [27],\n",
            "       [29],\n",
            "       [29],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [29],\n",
            "       [ 4],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [32],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [39],\n",
            "       [ 2],\n",
            "       [ 2],\n",
            "       [34],\n",
            "       [34],\n",
            "       [34],\n",
            "       [34],\n",
            "       [31],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [18],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [24],\n",
            "       [24],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [19],\n",
            "       [19],\n",
            "       [19],\n",
            "       [19],\n",
            "       [19],\n",
            "       [24],\n",
            "       [19],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [40],\n",
            "       [33],\n",
            "       [33],\n",
            "       [33],\n",
            "       [35],\n",
            "       [33],\n",
            "       [33],\n",
            "       [ 6],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [47],\n",
            "       [28],\n",
            "       [28],\n",
            "       [21],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [39],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [27],\n",
            "       [21],\n",
            "       [21],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [41],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [41],\n",
            "       [41],\n",
            "       [34],\n",
            "       [41],\n",
            "       [41],\n",
            "       [34],\n",
            "       [41],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [44],\n",
            "       [18],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [45],\n",
            "       [ 9],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [13],\n",
            "       [13],\n",
            "       [15],\n",
            "       [13],\n",
            "       [13],\n",
            "       [13],\n",
            "       [13],\n",
            "       [13],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [16],\n",
            "       [47],\n",
            "       [47],\n",
            "       [47],\n",
            "       [47],\n",
            "       [47],\n",
            "       [39],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [30],\n",
            "       [46],\n",
            "       [16],\n",
            "       [35],\n",
            "       [35],\n",
            "       [32],\n",
            "       [32],\n",
            "       [ 8],\n",
            "       [42],\n",
            "       [10],\n",
            "       [20],\n",
            "       [10],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [42],\n",
            "       [20],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [30],\n",
            "       [11],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [ 0],\n",
            "       [30],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [27],\n",
            "       [21],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [39],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [18],\n",
            "       [36],\n",
            "       [14],\n",
            "       [14],\n",
            "       [13],\n",
            "       [31],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [14],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [12],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [37],\n",
            "       [24],\n",
            "       [24],\n",
            "       [25],\n",
            "       [24],\n",
            "       [24],\n",
            "       [24],\n",
            "       [24],\n",
            "       [24],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [35],\n",
            "       [35],\n",
            "       [32],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 2)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 2)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 2)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iSv3Hu0VGt9",
        "outputId": "1a859f44-a8c4-4409-c564-8f1ac8a91245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(417, 2) (417,)\n",
            "precision 0.4712230215827338\n",
            "update_recall:  0.9424460431654677\n",
            "recall 0.9424460431654677\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 393.0, 24.0, 393.0, 441.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5,  1],\n",
            "       [ 5,  1],\n",
            "       [ 5,  4],\n",
            "       [ 5,  1],\n",
            "       [ 7,  5],\n",
            "       [ 7,  5],\n",
            "       [41, 34],\n",
            "       [ 5,  0],\n",
            "       [ 5,  1],\n",
            "       [ 7,  5],\n",
            "       [ 7,  5],\n",
            "       [ 5,  4],\n",
            "       [ 4,  0],\n",
            "       [27,  0],\n",
            "       [29,  0],\n",
            "       [12,  4],\n",
            "       [26,  0],\n",
            "       [27,  0],\n",
            "       [21,  0],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [27, 21],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  4],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [32,  2],\n",
            "       [41,  2],\n",
            "       [ 2,  1],\n",
            "       [17,  2],\n",
            "       [34,  2],\n",
            "       [39,  6],\n",
            "       [ 6,  2],\n",
            "       [ 2,  0],\n",
            "       [41, 34],\n",
            "       [34, 17],\n",
            "       [34,  0],\n",
            "       [34, 32],\n",
            "       [31, 22],\n",
            "       [46, 22],\n",
            "       [22, 20],\n",
            "       [22, 20],\n",
            "       [22, 20],\n",
            "       [33, 22],\n",
            "       [22, 11],\n",
            "       [22, 11],\n",
            "       [45, 22],\n",
            "       [36, 22],\n",
            "       [33, 22],\n",
            "       [13,  9],\n",
            "       [33,  9],\n",
            "       [ 9,  3],\n",
            "       [33,  9],\n",
            "       [21,  9],\n",
            "       [33,  9],\n",
            "       [33,  9],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [18, 10],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [18, 17],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [18, 17],\n",
            "       [17, 11],\n",
            "       [18, 17],\n",
            "       [17, 11],\n",
            "       [17, 11],\n",
            "       [17, 11],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [25, 19],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 19],\n",
            "       [25, 19],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [25, 24],\n",
            "       [24, 19],\n",
            "       [24, 19],\n",
            "       [24, 19],\n",
            "       [24, 19],\n",
            "       [24, 19],\n",
            "       [24, 23],\n",
            "       [25, 19],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [41, 12],\n",
            "       [39, 12],\n",
            "       [41, 12],\n",
            "       [39, 12],\n",
            "       [26, 16],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 16],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [40, 39],\n",
            "       [33, 32],\n",
            "       [33,  8],\n",
            "       [33, 32],\n",
            "       [35, 33],\n",
            "       [33, 32],\n",
            "       [33, 32],\n",
            "       [42,  6],\n",
            "       [28, 21],\n",
            "       [37, 28],\n",
            "       [37, 28],\n",
            "       [47,  6],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [21, 18],\n",
            "       [28, 21],\n",
            "       [28, 19],\n",
            "       [37, 28],\n",
            "       [35, 28],\n",
            "       [28, 21],\n",
            "       [39, 28],\n",
            "       [21,  1],\n",
            "       [45, 21],\n",
            "       [44, 21],\n",
            "       [44, 21],\n",
            "       [44, 21],\n",
            "       [21, 19],\n",
            "       [25, 21],\n",
            "       [29, 27],\n",
            "       [21,  1],\n",
            "       [21,  1],\n",
            "       [ 5,  1],\n",
            "       [41,  1],\n",
            "       [41, 34],\n",
            "       [41,  1],\n",
            "       [21,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41, 34],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41, 34],\n",
            "       [41,  1],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [18,  3],\n",
            "       [46, 45],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [46, 45],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45, 22],\n",
            "       [45,  3],\n",
            "       [45,  9],\n",
            "       [17, 11],\n",
            "       [17, 11],\n",
            "       [37, 11],\n",
            "       [37, 11],\n",
            "       [17, 11],\n",
            "       [11,  2],\n",
            "       [31, 25],\n",
            "       [31, 13],\n",
            "       [31, 22],\n",
            "       [31, 22],\n",
            "       [31, 16],\n",
            "       [31, 13],\n",
            "       [47, 13],\n",
            "       [15, 12],\n",
            "       [13, 12],\n",
            "       [47, 13],\n",
            "       [14, 13],\n",
            "       [47, 13],\n",
            "       [31, 13],\n",
            "       [26, 16],\n",
            "       [16, 14],\n",
            "       [16, 14],\n",
            "       [16, 14],\n",
            "       [16, 13],\n",
            "       [29, 16],\n",
            "       [26, 16],\n",
            "       [26, 16],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [47, 39],\n",
            "       [38, 33],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [38, 31],\n",
            "       [38, 25],\n",
            "       [38, 31],\n",
            "       [38, 32],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [47, 16],\n",
            "       [35, 15],\n",
            "       [35, 32],\n",
            "       [32,  8],\n",
            "       [33, 32],\n",
            "       [35,  8],\n",
            "       [42, 32],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [42,  8],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [34, 10],\n",
            "       [18, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [18, 10],\n",
            "       [34, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [32, 30],\n",
            "       [36, 11],\n",
            "       [30, 17],\n",
            "       [30, 11],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [30,  0],\n",
            "       [33, 30],\n",
            "       [46, 30],\n",
            "       [33, 30],\n",
            "       [30, 10],\n",
            "       [32,  0],\n",
            "       [32, 30],\n",
            "       [43, 28],\n",
            "       [45, 43],\n",
            "       [45, 43],\n",
            "       [45, 43],\n",
            "       [45, 43],\n",
            "       [45, 43],\n",
            "       [45, 43],\n",
            "       [29, 27],\n",
            "       [27, 21],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [39,  6],\n",
            "       [39,  6],\n",
            "       [39,  6],\n",
            "       [39,  6],\n",
            "       [ 7,  6],\n",
            "       [39,  6],\n",
            "       [29,  7],\n",
            "       [35,  7],\n",
            "       [39,  7],\n",
            "       [ 7,  6],\n",
            "       [ 7,  5],\n",
            "       [ 7,  5],\n",
            "       [39,  7],\n",
            "       [39,  7],\n",
            "       [39,  6],\n",
            "       [ 7,  6],\n",
            "       [ 7,  6],\n",
            "       [11,  8],\n",
            "       [17,  8],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [17,  8],\n",
            "       [30,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [14, 13],\n",
            "       [31, 13],\n",
            "       [14, 13],\n",
            "       [15, 14],\n",
            "       [14, 13],\n",
            "       [15, 14],\n",
            "       [16, 14],\n",
            "       [16, 15],\n",
            "       [16, 15],\n",
            "       [34, 15],\n",
            "       [16, 15],\n",
            "       [16, 15],\n",
            "       [34, 15],\n",
            "       [16, 15],\n",
            "       [16, 15],\n",
            "       [34, 15],\n",
            "       [34, 15],\n",
            "       [16, 15],\n",
            "       [16, 15],\n",
            "       [16, 15],\n",
            "       [38, 37],\n",
            "       [45, 38],\n",
            "       [45, 38],\n",
            "       [38,  9],\n",
            "       [38, 31],\n",
            "       [38, 32],\n",
            "       [45, 38],\n",
            "       [38, 33],\n",
            "       [38, 32],\n",
            "       [37, 12],\n",
            "       [12,  4],\n",
            "       [12,  4],\n",
            "       [12,  4],\n",
            "       [37,  1],\n",
            "       [37, 28],\n",
            "       [37, 12],\n",
            "       [37, 12],\n",
            "       [37,  4],\n",
            "       [37, 11],\n",
            "       [37, 19],\n",
            "       [37,  8],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [25, 24],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [40, 19],\n",
            "       [40, 24],\n",
            "       [41, 40],\n",
            "       [40, 19],\n",
            "       [40, 24],\n",
            "       [40, 39],\n",
            "       [40, 39],\n",
            "       [40, 16],\n",
            "       [40, 24],\n",
            "       [40, 39],\n",
            "       [40, 39],\n",
            "       [35, 32],\n",
            "       [35, 32],\n",
            "       [35, 32],\n",
            "       [35, 33],\n",
            "       [35, 32],\n",
            "       [35, 33]]), indices=array([[0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1]], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGbi4DEZkwhh",
        "outputId": "cd3368f1-fd70-4f5a-bdb5-2d5f4bc5690b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3918918918918919"
            ]
          },
          "execution_count": 106,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = np.array(labels)\n",
        "final_predictions = np.array(final_predictions).squeeze()\n",
        "final_predictions.shape\n",
        "len(final_predictions[final_predictions==y_true])/len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IN1UA_4uBu_S"
      },
      "outputs": [],
      "source": [
        "categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdD0JiYgEX4k"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/model_euclidean_SENT_BERT_cos_attention_2_V3.zip \"/content/drive/My Drive/research_lo_content_taxonomy_classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYmKDWRyrsFs"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/model_euclidean_SENT_BERT_cos_attention_2_V3 \"/content/drive/My Drive/research_lo_content_taxonomy_classification\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_WchmXtDspr"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (final_data.label.sum(), len(final_data.label), (final_data.label.sum() / len(final_data.label) * 100.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5BoY2hKGb7_"
      },
      "outputs": [],
      "source": [
        "pred =  np.argmax(predictions[0],axis=1).flatten()\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPuK0-vzGp3R"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  # pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(np.array(labels[i]), np.array(predictions[i])   )             \n",
        "  matthews_set.append(matthews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_vxvq7rHlgr"
      },
      "outputs": [],
      "source": [
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v48rDl4JHmhv",
        "outputId": "df36f340-8ae9-41d6-d481-61b7bc086b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total MCC: 0.000\n"
          ]
        }
      ],
      "source": [
        "flat_predictions = np.array(predictions)\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.array(labels)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI8-HrJ6MSEk",
        "outputId": "f6320849-0f91-41bf-dd5d-e67a37d860d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False False False ... False False False]\n",
            "68\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2664"
            ]
          },
          "execution_count": 93,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_bool = (flat_true_labels==flat_predictions)\n",
        "print(list_bool)\n",
        "print(len([i for i, val in enumerate(list_bool) if val]))\n",
        "len(flat_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drJC0xYkHr_8",
        "outputId": "f1a888f5-f796-4afa-d2bb-d386f0538f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total MCC: 0.023\n"
          ]
        }
      ],
      "source": [
        "print('Total MCC: %.3f' % mcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r6f8jW4BN3j",
        "outputId": "071a5587-f337-437a-94ff-4f47b7997a8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 105,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(flat_predictions[flat_predictions==flat_true_labels])/len(flat_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlA88cTuvlNA",
        "outputId": "bd4b4d4b-023e-4323-cbd1-59c034cf32ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'physical science>>physical science (chemistry)>>synthetic fibres and plastics>>plastics',\n",
              "       'science>>physical and chemical changes',\n",
              "       'social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'computer science[c++]>>arrays',\n",
              "       'computer science[c++]>>standard library functions',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>reproduction in animals',\n",
              "       'social science>>history : our pasts - iii>>weavers, iron smelter & factory owners',\n",
              "       'social science>>civics : social and political life-i>>key elements of a democratic government',\n",
              "       'science>>materials : metals and non-metals',\n",
              "       'physics>>physics : part - i>>physical world',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>sources of energy',\n",
              "       'science>>materials : metals and non-metals',\n",
              "       'science>>human eye and colourful world',\n",
              "       'science>>human eye and colourful world',\n",
              "       'social science>>civics : social and political life>>judiciary',\n",
              "       'social science>>history : our pasts - i>>vital villages, thriving towns',\n",
              "       'computer science[c++]>>standard library functions',\n",
              "       'science>>the living organisms — characteristics and habitats',\n",
              "       'chemistry>>chemistry : part i>>d and f- block elements',\n",
              "       'social science>>civics : social and political life>>confronting marginalisation',\n",
              "       'science>>how do organisms reproduce?',\n",
              "       'science>>weather, climate and adaptations of animals to climate',\n",
              "       'social science>>political science : democratic politics - i>>what is democracy? why democracy?',\n",
              "       'science>>is matter around us pure',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'science>>sources of energy',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>weather, climate and adaptations of animals to climate',\n",
              "       'physics>>physics : part - i>>laws of motion',\n",
              "       'physics>>physics : part - ii>>mechanical properties of fluids',\n",
              "       'computer science[c++]>>arrays',\n",
              "       'social science>>geography : our environment>>human environment-settlement, transport and communication',\n",
              "       'social science>>civics : social and political life>>confronting marginalisation',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'chemistry>>chemistry : part ii>>the s-block elements',\n",
              "       'science>>improvement in food resources'], dtype='<U102')"
            ]
          },
          "execution_count": 97,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_predictions[:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa48dokzvnq8",
        "outputId": "6a7efcd3-1b36-4ade-d198-d11d37163e0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'science>>electricity and circuits', 'science>>changes around us',\n",
              "       'social science>>civics : social and political life - ii>>understanding advertising',\n",
              "       'computer science[c++]>>programming methodology',\n",
              "       'computer science[c++]>>structured query language',\n",
              "       'computer science[c++]>>object oriented programming',\n",
              "       'computer science[c++]>>general oop concepts',\n",
              "       'science>>how do organisms reproduce?',\n",
              "       'social science>>history : our pasts - iii>>ruling the countryside',\n",
              "       'social science>>civics : social and political life>>the indian constitution',\n",
              "       'physical science>>physical science (chemistry)>>metals and non-metals>>metals',\n",
              "       'physics>>physics : part - i>>motion in straight line',\n",
              "       'computer science[c++]>>structured query language',\n",
              "       'physics>>physics : part - i>>laws of motion',\n",
              "       'social science>>civics : social and political life - ii>>role of the government in health',\n",
              "       'science>>friction',\n",
              "       'physical science>>physical science (physics)>>friction>>friction',\n",
              "       'social science>>history : our pasts - iii>>india after independence',\n",
              "       'social science>>history : our pasts - i>>new questions and ideas',\n",
              "       'computer science[c++]>>c++ revision tour',\n",
              "       'science>>getting to know plants',\n",
              "       'chemistry>>chemistry : part i>>chemical bonding and molecular structure',\n",
              "       'social science>>civics : social and political life>>public facilities',\n",
              "       'science>>getting to know plants',\n",
              "       'science>>forests: our lifeline',\n",
              "       'social science>>political science : democratic politics - i>>democracy in the contemporary world',\n",
              "       'science>>atoms and molecules',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'physics>>sources of energy>>sources of energy',\n",
              "       'computer science[c++]>>classes and objects',\n",
              "       'science>>forests: our lifeline',\n",
              "       'physics>>physics : part - i>>system of particles and rotational motion',\n",
              "       'science>>gravitation', 'computer science[c++]>>boolean algebra',\n",
              "       'social science>>geography : our environment>>air',\n",
              "       'social science>>disaster management - together, towards a safer india-ii>>specific hazards and mitigation',\n",
              "       'social science>>the mughal empire>>the mughal empire',\n",
              "       'chemistry>>chemistry : part i>>classification of elements and periodicity in properties',\n",
              "       'science>>getting to know plants'], dtype=object)"
            ]
          },
          "execution_count": 98,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_true_labels[:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlDkbovu0rg5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "av3GeuiBHock",
        "outputId": "b26059ca-4c1e-4b2e-ff53-d01a08318bb7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-bccf3861f92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_true_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'flat_true_labels' is not defined"
          ]
        }
      ],
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKxxgz1AFAkM",
        "outputId": "120ff3ec-6c34-465d-8f16-c33b8ab205c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.1922086736219466, 0.2357500283089443, 0.18486435529602976, None)"
            ]
          },
          "execution_count": 105,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it0TjEdVE-eH",
        "outputId": "b005a06b-cbc2-4f70-cb8a-1034bb84ffef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.2265830482911008, 0.26238738738738737, 0.21514243361084723, None)"
            ]
          },
          "execution_count": 106,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPts-dvGHsZj",
        "outputId": "b4e8016f-dfbf-4e77-e838-705ea6331bd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.2265830482911008, 0.26238738738738737, 0.21514243361084723, None)"
            ]
          },
          "execution_count": 107,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "9bq9ymZTM3_j",
        "outputId": "c0d0fe3a-4aa7-4e88-813b-d5a6b124cfe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'bertviz_repo'...\n",
            "remote: Enumerating objects: 1074, done.\u001b[K\n",
            "remote: Total 1074 (delta 0), reused 0 (delta 0), pack-reused 1074\u001b[K\n",
            "Receiving objects: 100% (1074/1074), 99.41 MiB | 27.17 MiB/s, done.\n",
            "Resolving deltas: 100% (687/687), done.\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
        "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
        "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
        "if not 'bertviz_repo' in sys.path:\n",
        "  sys.path += ['bertviz_repo']\n",
        "!pip install regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yCzNQ6ZBYtI"
      },
      "outputs": [],
      "source": [
        "!7z x model_save.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kbAQwaydsyl"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==3.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV9m2pTXybLf"
      },
      "outputs": [],
      "source": [
        "!pip list | grep transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPpDi44ySCjH"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "smodel = BertForSequenceClassification.from_pretrained('/content/model_save_categorized_reduced_oct', num_labels = 335,  cache_dir=None, \n",
        "    output_attentions = True, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True)\n",
        "tokenizer = BertTokenizer.from_pretrained('model_save_categorized_reduced_oct', do_lower_case=True)\n",
        "# model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "Gr9EyWoVSZk-",
        "outputId": "e20c3b84-d6e8-4312-9d4d-d08eb3fe6f67"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-d03fb6cb4ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_neuron_view\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbertviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_view\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1.1.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWordpieceTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIGPTTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_transfo_xl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTransfoXLTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransfoXLCorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_gpt2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/tokenization_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/tokenization_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/file_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boto3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n",
        "from bertviz.neuron_view import show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtPPmu9rcGRV"
      },
      "outputs": [],
      "source": [
        "def call_html():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
        "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEq2YAbed5Fl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def show_head_view(model, tokenizer, sentence_a, sentence_b=None):\n",
        "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    if sentence_b:\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
        "        sentence_b_start = token_type_ids[0].tolist().index(1)\n",
        "    else:\n",
        "        attention = model(input_ids)[-1]\n",
        "        sentence_b_start = None\n",
        "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)    \n",
        "    head_view(attention, tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oUiRZRdcIFC"
      },
      "outputs": [],
      "source": [
        "sentence_a = \"The cat sat on the mat\"\n",
        "sentence_b = \"The cat lay on the rug\"\n",
        "\n",
        "model_type = 'bert'\n",
        "model_version = 'bert-base-uncased'\n",
        "model.to('cpu')\n",
        "show_head_view(model, tokenizer, sentence_a, sentence_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2x-6JL3cNPz"
      },
      "outputs": [],
      "source": [
        "print(\"here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYSYbMG-Gorc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "euclidean_taxonomy_prediction_SENT_BERT_interactive_attention_V3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}